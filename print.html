<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>learn-gfx-hal</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body class="light">
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { } 
            if (theme === null || theme === undefined) { theme = default_theme; }
            document.body.className = theme;
            document.querySelector('html').className = theme + ' js';
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <ol class="chapter"><li><a href="01_introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li><a href="02_opening_a_window.html"><strong aria-hidden="true">2.</strong> Opening A Window</a></li><li><a href="03_clear_the_window.html"><strong aria-hidden="true">3.</strong> Clear The Window</a></li><li><a href="04_triangle_intro.html"><strong aria-hidden="true">4.</strong> Triangle Intro</a></li><li><a href="05_shaders.html"><strong aria-hidden="true">5.</strong> Shaders</a></li><li><a href="06_textures.html"><strong aria-hidden="true">6.</strong> Textures</a></li><li><a href="07_coordinates.html"><strong aria-hidden="true">7.</strong> Coordinates</a></li><li><a href="08_camera.html"><strong aria-hidden="true">8.</strong> Camera</a></li><li><a href="09_depth_buffer.html"><strong aria-hidden="true">9.</strong> Depth Buffer</a></li><li><a href="10_instanced_drawing.html"><strong aria-hidden="true">10.</strong> Instanced Drawing</a></li></ol>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">learn-gfx-hal</h1> 

                        <div class="right-buttons">
                            <a href="print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <a class="header" href="#introduction" id="introduction"><h1>Introduction</h1></a>
<a class="header" href="#what-is-gfx-hal" id="what-is-gfx-hal"><h2>What Is <code>gfx-hal</code></h2></a>
<p>The <a href="https://docs.rs/gfx-hal">gfx-hal</a> crate is a cross platform graphics API
that attempts to be a minimal wrapping of the &quot;modern, low level&quot; graphics APIs
(DX12, Vulkan, and Metal).</p>
<p>To quote Icefox (lead of the GGEZ project):</p>
<blockquote>
<p>I think of Vulkan as basically being GPU assembly language, at least in terms
of level of abstraction. Which is to say, there is very little abstraction: it
gives you the parts that you have to work with, it has nothing stopping you
from doing whatever you feel like with those parts, now go write stuff with
it. No, there's no memory allocator. I just told you to go write stuff, didn't
I? Write it. Comparatively, OpenGL is like GPU Javascript: It starts out
convenient, but it's old, wacky, clunky, weird, has a million evolutionary
versions and odd edge cases, and itâ€™s not really a convenient model for
computation these days. Sure you can make it fast if you try, but you have to
jump through lots of hoops to do so.</p>
</blockquote>
<p>So this will be a <em>very long</em> style of tutorial, because we'll have to be doing
oh-so-many little steps and configurations by hand as we learn to do each new
thing. If that's not your scene then sorry I guess, this tutorial might not be
for you.</p>
<a class="header" href="#requirements" id="requirements"><h2>Requirements</h2></a>
<p>I assume that you have basic familiarity with Rust. So go read <a href="https://doc.rust-lang.org/book/">The Rust
Book</a> if you haven't ever done that.</p>
<p>We will also be touching upon elements of <code>unsafe</code> Rust, and so you should also
read <a href="https://doc.rust-lang.org/nomicon/">The Rustonomicon</a> if you have not.
Actually, that's a mild lie, most of <code>gfx-hal-0.1.0</code> doesn't define any of its
safety limits anyway (not beyond &quot;whatever Vulkan say is okay&quot;), so it's all a
shot in the dark no matter what you do. Even if you're using a backend that
isn't Vulkan.</p>
<p>I don't assume you have any prior graphics programming skills. I sure don't have
much myself. I drew a quad once in OpenGL, but that's it. We'll be learning and
reviewing all that stuff together.</p>
<p>The code all assumes that you're using <strong>Rust 2018</strong>.</p>
<p>I set rustfmt to have 2 space indents and a line limit of 100.</p>
<a class="header" href="#opening-a-window" id="opening-a-window"><h1>Opening A Window</h1></a>
<p>Before we can draw anything, we need a place to draw it. That means we need to
open a window.</p>
<a class="header" href="#initializing-a-window" id="initializing-a-window"><h2>Initializing A Window</h2></a>
<p>To open a window in Rust, you want to use the <a href="https://docs.rs/winit/">winit</a>
crate to get the best cross-platform coverage available. At the time of writing,
the latest version is 0.18. Set up a project for this tutorial however you like
and just add <code>winit</code> to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
winit = &quot;0.18&quot;
</code></pre>
<p>The <code>winit</code> crate is what you'd call &quot;mostly stable&quot;. There are small breaking changes
with new versions, but it's usually plain enough to see what the new types or methods
that you need to move to are.</p>
<p>The <a href="https://docs.rs/winit/0.18.0/winit/#building-a-window">crate documentation</a>
goes over the basic steps of building a window:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let events_loop = EventsLoop::new();
let window = WindowBuilder::new()
  .with_title(&quot;Example&quot;)
  .build(&amp;events_loop)
  .expect(&quot;Could not create a window!&quot;);
#}</code></pre></pre>
<p>Of course, the
<a href="https://docs.rs/winit/0.18.0/winit/struct.WindowBuilder.html">WindowBuilder</a>
type has many other methods you might want to use, so be sure to check all
that out.</p>
<a class="header" href="#responding-to-events" id="responding-to-events"><h2>Responding To Events</h2></a>
<p>Once the window is open the user will try to interact with the window. They'll
move the mouse, type keys, click the <code>x</code> in the corner to close it, things like
that. You handle all of this with
<a href="https://docs.rs/winit/0.18.0/winit/struct.EventsLoop.html">EventsLoop</a>.
You can call
<a href="https://docs.rs/winit/0.18.0/winit/struct.EventsLoop.html#method.run_forever">run_forever</a>
with a callback, or
<a href="https://docs.rs/winit/0.18.0/winit/struct.EventsLoop.html#method.poll_events">poll_events</a>
with a callback. In both cases, your callback gets an
<a href="https://docs.rs/winit/0.18.0/winit/enum.Event.html">Event</a>, which is an enum.
Naturally we have to match on that and find the cases we care about. We can discard the
other types. You'll actually get a whole lot of events through <code>winit</code>,
so it's definitely good to ignore most of them if you only care about one or two
event types.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut running = true;
while running {
  events_loop.poll_events(|event| match event {
    Event::WindowEvent {
      event: WindowEvent::CloseRequested,
      ..
    } =&gt; running = false,
    _ =&gt; (),
  });
}
#}</code></pre></pre>
<a class="header" href="#pack-it-together" id="pack-it-together"><h2>Pack It Together</h2></a>
<p>We'll have a lot of things floating around as we go along, so we'll want to pack
things together when we can. Winit doesn't care what graphical libs you're using
to draw within the frame, so we can keep just the windowing stuff in its own
struct, apart from any gfx-hal things.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug)]
pub struct WinitState {
  pub events_loop: EventsLoop,
  pub window: Window,
}
#}</code></pre></pre>
<p>Of course, we want to streamline those building steps:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl WinitState {
  /// Constructs a new `EventsLoop` and `Window` pair.
  ///
  /// The specified title and size are used, other elements are default.
  /// ## Failure
  /// It's possible for the window creation to fail. This is unlikely.
  pub fn new&lt;T: Into&lt;String&gt;&gt;(title: T, size: LogicalSize) -&gt; Result&lt;Self, CreationError&gt; {
    let events_loop = EventsLoop::new();
    let output = WindowBuilder::new()
      .with_title(title)
      .with_dimensions(size)
      .build(&amp;events_loop);
    output.map(|window| Self {
      events_loop,
      window,
    })
  }
}
#}</code></pre></pre>
<p>And we probably want to go one step farther for our examples and just give a
<code>Default</code> impl that calls <code>new</code> with some default values and then panics if
there's a <code>CreationError</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const WINDOW_NAME: &amp;str = &quot;Hello Winit&quot;;

impl Default for WinitState {
  /// Makes an 800x600 window with the `WINDOW_NAME` value as the title.
  /// ## Panics
  /// If a `CreationError` occurs.
  fn default() -&gt; Self {
    Self::new(
      WINDOW_NAME,
      LogicalSize {
        width: 800.0,
        height: 600.0,
      },
    )
    .expect(&quot;Could not create a window!&quot;)
  }
}
#}</code></pre></pre>
<a class="header" href="#running-the-program" id="running-the-program"><h2>Running The Program</h2></a>
<p>So far we only have a very tiny main function to look at:</p>
<pre><pre class="playpen"><code class="language-rust">fn main() {
  let mut winit_state = WinitState::default();
  let mut running = true;
  while running {
    winit_state.events_loop.poll_events(|event| match event {
      Event::WindowEvent {
        event: WindowEvent::CloseRequested,
        ..
      } =&gt; running = false,
      _ =&gt; (),
    });
  }
}
</code></pre></pre>
<p>If you run this you get an all white window. Actually, without anything being
drawn to the window, it might instead show all black, or even just garbage pixel
data. It depends on your windowing system.</p>
<p>Also, normally an application would use &quot;Vertical Synchronization&quot; (Vsync) to
slow down the main loop. Without any drawing code we can't use vsync, so the
loop will run as fast as possible and use 100% of the core it's on.</p>
<p>Both things are not good, but this is just a stepping stone and we learn
to draw stuff in the next lesson, so it's fine.</p>
<p><img src="images/hello-winit-complete.png" alt="hello-winit-complete" /></p>
<p>All of the code discussed here is available within the
<a href="https://github.com/gfx-rs/learn-gfx-hal/blob/master/examples/hello_winit.rs">hello_winit</a>
example.</p>
<a class="header" href="#clearing-the-window" id="clearing-the-window"><h1>Clearing The Window</h1></a>
<p>Once you have a window open, the <em>usual</em> next step for a graphics tutorial is to
draw &quot;your first triangle&quot;. You see, the fundamental primitive of 3d graphics is
the triangle. Yes, there are some systems such as the <a href="https://en.wikipedia.org/wiki/Sega_Saturn">Sega
Saturn</a> that use quads instead, but
in all the modern systems you'll find it's going to be triangles. Even a quad is
just two triangles, when you think about it. With enough math and enough
parallel processing you can do anything you want with triangles.</p>
<ul>
<li>Skyrim? Triangles.</li>
<li>Breath of The Wild? Has a few more triangles than Skyrim.</li>
<li>Super Smash Bros? Just a whole lot of triangles.</li>
</ul>
<p>We'll be covering triangles <em>quite</em> a bit. However, in the context of <code>gfx-hal</code>,
which is like 97% &quot;whatever Vulkan does&quot;, even if you're <em>not</em> using the Vulkan
backend, there's a great <em>many</em> steps of setup involved between &quot;a window that
draws nothing&quot; and &quot;a window that draws one triangle&quot;.</p>
<p>In fact the <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/">official gfx-hal docs</a>
specifically give us a warning about this. The top level docs are so short I can
include all three sentences right here for dramatic effect:</p>
<blockquote>
<p>Low-level graphics abstraction for Rust. Mostly operates on data, not types.
Designed for use by libraries and higher-level abstractions only.</p>
</blockquote>
<p>There are basically no defaults provided. We have to list out every single
little step of the entire configuration process. I mean they convert C types
into Rust types for us, but it's still very &quot;do it yourself&quot;. That's <em>cool</em> if
you actually care about defining it all (which you will some day, I'm sure, or
you wouldn't be reading this right now), but it's also <em>long</em> when you're
starting out and want to get something on the screen.</p>
<p>Since going all the way to &quot;drawing a triangle&quot; might end up feeling like too
much at once, we'll stop this lesson at an intermediate step. Remember how our
<code>winit</code> window from last lesson didn't refresh itself properly? We can fix just
that much and then stop there. That <em>alone</em> will cover a surprising amount of
ground.</p>
<p>To be absolutely clear: <em>PLEASE</em> understand that this is a whirlwind tour of
many corners of the whole process all at once. Since so much needs to be set up
before you can draw anything, quite a bit gets skimmed over simply so that we
can talk about all the parts. As it is, this lesson is still more than 10,000
words long. Future lessons will review different elements of what gets built
here, and I promise that it makes sense the more you stick with it.</p>
<a class="header" href="#outline-our-target-api" id="outline-our-target-api"><h2>Outline Our Target API</h2></a>
<p>So, in the first lesson we had <code>WinitState</code> and it just had two public fields.
There's not much there, it's all safe code, and it's not the focus of our
lessons, so that's fine. I mean I guess you could pair up the wrong <code>EventLoop</code>
with the wrong <code>Window</code> or something, but two public fields is good enough.</p>
<p>With <code>gfx-hal</code> it is <em>wildly</em> the opposite situation. We're going to be juggling
a dozen or more things at once, and most of them are <strong>very</strong> unsafe things that
must be handled with extreme care. <code>gfx-hal</code>, at its core, is about directing a
pile of DMA units and a hyper-SIMD co-processor with all safety checks left in
&quot;up to you&quot; mode. That's <em>about</em> as unsafe as it gets. Not only do we want a
<code>HalState</code> type, we want to expose <em>nothing</em> that's inside of it, because it's
all a giant pile of sharp and dangerous things. We want to wrap all that up,
then offer a very small, well curated, semantically meaningful set of operations
that the outside world can access.</p>
<p>Sure sounds like API Design. There's so much that could be said about API
design. Let's keep it short:</p>
<ul>
<li>Always, <em>Always</em>, <strong><em>Always</em></strong> <a href="https://caseymuratori.com/blog_0025">write the usage code
first.</a></li>
</ul>
<p>Even before we know <em>any details about how <code>gfx-hal</code> works</em>, we're going to just
write out how we <em>think</em> we should be able to use it. How we think it's be
easiest to use. Once it's built we will be calling the methods a lot more than
we'll be implementing the methods, so unless we end up with some sort of
performance disaster or impossible requirement we'll keep the exterior simple
even if it means the interior might end up a little more complex.</p>
<p>So what's our <em>usage</em> of the <code>HalState</code> type look like?</p>
<p>There's lots of answers you could have to that question. Really, there are.
Obviously since I'm writing this we're going to be using what I came up with,
but if you think you can get a better solution you should try it out. I'll try
to explain my thinking as best as I can, and hopefully you'll agree with me.</p>
<a class="header" href="#initialization" id="initialization"><h3>Initialization</h3></a>
<p>We already have <code>WinitState</code>, we're going to want <code>HalState</code> too. Clearly the
<code>WinitState</code> can be made before the <code>HalState</code> (since we did it last lesson).</p>
<p>We'll also want to have a <code>LocalState</code>, and that's the grab bag of everything
else in the program. If you're doing a game or a simulation or something that's
your <code>GameState</code> or <code>World</code> or whatever you wanna call the type.</p>
<p>So far the code outline looks like this:</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let mut winit_state = WinitState::default();
  let mut hal_state = HalState::default();
  let mut local_state = LocalState::default();
  // MAIN LOOP
  // CLEANUP
}
</code></pre></pre>
<p>Except, when you think about it, the way that <code>gfx-hal</code> initializes itself
~~probably~~ definitely depends on the <code>Window</code> it's going to draw within. It
can't be totally default with no inputs. We need a <code>HalState</code> initialization
method that takes a <code>Window</code> reference. The default name for any initialization
method in Rust is just <code>new</code>, and I can't think of a better name to use, so
we'll go with that.</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let mut winit_state = WinitState::default();
  let mut hal_state = HalState::new(&amp;winit_state.window);
  let mut local_state = LocalState::default();
  // MAIN LOOP
  // CLEANUP
}
</code></pre></pre>
<p>Also, of course, our local variables might depend on all sorts of things in some
sort of application specific way. That part is up to you.</p>
<a class="header" href="#main-loop" id="main-loop"><h3>Main Loop</h3></a>
<p>Once things are all initialized and ready we go into the &quot;main loop&quot; part of the
program.</p>
<p><strong>Digression:</strong> Video is really just a series of still pictures. You show one after
the other, very quickly, and a human brain interprets the existence of movement
where none &quot;really&quot; exists. Each picture is a &quot;frame&quot;, and how quickly you go
from one frame to the next is the &quot;frames per second&quot; (fps). The minimum fps for
apparent movement is actually quite modest, you only need <a href="https://en.wikipedia.org/wiki/Frame_rate#Human_vision">about
12</a>. More is better of
course, the movement appears smoother the more fps you have. People have been
animating for a long time and there's all sorts of standards by now, but on a
computer you're usually expected to be drawing at about 60fps for &quot;good&quot; quality
animation and 30fps for &quot;I guess that's okay for something made in Unity&quot;
quality animation.</p>
<p><strong>Back to code:</strong> The implication here is that each pass through our main loop
will be one frame of display. We gather up the input for that frame, adjust our
local variables according to the input (eg: in a game you might move the player a tiny
bit, or whatever change), and then render the new state of the world into a frame that
gets shown to the user. Something like this:</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let winit_state = WinitState::default();
  let hal_state = HalState::new(&amp;winit_state.window);
  let mut local_state = LocalState::default();
  loop {
    let inputs = UserInput::poll_events_loop(&amp;mut winit_state.event_loop);
    if inputs.end_requested {
      break;
    }
    local_state.update_from_input(inputs);
    do_the_render(&amp;mut hal_state, &amp;local_state);
  }
  // CLEANUP
}
</code></pre></pre>
<p>This should look fairly familiar after what we did in the first lesson.</p>
<p>You may be wondering why the <code>do_the_render</code> function is taking a <code>&amp;mut HalState</code> as the first argument, instead of having it be a <code>&amp;mut self</code> method on
the <code>HalState</code> type. Well, I'm not sure it's the perfect decision, but we're
going to <em>try</em> and keep our <code>HalState</code> and <code>LocalState</code> as totally separate as
we can.</p>
<ul>
<li>If <code>HalState</code> doesn't know anything about the <code>LocalState</code> then it's a lot
more likely to focus on reusable drawing operations, and we'll be a lot more
likely to have something we can reuse in future situations (including
&quot;practical&quot; situations beyond just this tutorial series).</li>
<li>Similarly, if <code>LocalState</code> doesn't know about <code>HalState</code> then it's easier for
it to focus on the &quot;business logic&quot; without worrying about anything else. We
could even run the <code>LocalState</code> <em>without graphics at all</em> (sometimes called a
&quot;headless&quot; mode), which can be nice if you want to do CI tests, or hook it to
a server people connect to, or any other unexpected use.</li>
</ul>
<p>It can often be <em>tempting</em> to make everything into a method on some type, but
that's an urge we need to resist in this situation.</p>
<a class="header" href="#what-does-do_the_render-actually-do" id="what-does-do_the_render-actually-do"><h3>What Does <code>do_the_render</code> Actually Do?</h3></a>
<p>I cheated a bit there, because I wrote down a call to <code>do_the_render</code> without
actually saying <em>what</em> it's doing on the inside. That's the part we care about
the most! That's how we know what our <code>HalState</code> API needs to look like.</p>
<p>For this lesson, all we do is clear the screen. That sounds simple enough. Later
lessons will add more, but this is our starting point.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn do_the_render(hal: &amp;mut HalState, locals: &amp;LocalState) {
  hal.draw_clear_frame(locals.color());
}
#}</code></pre></pre>
<p>That looks okay at first, but there might be some sort of error that happens
during rendering. Nothing inside <code>do_the_render</code> particularly knows about how to
handle an error, so we'll just pass that back up the stack.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn do_the_render(hal: &amp;mut HalState, locals: &amp;LocalState) -&gt; Result&lt;(), &amp;str&gt; {
  hal.draw_clear_frame(locals.color())
}
#}</code></pre></pre>
<p>And then in <code>main</code> I guess we can just... log the error and quit? It's not ideal
for the program to shut itself down unexpectedly, but we don't really have a
backup strategy at the moment. In a more advanced situation the error might be
from the user trying to switch graphics settings or something, so you could
automatically switch back to the previous settings in that case. Depends on the
program, and the error.</p>
<p>Also, in a full program you'd want to use a proper error enum, but we don't know
what all our possible errors are, so we'll just use string literals for now.</p>
<p>Anyway, now things look more like this:</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let winit_state = WinitState::default();
  let hal_state = HalState::new(&amp;winit_state.window);
  let mut local_state = LocalState::default();
  loop {
    let inputs = UserInput::poll_events_loop(&amp;mut winit_state.events_loop);
    if inputs.end_requested {
      break;
    }
    local_state.update_from_input(inputs);
    if let Err(e) = do_the_render(&amp;mut hal_state, &amp;local_state) {
      error!(&quot;Rendering Error: {:?}&quot;, e);
      break;
    }
  }
  // CLEANUP
}
</code></pre></pre>
<a class="header" href="#cleanup" id="cleanup"><h3>Cleanup</h3></a>
<p>Usually when working with &quot;foreign&quot; data, anything that comes from outside of
Rust, you have to consider the possibility that you'll have to manually do some
cleanup work. <code>gfx-hal</code> is no different. Not only do we need to clean things up
to avoid leaks when we're done, we need to clean up in the exactly correct
order. The backend code can segfault your process just by you not shutting it
down properly.</p>
<p>How do we expose this in our API?</p>
<p>We <em>don't</em>.</p>
<p>I'm not saying that we <em>ignore</em> the subject of cleanup, that would be foolish,
but I am saying that we should keep all of it entirely within the <code>HalState</code>
type. Things are smoothest for the user when they can just let a type drop away
without a care, and we're going to try and allow for such an easy use
experience. Mostly what this means is that we won't want to have any &quot;getter&quot;
methods that let an outside user move out anything that needs to be manually
destroyed later. If they want to check the value of a number or maybe even get a
<code>&amp;mut</code> to some that's fine, but anything that needs to be explicitly cleaned up
we can't let out of our control.</p>
<p>Now we can see our final outline:</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let winit_state = WinitState::default();
  let hal_state = HalState::new(&amp;winit_state.window);
  let mut local_state = LocalState::default();
  loop {
    let inputs = UserInput::poll_events_loop(&amp;mut winit_state.event_loop);
    if inputs.end_requested {
      break;
    }
    local_state.update_from_input(inputs);
    if let Err(e) = do_the_render(&amp;mut hal_state, &amp;local_state) {
      error!(&quot;Rendering Error: {:?}&quot;, e);
      break;
    }
  }
}
</code></pre></pre>
<p>Will we achieve this? Hard to say without trying.</p>
<a class="header" href="#activate-logging-powers" id="activate-logging-powers"><h2>Activate Logging Powers</h2></a>
<p>As you write for <code>gfx-hal</code>, you'll definitely write stuff that's wrong. That's
just how it goes, no shame in it. There's so many rules and details that even
the <code>gfx-rs</code> team members don't know all of it all the time. They look at the
Vulkan spec to verify the rules just like anyone else has to. Thankfully, we can
avoid having too many bugs quietly creep into things by logging what's going on
inside the program and hopefully something will show up in the logs to explain
the problem when there is a problem.</p>
<a class="header" href="#the-log-crate" id="the-log-crate"><h3>The <code>log</code> Crate</h3></a>
<p>If you've ever done logging before you know that usually there's a &quot;logging
facade&quot; which defines a way to write log messages that libraries use, and then
there's an actual logging implementation that a binary will activate at the
start of a process to receive logging messages and deal with them. Rust is no
different.</p>
<p>You use the <a href="https://docs.rs/log">log</a> crate to write a logging message. You use
<a href="https://docs.rs/log/0.4.6/log/#available-logging-implementations">a logging implementation of
choice</a> to
actually process those logging messages. The actual macros for logging are just
like how <code>println!</code> works, but instead of being called <code>println!</code> there's one
macro for each &quot;level&quot; of logging. From most important to least important it
goes: <code>error!</code>, <code>warn!</code>, <code>info!</code>, <code>debug!</code> and <code>trace!</code>. Different logging
implementations let you limit the levels that actually get logged, and the
logging crate has features to restrict what logging messages even get compiled
in (so you can compile out all logging in release mode or whatever). It's a
whole huge thing you can really dig through if you want.</p>
<p>I don't want to. I want to not have any fuss. So we'll use
<a href="https://crates.io/crates/simple_logger">simple_logger</a> which is exactly as easy
as it sounds. You write one line, once, and then logging messages just go to
<code>stdout</code> or <code>stderr</code>.</p>
<p>First we add things to our <code>Cargo.toml</code> file.</p>
<pre><code class="language-toml">[dependencies]
log = &quot;0.4.0&quot;
simple_logger = &quot;1.0&quot;
winit = &quot;0.18&quot;
</code></pre>
<p>And then we turn on the <code>simple_logger</code> in main before we do anything else:</p>
<pre><pre class="playpen"><code class="language-rust">fn main() {
  simple_logger::init().unwrap();
  // ...
</code></pre></pre>
<p>And now we'll see anything that someone wanted to log. If we want to do our own
logging that's easy too:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[allow(unused_imports)]
use log::{error, warn, info, debug, trace};
#}</code></pre></pre>
<a class="header" href="#lunarg-vulkan-sdk" id="lunarg-vulkan-sdk"><h3>LunarG Vulkan SDK</h3></a>
<p>Next you'll also want some tools that <em>aren't</em> strictly Rust related (shocking,
I know).</p>
<p>The <a href="https://vulkan.lunarg.com/sdk/home">LunarG Vulkan SDK</a> is a free set of
tools for all major operating systems. Once you install the SDK, if you're using
the <code>gfx-backend-vulkan</code> crate as your <code>gfx-hal</code> backend it'll log any
validation errors when <code>debug_assertions</code> are on. You don't need to do any
special setup, it just conveniently happens for you.</p>
<p>Unfortunately, when testing with other backends you're much more &quot;on your own&quot;,
but some help is still better than zero help. You can set up Metal validation,
and I'll update here just as soon as one of the gfx team members with a mac
updates me on what to say.</p>
<a class="header" href="#adding-in-gfx-hal-and-a-backend" id="adding-in-gfx-hal-and-a-backend"><h2>Adding In <code>gfx-hal</code> And A Backend</h2></a>
<p>Adding <code>gfx-hal</code> to our <code>Cargo.toml</code> file comes in two parts. There's <code>gfx-hal</code>,
and also we need an actual &quot;backend&quot; that provides a specific implementation of
the types and operations that <code>gfx-hal</code> defines.</p>
<a class="header" href="#configuring-cargo" id="configuring-cargo"><h3>Configuring Cargo</h3></a>
<p>We want to keep the backend selection as easy to swap as possible. Normally this
is done at compile time, since there's only about one good backend per OS
anyway, and it keeps things simpler than trying to select a backend at startup.
The standard idiom for how to do this looks something like:</p>
<pre><code class="language-toml">[features]
default = []
metal = [&quot;gfx-backend-metal&quot;]
dx12 = [&quot;gfx-backend-dx12&quot;]
vulkan = [&quot;gfx-backend-vulkan&quot;]

[dependencies]
log = &quot;0.4.0&quot;
simple_logger = &quot;1.0&quot;
winit = &quot;0.18&quot;
gfx-hal = &quot;0.1&quot;
arrayvec = &quot;0.4&quot;

[dependencies.gfx-backend-vulkan]
version = &quot;0.1&quot;
optional = true

[target.'cfg(target_os = &quot;macos&quot;)'.dependencies.gfx-backend-metal]
version = &quot;0.1&quot;
optional = true

[target.'cfg(windows)'.dependencies.gfx-backend-dx12]
version = &quot;0.1&quot;
optional = true
</code></pre>
<p>If you want the Rust Language Server (RLS) to play nice with the various
optional features you must tell it which one to use for its compilations. You
could specify a default feature, but that's not quite elegant. If you're using
VS Code with the RLS plugin you can instead make a <code>.vscode/settings.json</code> file
in your project folder, and then in there place a setting for the feature you
want it to use for RLS runs. Something like this:</p>
<pre><code class="language-json">{
  &quot;rust.features&quot;: [
    &quot;dx12&quot;
  ]
}
</code></pre>
<p>If you're using RLS with some editor besides VS Code I'm afraid I don't know the
details of how you tell RLS to use a particular feature, but you probably can.
Consult your plugin docs, and such.</p>
<a class="header" href="#configuring-the-code" id="configuring-the-code"><h3>Configuring The Code</h3></a>
<p>Over inside our main file we won't actually be importing too much from the
backends, but we'll place some conditional <code>use</code> statements so that they're
always aliased to the same name, regardless of what one we're using.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[cfg(feature = &quot;dx12&quot;)]
use gfx_backend_dx12 as back;
#[cfg(feature = &quot;metal&quot;)]
use gfx_backend_metal as back;
#[cfg(feature = &quot;vulkan&quot;)]
use gfx_backend_vulkan as back;
#}</code></pre></pre>
<a class="header" href="#any-other-backend-options" id="any-other-backend-options"><h3>Any Other Backend Options?</h3></a>
<p>There <em>are</em> other backend options that we haven't considered:</p>
<ul>
<li><a href="https://crates.io/crates/gfx-backend-empty">gfx-backend-empty</a> does nothing
but provide the required implementations as empty structs and do-nothing
methods and similar. It's mostly used in the rustdoc examples for <code>gfx-hal</code>,
so that they can check that doctests compile properly. You might also use this
with RLS I guess, but since you'll also need a real backend compiled to run
any code, you might as well make RLS use your real backend.</li>
<li><a href="https://crates.io/crates/gfx-backend-gl">gfx-backend-gl</a> lets you target
OpenGL 2.1+ and OpenGL ES2+. You'd probably use this if you wanted to run
inside a webpage, or perhaps on a Raspberry Pi (which has OpenGL ES2 drivers,
but not Vulkan), or anything else where you can't pick one of the &quot;main&quot;
options. Unfortunately, the GL backend is actually a little busted at the
moment. The biggest snag is that webpages and desktop apps have rather
different control flow, so it's hard to come up with a unified API. Work is
being done, and hopefully soon I'll be able to recommend the GL backend.</li>
</ul>
<a class="header" href="#also-arrayvec" id="also-arrayvec"><h3>Also <code>arrayvec</code></h3></a>
<p>As you might have noticed, we're going to be using
<a href="https://docs.rs/arrayvec">arrayvec</a> later on for the <code>ArrayVec</code> type. I don't
want to come back to <code>Cargo.toml</code> later, so we can just mention it now.</p>
<p><code>ArrayVec</code> works basically just like <code>Vec</code> but it's backed by an array on the
stack, not a data blob on the heap, so it can't resize, but it also doesn't need
a heap allocation to construct. We'll be using it during our draw code so that
we can call a few critical functions without doing a heap allocation each frame.
The functions in question have some weird generic bounds that work out for <code>Vec</code>
and <code>ArrayVec</code> and similar, but not for arrays themselves. Generics just be like
that sometimes.</p>
<a class="header" href="#implementing-draw_clear_frame" id="implementing-draw_clear_frame"><h1>Implementing <code>draw_clear_frame</code></h1></a>
<p>You might think that we'd start by learning how to initialize things, but
actually our core goal is clearing the screen. Anything else that we do,
including the initialization, is <em>only in service to that goal</em>. So first we'll
focus on our core goal, then we'll see what we need for that, and then we'll see
what we need for <em>that</em>, until eventually we stop needing to have already done
something else.</p>
<p>We'll be filling in this method:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl HalState {
  pub fn draw_clear_frame(&amp;mut self, color: [f32; 4]) -&gt; Result&lt;(), &amp;'static str&gt; {
    unimplemented!()
  }
}
#}</code></pre></pre>
<a class="header" href="#commandqueue" id="commandqueue"><h2>CommandQueue</h2></a>
<p>The heart of it all is that we want to be able to safely call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/queue/struct.CommandQueue.html#method.submit">CommandQueue::submit</a>,
which submits a list of work which we define in a <code>CommandBuffer</code> to the GPU (in
this case just clearing the image), and then we call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/trait.Swapchain.html#method.present">Swapchain::present</a>,
which instructs the GPU to wait until the CommandQueue work is done and
&quot;present&quot; the completed image into the Swapchain.</p>
<p><em>Exactly</em> what happens at that point depends on how you've configured the
Swapchain, which we'll talk about in the initialization section. The important
part to remember here is that <code>Swapchain::present</code> is effectively a
<strong>non-blocking</strong> call. If you're used to using OpenGL you might expect <code>present</code>
to be the point where your loop halts until Vsync, but with <code>gfx-hal</code> anything
that makes the CPU wait on the GPU is controlled via &quot;Fences&quot; (which we'll see
in a moment), and that doesn't include <code>present</code>.</p>
<a class="header" href="#submit" id="submit"><h3><code>submit</code></h3></a>
<p>The actual type of the <code>submit</code> method is <em>super generic</em> which means that it
reads like a pile of space runes:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub unsafe fn submit&lt;'a, T, Ic, S, Iw, Is&gt;(
    &amp;mut self, 
    submission: Submission&lt;Ic, Iw, Is&gt;, 
    fence: Option&lt;&amp;B::Fence&gt;
)
where
    T: 'a + Submittable&lt;B, C, Primary&gt;,
    Ic: IntoIterator&lt;Item = &amp;'a T&gt;,
    S: 'a + Borrow&lt;B::Semaphore&gt;,
    Iw: IntoIterator&lt;Item = (&amp;'a S, PipelineStage)&gt;,
    Is: IntoIterator&lt;Item = &amp;'a S&gt;,
#}</code></pre></pre>
<p>Gross, right? Let's cut out those generics and look again:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub unsafe fn submit(&amp;mut self, submission: Submission, fence: Option&lt;&amp;B::Fence&gt;)
#}</code></pre></pre>
<p>Okay that's <em>way</em> easier to look at and understand. It's just a rustified
version of
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkQueueSubmit.html">vkQueueSubmit</a>.
Which doesn't mean anything to you right now because we're just starting, but
like I said at the top: if the <code>gfx-hal</code> docs aren't clear on their semantics,
you can usually assume that Vulkan semantics apply.</p>
<ul>
<li>We <code>submit</code> a <code>Submission</code> into the <code>CommandQueue</code>. Instead of giving a count
and a pointer to an array of &quot;VkSubmitInfo&quot;, we give a single <code>Submission</code>,
which is itself composed of <code>IntoIterator</code> things that I assume get iterated
over. <em>Unfortunately</em>, since each backend has to handle the info in slightly
different ways, we have to pay for that cross-platform benefit by things
sometimes being a little less clear on our end.</li>
<li>We optionally give a &quot;fence&quot; which gets &quot;signalled&quot; once all of the submitted
command buffers have completed execution. We'll talk about that in a moment.</li>
</ul>
<a class="header" href="#present" id="present"><h3><code>present</code></h3></a>
<p>The <code>present</code> method looks like this</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
unsafe fn present&lt;'a, C, S, Iw&gt;(
    &amp;'a self, 
    present_queue: &amp;mut CommandQueue&lt;B, C&gt;, 
    image_index: SwapImageIndex, 
    wait_semaphores: Iw
) -&gt; Result&lt;(), ()&gt;
where
    Self: 'a + Sized + Borrow&lt;B::Swapchain&gt;,
    C: Capability,
    S: 'a + Borrow&lt;B::Semaphore&gt;,
    Iw: IntoIterator&lt;Item = &amp;'a S&gt;, 
#}</code></pre></pre>
<p>And if we cut out the extra stuff:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
unsafe fn present(
    &amp;self, 
    present_queue: &amp;mut CommandQueue&lt;B, C&gt;,
    image_index: SwapImageIndex,
    wait_semaphores: Iw) -&gt; Result&lt;(), ()&gt;
#}</code></pre></pre>
<p>So <code>present</code> takes a <code>&amp;mut</code> to our <code>CommandQueue</code>, a target index within the
Swapchain to present to, and a semaphore to wait on before actually presenting
the image. This works like
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkQueuePresentKHR.html">vkQueuePresentKHR</a>.
When we call <code>submit</code>, one of the Submission elements is going to be a semaphore
to signal when the rendering is done. When we call <code>present</code> we give it that
same semaphore to wait on before presenting the image, so that the user only
sees complete images.</p>
<a class="header" href="#fences" id="fences"><h3>Fences?</h3></a>
<p>A <a href="https://en.wikipedia.org/wiki/Memory_barrier">fence</a> (aka
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkFence.html">VkFence</a>)
is one of the two synchronization primitives we'll be dealing with. It's
basically just a bool, it can &quot;signaled&quot; or &quot;unsignaled&quot;. You can share a fence
between threads and everyone always sees the current state, so it's <em>like</em>
having an
<a href="https://doc.rust-lang.org/core/sync/atomic/struct.AtomicBool.html">AtomicBool</a>.</p>
<p>Fences are for CPU to GPU synchronization. The CPU can wait on a fence, and the
GPU will signal the fence when it's done whatever it's supposed to have done.</p>
<a class="header" href="#semaphores" id="semaphores"><h3>Semaphores?</h3></a>
<p>A <a href="https://en.wikipedia.org/wiki/Semaphore_(programming)">semaphore</a> (aka
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkSemaphore.html">VkSemaphore</a>)
is the other synchronization primitive that we deal with. In some contexts (eg:
<code>winapi</code>) a semaphore can be any integer value, but in a Vulkan / <code>gfx-hal</code>
context they can only be &quot;signaled&quot; or &quot;unsignaled&quot;.</p>
<p>The big difference between a fence and a semaphore is that semaphores are for
GPU to GPU synchronization. When once part of a graphics pipeline (such as
presentation to the swapchain) depends on another part of the pipeline (such as
command buffer processing), then you describe that dependency to the GPU using a
semaphore.</p>
<a class="header" href="#submission" id="submission"><h2>Submission</h2></a>
<p>Supposing that we already have a <code>CommandQueue</code> from somewhere, we need to give
it a <code>Submission</code> of what to do.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct Submission&lt;Ic, Iw, Is&gt; {
    pub command_buffers: Ic,
    pub wait_semaphores: Iw,
    pub signal_semaphores: Is,
}
#}</code></pre></pre>
<p>Hmm, but the <code>submit</code> method had extra bounds in there:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  T: 'a + Submittable&lt;B, C, Primary&gt;,
  Ic: IntoIterator&lt;Item = &amp;'a T&gt;,
  S: 'a + Borrow&lt;B::Semaphore&gt;,
  Iw: IntoIterator&lt;Item = (&amp;'a S, PipelineStage)&gt;,
  Is: IntoIterator&lt;Item = &amp;'a S&gt;,
#}</code></pre></pre>
<p>So if we put that together, and allow ourselves to use some slightly fake Rust
syntax for just a moment, we need to build this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct Submission {
    pub command_buffers: IntoIterator&lt;Item = &amp;'a Submittable&lt;B, C, Primary&gt;&gt;,
    pub wait_semaphores: IntoIterator&lt;Item = (&amp;'a Borrow&lt;B::Semaphore&gt;, PipelineStage)&gt;,
    pub signal_semaphores: IntoIterator&lt;Item = &amp;'a Borrow&lt;B::Semaphore&gt;&gt;,
}
#}</code></pre></pre>
<ul>
<li><code>command_buffers</code> is our
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/trait.Submittable.html">Submittable</a>
things, which are <code>Borrow&lt;B::CommandBuffer&gt;</code>, so we can think of that as being
<em>sorta</em> like <code>&amp;[CommandBuffer]</code>.</li>
<li><code>wait_semaphores</code> gives the semaphores that this submission has to <em>wait on
before it starts</em>. Each semaphore is paired with a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.PipelineStage.html">PipelineStage</a>,
allowing your submission to wait for a stage, do some work at that stage, wait
for another stage, do some more work at the new stage, and so on.</li>
<li><code>signal_semaphores</code> gives a list of semaphores that this submission <em>will
signal once it completes</em>. It doesn't say, but I'm guessing that all the
semaphores just get signaled at once at the end of the Submission.</li>
</ul>
<p>All of this is basically what you find in the
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkSubmitInfo.html">VkSubmitInfo</a>
struct.</p>
<a class="header" href="#arrayvec-submissions" id="arrayvec-submissions"><h3>ArrayVec Submissions</h3></a>
<p>Remember when I said that we'd use the ArrayVec to avoid allocations per frame?
That's this part. It's simple really. Instead of writing something like:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let command_buffers = vec![the_command_buffer];
#}</code></pre></pre>
<p>You write something like</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let command_buffers: ArrayVec&lt;[_; 1]&gt; = [the_command_buffer].into();
#}</code></pre></pre>
<a class="header" href="#submitting-and-presenting" id="submitting-and-presenting"><h2>Submitting And Presenting</h2></a>
<p>So far it sounds like we want something like this</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn draw_clear_frame(&amp;mut self, color: [f32; 4]) -&gt; Result&lt;(), &amp;str&gt; {
    // SETUP FOR THIS FRAME
    // ...

    // RECORD SOME COMMANDS
    // ...

    // SUBMISSION
    let command_buffers: ArrayVec&lt;[_; 1]&gt; = [the_command_buffer].into();
    let wait_semaphores: ArrayVec&lt;[_; 1]&gt; = [(image_available, PipelineStage::COLOR_ATTACHMENT_OUTPUT)].into();
    let signal_semaphores: ArrayVec&lt;[_; 1]&gt; = [render_finished].into();
    let present_wait_semaphores: ArrayVec&lt;[_; 1]&gt; = [render_finished].into();
    let submission = Submission {
      command_buffers,
      wait_semaphores,
      signal_semaphores,
    };
    unsafe {
      the_command_queue.submit(submission, Some(flight_fence));
      the_swapchain.present(&amp;mut the_command_queue, i_u32, present_wait_semaphores)
        .map_err(|_|&quot;Failed to present into the swapchain!&quot;)
    }
  }
#}</code></pre></pre>
<p>For all my fuss about things being so &quot;manual and on your own&quot;, that seems
fairly reasonable so far.</p>
<a class="header" href="#recording-commands" id="recording-commands"><h2>Recording Commands</h2></a>
<p>So we need to fill up a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.CommandBuffer.html">CommandBuffer</a>
with the operations that we want to have happen during the draw process.</p>
<p>All we want to do is clear the screen, that's got to be easy enough.</p>
<p>Well, it turns out that a CommandBuffer isn't totally free to make, so we want
to make them ahead of time and then pick out and use a particular command buffer
each frame. That's easy, we can change our Submission declaration very easily.
Also, before it's part of the Submission, we want to grab a <code>&amp;mut</code> to the
particular command buffer and write to it. That calls for the ever-lovable
&quot;inner scope&quot; so that the <code>&amp;mut</code> goes away and we can take a <code>&amp;</code> to our buffer
instead. Thankfully (I guess), recording to a CommandBuffer is all unsafe, so
we can kill two birds with one stone.</p>
<p>A CommandBuffer is actually wrapping around a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/trait.RawCommandBuffer.html">RawCommandBuffer</a>
with some metadata for bonus type safety. All the real documentation is given on
the RawCommandBuffer type. Unfortunately, the methods aren't <em>exactly</em> the same
name. Hopefully that's fixed in 0.2.</p>
<p>We start by calling <code>begin</code></p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub unsafe fn begin(&amp;mut self, allow_pending_resubmit: bool)
#}</code></pre></pre>
<p>To begin the buffer overall. Then we start a particular render pass with</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub unsafe fn begin_render_pass_inline&lt;T&gt;(
    &amp;mut self, 
    render_pass: &amp;B::RenderPass, 
    frame_buffer: &amp;B::Framebuffer, 
    render_area: Rect, 
    clear_values: T
) -&gt; RenderPassInlineEncoder&lt;B&gt;
where
    T: IntoIterator,
    T::Item: Borrow&lt;ClearValue&gt;, 
#}</code></pre></pre>
<p>Which records a render pass with no secondary command buffers.</p>
<p>Next we... immediately finish the render pass. The RenderPass struct will define
how to deal with the color buffer, including the clear effect, and the
ClearValue just picks what color to clear to.</p>
<p>Note: images can have more than just color data, so we have to put the &quot;clear to
this color&quot; part into an iterator. In more advanced code you'd specify the clear
color and also the clear depth value (they're both part of the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/enum.ClearValue.html">ClearValue</a>
enum). We're not using the depth buffer at the moment, so it's just a 1 element
array.</p>
<p>After that, we're already done.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn draw_clear_frame(&amp;mut self, color: [f32; 4]) -&gt; Result&lt;(), &amp;str&gt; {
    // SETUP FOR THIS FRAME
    // ...

    // RECORD SOME COMMANDS
    {
      let buffer = &amp;mut self.command_buffers[i_usize];
      let clear_values = [ClearValue::Color(ClearColor::Float(color))];
      buffer.begin(false);
      buffer.begin_render_pass_inline(
        &amp;self.render_pass,
        &amp;self.swapchain_framebuffers[i_usize],
        self.render_area,
        clear_values.iter(),
      );
      buffer.finish();
    }

    // SUBMISSION
    // ...
  }
#}</code></pre></pre>
<a class="header" href="#frame-setup" id="frame-setup"><h2>Frame Setup</h2></a>
<p>What's left to do as setup? Well, the GPU can be doing more than one of these
buffer things at once. When you've got several images all going on it's called
having frames &quot;in flight&quot;. At the start of each frame of work, we have to pick
the right fences and semaphores and all that for the current frame that we're
going to be working with. The simplest way is to just keep them in parallel
vectors and go through them like a ring buffer.</p>
<p>However, even once we've picked our current sync primitives, we have to
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkAcquireNextImageKHR.html">acquire</a>
a particular image to work with out of the swapchain. We don't move the whole
image out of the swapchain, we just get an index to target later with the
<code>present</code> method.</p>
<a class="header" href="#final-draw_clear_frame-code" id="final-draw_clear_frame-code"><h2>Final <code>draw_clear_frame</code> Code</h2></a>
<p>So now we put it all together, with the signaling in big caps to help make it
clear.</p>
<ul>
<li>Grab an image index that will SIGNAL the <code>image_available</code> semaphore once it's
fully ready.</li>
<li>Get our sync primitives out of our ring buffers</li>
<li>WAIT on the <code>flight_fence</code> for this image index to know we're in the clear to
use this position of our ring buffer.</li>
<li>Reset that fence so we can pass it as part of our submission later.</li>
<li>Record our command buffer while we're waiting for that.</li>
<li>Submit a command buffer to WAIT on <code>image_available</code> and SIGNAL both
<code>render_finished</code> and <code>flight_fence</code>.</li>
<li>Present the results into the swapchain after a WAIT on <code>render_finished</code></li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  /// Draw a frame that's just cleared to the color specified.
  pub fn draw_clear_frame(&amp;mut self, color: [f32; 4]) -&gt; Result&lt;(), &amp;str&gt; {
    // SETUP FOR THIS FRAME
    let image_available = &amp;self.image_available_semaphores[self.current_frame];
    let render_finished = &amp;self.render_finished_semaphores[self.current_frame];
    // Advance the frame _before_ we start using the `?` operator
    self.current_frame = (self.current_frame + 1) % self.frames_in_flight;

    let (i_u32, i_usize) = unsafe {
      let image_index = self
        .swapchain
        .acquire_image(core::u64::MAX, FrameSync::Semaphore(image_available))
        .map_err(|_| &quot;Couldn't acquire an image from the swapchain!&quot;)?;
      (image_index, image_index as usize)
    };

    let flight_fence = &amp;self.in_flight_fences[i_usize];
    unsafe {
      self
        .device
        .wait_for_fence(flight_fence, core::u64::MAX)
        .map_err(|_| &quot;Failed to wait on the fence!&quot;)?;
      self
        .device
        .reset_fence(flight_fence)
        .map_err(|_| &quot;Couldn't reset the fence!&quot;)?;
    }

    // RECORD COMMANDS
    unsafe {
      let buffer = &amp;mut self.command_buffers[i_usize];
      let clear_values = [ClearValue::Color(ClearColor::Float(color))];
      buffer.begin(false);
      buffer.begin_render_pass_inline(
        &amp;self.render_pass,
        &amp;self.framebuffers[i_usize],
        self.render_area,
        clear_values.iter(),
      );
      buffer.finish();
    }

    // SUBMISSION AND PRESENT
    let command_buffers = &amp;self.command_buffers[i_usize..=i_usize];
    let wait_semaphores: ArrayVec&lt;[_; 1]&gt; = [(image_available, PipelineStage::COLOR_ATTACHMENT_OUTPUT)].into();
    let signal_semaphores: ArrayVec&lt;[_; 1]&gt; = [render_finished].into();
    // yes, you have to write it twice like this. yes, it's silly.
    let present_wait_semaphores: ArrayVec&lt;[_; 1]&gt; = [render_finished].into();
    let submission = Submission {
      command_buffers,
      wait_semaphores,
      signal_semaphores,
    };
    let the_command_queue = &amp;mut self.queue_group.queues[0];
    unsafe {
      the_command_queue.submit(submission, Some(flight_fence));
      self
        .swapchain
        .present(the_command_queue, i_u32, present_wait_semaphores)
        .map_err(|_| &quot;Failed to present into the swapchain!&quot;)
    }
  }
#}</code></pre></pre>
<a class="header" href="#initializing-halstate" id="initializing-halstate"><h1>Initializing <code>HalState</code></h1></a>
<p>So for our <code>draw_clear_frame</code> method to work it expects that we have many things
on hand as part of <code>HalState</code>. Listing them in the order that they're used:</p>
<ul>
<li>fences (requires a Device + frames_in_flight)</li>
<li>semaphores (requires a Device + frames_in_flight)</li>
<li>current_frame (just starts at 0)</li>
<li>frames_in_flight (comes from the Swapchain)</li>
<li>device (requires an Adapter)</li>
<li>swapchain (requires a Surface+Adapter+Device)</li>
<li>command_buffers (requires a CommandPool)</li>
<li>render_pass (requires a Device)</li>
<li>swapchain_framebuffers (requires ImageView values)</li>
<li>render_area (comes from the Swapchain)</li>
<li>queue_group (requires an Adapter)</li>
</ul>
<p>But, as you can probably guess, that's <em>not</em> the order that they're initialized.
You should have noticed that there's some things on there we haven't even
discussed yet, which also have their requirements. In no particular order:</p>
<ul>
<li>image_views (requires a Device+Backbuffer)</li>
<li>backbuffer (requires Surface+Adapter)</li>
<li>Command Pool (requires Device)</li>
<li>Surface (requires an Instance+Window)</li>
<li>Adapter (requires an Instance)</li>
<li>Instance</li>
</ul>
<p>Now we just re-order it all so that nothing is built before the parts it depends
on. We'll even add some names to the build phases to help group it mentally:</p>
<ul>
<li>Top Level Stuff
<ul>
<li>Instance</li>
<li>Surface (requires an Instance+Window)</li>
<li>Adapter (requires an Instance)</li>
<li>queue_group (requires an Adapter)</li>
<li>device (requires an Adapter)</li>
</ul>
</li>
<li>The GPU Swapchain
<ul>
<li>swapchain (requires a Surface+Adapter+Device)</li>
<li>backbuffer (requires Surface+Adapter)</li>
<li>render_area (comes from the Swapchain)</li>
<li>frames_in_flight (comes from the Swapchain)</li>
<li>fences (requires a Device + frames_in_flight)</li>
<li>semaphores (requires a Device + frames_in_flight)</li>
</ul>
</li>
<li>RenderPass
<ul>
<li>render_pass (requires a Device + Swapchain format)</li>
</ul>
</li>
<li>Targets For Rendering
<ul>
<li>image_views (requires a Device+Backbuffer)</li>
<li>framebuffers (requires ImageView values)</li>
</ul>
</li>
<li>Command Issuing
<ul>
<li>Command Pool (requires Device)</li>
<li>command_buffers (requires a CommandPool + Swapchain)</li>
</ul>
</li>
<li>Misc
<ul>
<li>current_frame (just starts at 0)</li>
</ul>
</li>
</ul>
<p>Notice that after the initial top level stuff you can do the other general
phases in about any order you want. You use the parts that they each build all
at once during rendering, but they can be constructed and configured
independently.</p>
<p>Also, there's many other things that a person might initialize in <code>gfx-hal</code>.
That's why we looked at how to submit the command we wanted first, so we don't
go wandering off initializing all sorts of things we don't end up needing.</p>
<p>And I guess we can just copy this outline as our outline for the explanation of
each step too. Nice when things work out like that.</p>
<a class="header" href="#top-level-stuff" id="top-level-stuff"><h2>Top Level Stuff</h2></a>
<p>Alright, so we're going to initialize a <code>HalState</code>. Well, just as with drawing,
there might be any number of problems that come up during this many step
process.</p>
<p>So the method we're filling in looks like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl HalState {
  pub fn new(window: &amp;Window) -&gt; Result&lt;Self, &amp;'static str&gt; {
    unimplemented!()
  }
}
#}</code></pre></pre>
<a class="header" href="#instance" id="instance"><h3>Instance</h3></a>
<p>An <code>Instance</code> is a backend specific black box. It's the handle that you hold to
prove that you've activated the backend API, and when it drops the backend tries
to close down, so you have to hold on to it at the very end and let it go last.</p>
<p>For something so important, you'd imagine that there's a dedicated trait for
them, and <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/trait.Instance.html">you'd be
right</a>. You'd also
expect that the trait includes a way to create them instead of leaving it up to
convention, and you'd be wrong.</p>
<p>Still, it's very easy. We give an instance name and a version and the details of
how that's used depend on the backend.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let instance = back::Instance::create(WINDOW_NAME, 1);
#}</code></pre></pre>
<a class="header" href="#surface" id="surface"><h3>Surface</h3></a>
<p>The <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/trait.Surface.html">Surface</a>
is an abstraction of how the <code>Window</code> (from <code>winit</code>) and your <code>Instance</code> (from
your <code>gfx-backend-whatever</code>) will actually be able to interact and show
something on the screen.</p>
<p>Similar to the Instance, it's very important, but also totally boring to create:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut surface = instance.create_surface(window);
#}</code></pre></pre>
<p>As far as I can tell, it has no special cleanup operation. It probably shouldn't
outlive the Instance or the Window, but that's just a best guess.</p>
<a class="header" href="#adapter" id="adapter"><h3>Adapter</h3></a>
<p>The <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/adapter/struct.Adapter.html">Adapter</a>
is... <em>something</em> that supports the usage of the API you've got an Instance for.
It's <em>probably</em> a hardware GPU, but it could technically be a purely software
implementation.</p>
<p>We actually don't <em>make</em> an Adapter, we pick one that already exists. Once we've
picked one, we haven't even made any changes to the system. Picking an Adapter
is like picking a IP address to connect to. It's one step to select the IP
address you want, and then another step to actually open a connection to that IP
address (which we'll do in a moment).</p>
<p>We have to call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/trait.Instance.html#tymethod.enumerate_adapters">Instance::enumerate_adapters</a>,
which gives a vector of things to pick from. Our criteria here is based on the <code>queue_families: Vec&lt;B::QueueFamily&gt;</code> that each Adapter has. We want a QueueFamily</p>
<ol>
<li>That supports Graphics</li>
<li>That our Surface supports</li>
</ol>
<p>It's considered a bug in <code>gfx-hal</code> if any backend ever gives a QueueFamily that
has 0 max queues, so we don't need to bother checking that.</p>
<p>Since we're going over a vector, we can use some fancy Iterator stuff</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let adapter = instance
  .enumerate_adapters()
  .into_iter()
  .find(|a| {
    a.queue_families
      .iter()
      .any(|qf| qf.supports_graphics() &amp;&amp; surface.supports_queue_family(qf))
  })
  .ok_or(&quot;Couldn't find a graphical Adapter!&quot;)?;
#}</code></pre></pre>
<a class="header" href="#device-and-queuegroup" id="device-and-queuegroup"><h3>Device and QueueGroup</h3></a>
<p>This is a &quot;two things in one step&quot; situation. From here on out we'll be doing a
lot of steps where we have an inner scope do to some setup, then we pass the
important data back up to the <code>new</code> method's primary scope. It's a Rust take on
what you might call &quot;<a href="http://number-none.com/blow/blog/programming/2014/09/26/carmack-on-inlined-code.html">Style
C</a>&quot;
coding. We're just going to let the method get super long, with every single
step being as plan and obvious as possible, to see the full horror of what we're
doing.</p>
<p>The actual process here is easy enough to understand.</p>
<ul>
<li>Every Adapter has a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/adapter/trait.PhysicalDevice.html">PhysicalDevice</a>,
and you call <code>open</code> to actually &quot;connect&quot; your program to that PhysicalDevice.
This (hopefully) gives a Gpu. You have to pass in a list of QueueFamily values
with a priority for each one.</li>
<li>A <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/struct.Gpu.html">Gpu</a> is a pairing of
a <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html">Device</a>
(which is a logical device, but you use it so often they wanted to make the
name shorter) and a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/queue/family/struct.Queues.html">Queues</a>
value, which is a container for the different queues that we can now use.</li>
<li>Once we've got the Queues, we pull out a particular
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/queue/family/struct.QueueGroup.html">QueueGroup</a>
as well, which we use much later to build the CommandPool, and also it's how
we <code>submit</code> our written CommandBuffer values of course.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let (device, queue_group) = {
  let queue_family = adapter
    .queue_families
    .iter()
    .find(|qf| qf.supports_graphics() &amp;&amp; surface.supports_queue_family(qf))
    .ok_or(&quot;Couldn't find a QueueFamily with graphics!&quot;)?;
  let Gpu { device, mut queues } = unsafe {
    adapter
      .physical_device
      .open(&amp;[(&amp;queue_family, &amp;[1.0; 1])])
      .map_err(|_| &quot;Couldn't open the PhysicalDevice!&quot;)?
  };
  let queue_group = queues
    .take::&lt;Graphics&gt;(queue_family.id())
    .ok_or(&quot;Couldn't take ownership of the QueueGroup!&quot;)?;
  let _ = if queue_group.queues.len() &gt; 0 {
    Ok(())
  } else {
    Err(&quot;The QueueGroup did not have any CommandQueues available!&quot;)
  }?;
  (device, queue_group)
};
#}</code></pre></pre>
<p>Now, I can already <em>hear</em> you trying to tell me that we shouldn't repeat the
<code>find</code> operation, but because of how the lifetimes work out we can't hang on to
a <code>queue_family</code> and also use our Adapter normally because the QueueFamily
reference keeps the Adapter borrowed the whole time, and it's a mess. <strong>Even
if</strong> we didn't care about lifetime issues the two <code>find</code> operations are actually
different because one works on <code>&amp;</code> and the other is working on <code>&amp;&amp;</code> and we just
don't happen to <em>see</em> the difference because of <a href="https://doc.rust-lang.org/book/ch15-02-deref.html?highlight=deref#implicit-deref-coercions-with-functions-and-methods">Deref
coercion</a>.
It's fine to just do it twice, don't worry too much about it, really.</p>
<a class="header" href="#the-gpu-swapchain" id="the-gpu-swapchain"><h2>The GPU Swapchain</h2></a>
<p>The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/trait.Swapchain.html">Swapchain</a>
is like a collection of images on the GPU. They've got a linear index, like an
array or vector, and the GPU jumps around the Swapchain showing one image at any
given moment. This is where things start to get more configurable.</p>
<a class="header" href="#swapchain-and-friends" id="swapchain-and-friends"><h3>Swapchain and friends</h3></a>
<p>The basic idea is that you call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/trait.Surface.html#tymethod.compatibility">Surface::compatibility</a>
to get information about what sort of
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/struct.SwapchainConfig.html">SwapchainConfig</a>
you're allowed to build, and then you call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_swapchain">Device::create_swapchain</a>
with your Surface and the config you want. This gives you a Swapchain, which has
methods for controlling the GPU's swapchain, as well as a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/enum.Backbuffer.html">Backbuffer</a>,
which holds the handles to particular Image data. We use an Image to make an
ImageView, and we use that to make a Framebuffer, and <em>that's</em> what we're
manipulating with the CommandBuffer.</p>
<p>So what SwapchainConfig do we try to build? Well, the best one we can.
Unfortunately, this varies by quite a bit. Even if I just switch from the Vulkan
backend to the DX12 backend on a single machine the system ends up giving me
different compatibility results.</p>
<p>The SwapchainConfig type does have a <code>from_caps</code> method to try and help you
build a value, but it's shockingly error prone, because not all of the
capabilities of your Surface are actually contained in the SurfaceCapabilities
struct! The <code>Surface::compatibility</code> also gives you Format, PresentMode, and
CompositeAlpha that you have to pay attention to, which <code>from_caps</code> totally
ignores. We're not going to use that, we'll just write out a struct literal
ourselves. SwapchainConfig looks like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct SwapchainConfig {
  pub present_mode: PresentMode,
  pub composite_alpha: CompositeAlpha,
  pub format: Format,
  pub extent: Extent2D,
  pub image_count: SwapImageIndex,
  pub image_layers: Layer,
  pub image_usage: Usage,
}
#}</code></pre></pre>
<ul>
<li><code>present_mode</code>:
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/enum.PresentMode.html">PresentMode</a>
gives us access to that sweet, sweet Vsync. Well, if it's available.
<ul>
<li>We would most like to have <code>Mailbox</code>, which lets us do &quot;triple buffering&quot;.
That's where you have at least 3 images, and one is &quot;being shown&quot; and then
you render frames as quick as you can to different swapchain slots, always
keeping the most recent complete frame ready. This gives the least amount of
latency between user input and what they see on the screen.</li>
<li>We would accept <code>Fifo</code>, where frames are shown in the exact order that they're
created. If you do this with 2 images you can have &quot;double buffering&quot; (where
you show one frame and work on the next), but if you're using this with more
than two images then it causes excess latency between input and display.</li>
<li>We would begrudgingly accept <code>Relaxed</code> if we had to use it, which &quot;usually&quot;
has vsync but not always. I suppose this is for low-end machines. We want to
avoid this if we can.</li>
<li>We would hate to have to use <code>Immediate</code>, where there's no vsync at all.
That would just be terrible. We could live with it, but it'd be terrible
because we'd have to sync the program ourselves to avoid eating up 100% of
the core (and all of the user's battery, if they're on a mobile device).</li>
</ul>
</li>
<li><code>composite_alpha</code>:
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/enum.CompositeAlpha.html">CompositeAlpha</a>
controls how your window interacts with other windows within the user's UI.
<ul>
<li>For now we'd prefer <code>Opaque</code>, so that we just show our window &quot;normally&quot;.</li>
<li>We'd also accept <code>Native</code>, because we trust the user to have set things up
how they want.</li>
<li><code>PreMultiplied</code> or <code>PostMultiplied</code> will almost certainly give &quot;wrong&quot;
results because our graphics aren't smart enough to compensate for being
forced into such a mode. Well, they'd be wrong if our graphics were anything
more than a single clear color, but you know what I mean.</li>
</ul>
</li>
<li><code>format</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/format/enum.Format.html">Format</a> of the
swapchain is how the data for each pixel is expected to exist in memory.
<em>Normally</em> we'd be a lot more interested, but since we're just clearing the
screen it doesn't super matter. Still, we'll try to pick an sRGB format (which
stands for &quot;standard Red Green Blue&quot;), just because that's what we'll be using
in basically all the future lessons. Here we've got an <code>Option&lt;Vec&lt;_&gt;&gt;</code>, which
means that the selection block will be silly and fiddly.</li>
<li><code>extent</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/struct.Extent2D.html">Extent2D</a>
describes a full sized rectangle (not a sub-rectangle), and selects a size for
our images. Here's where we start using the SurfaceCapabilities that we got
earlier. The SwapchainConfig <code>extent</code> that we use must be within the range
that the <code>extents: Range&lt;Extent2D&gt;</code> field in our SurfaceCapabilities
specifies. Note that the
<a href="https://doc.rust-lang.org/nightly/core/ops/struct.Range.html">Range</a> type is
semantically supposed to be <em>exclusive</em> but both the Vulkan and DX12 backends
use it wrong, so it's actually an inclusive value here.
<ul>
<li>As far as what extent we're actually going to pick, we'll go as big as we
can. The Surface should should end up being the size of our Window, so our
images are just &quot;normal&quot; size and it all works out.</li>
</ul>
</li>
<li><code>image_count</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/type.SwapImageIndex.html">SwapImageIndex</a>
is just a <code>u32</code> for how many images we want in our Swapchain. Like I said, if
we're going to be using <code>Mailbox</code> then we want 3, otherwise we'll go with 2.
Note that we have to respect the <code>image_count: Range&lt;SwapImageIndex&gt;</code> field of
the SurfaceCapabilities, which is <em>another</em> field that is a Range but should
actually be a RangeInclusive.</li>
<li><code>image_layers</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/type.Layer.html">Layer</a> is just a
<code>u16</code> for how many layers we want in our image. 1 is fine.</li>
<li><code>image_usage</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/struct.Usage.html">Usage</a> defines
how we'll be using the images in the swap chain in terms of the render pass
stuff. We'll be using just color for now, so we check for that.</li>
</ul>
<p>With that all done, we make the SwapchainConfig and then we use the Device to
build a Swapchain and Backbuffer pair. This is a very vertical portion of code,
but not too much is actually happening.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let (swapchain, extent, backbuffer, format, frames_in_flight) = {
  let (caps, preferred_formats, present_modes, composite_alphas) = surface.compatibility(&amp;adapter.physical_device);
  info!(&quot;{:?}&quot;, caps);
  info!(&quot;Preferred Formats: {:?}&quot;, preferred_formats);
  info!(&quot;Present Modes: {:?}&quot;, present_modes);
  info!(&quot;Composite Alphas: {:?}&quot;, composite_alphas);
  //
  let present_mode = {
    use gfx_hal::window::PresentMode::*;
    [Mailbox, Fifo, Relaxed, Immediate]
      .iter()
      .cloned()
      .find(|pm| present_modes.contains(pm))
      .ok_or(&quot;No PresentMode values specified!&quot;)?
  };
  let composite_alpha = {
    use gfx_hal::window::CompositeAlpha::*;
    [Opaque, Inherit, PreMultiplied, PostMultiplied]
      .iter()
      .cloned()
      .find(|ca| composite_alphas.contains(ca))
      .ok_or(&quot;No CompositeAlpha values specified!&quot;)?
  };
  let format = match preferred_formats {
    None =&gt; Format::Rgba8Srgb,
    Some(formats) =&gt; match formats
      .iter()
      .find(|format| format.base_format().1 == ChannelType::Srgb)
      .cloned()
    {
      Some(srgb_format) =&gt; srgb_format,
      None =&gt; formats.get(0).cloned().ok_or(&quot;Preferred format list was empty!&quot;)?,
    },
  };
  let extent = caps.extents.end;
  let image_count = if present_mode == PresentMode::Mailbox {
    (caps.image_count.end - 1).min(3)
  } else {
    (caps.image_count.end - 1).min(2)
  };
  let image_layers = 1;
  let image_usage = if caps.usage.contains(Usage::COLOR_ATTACHMENT) {
    Usage::COLOR_ATTACHMENT
  } else {
    Err(&quot;The Surface isn't capable of supporting color!&quot;)?
  };
  let swapchain_config = SwapchainConfig {
    present_mode,
    composite_alpha,
    format,
    extent,
    image_count,
    image_layers,
    image_usage,
  };
  info!(&quot;{:?}&quot;, swapchain_config);
  //
  let (swapchain, backbuffer) = unsafe {
    device
      .create_swapchain(&amp;mut surface, swapchain_config, None)
      .map_err(|_| &quot;Failed to create the swapchain!&quot;)?
  };
  (swapchain, extent, backbuffer, format, image_count as usize)
};
#}</code></pre></pre>
<a class="header" href="#render_area" id="render_area"><h4>render_area</h4></a>
<p>This is a <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.Rect.html">Rect</a>
version of our Extent2D. While an Extent2D is semantically the full area of an
image or texture (storing only width:<code>u32</code> and height:<code>u32</code>), a Rect is some
sub-portion of such an area (storing x,y,w,h, all <code>i16</code>). Note that your
sub-portion can totally just be &quot;all of it&quot;.</p>
<a class="header" href="#frames_in_flight" id="frames_in_flight"><h4>frames_in_flight</h4></a>
<p>This is just us storing how many images are in our Swapchain. As you saw when we
cleared the screen, we'll have one set of just about everything per frame in
flight.</p>
<a class="header" href="#fences-and-semaphores" id="fences-and-semaphores"><h3>Fences and Semaphores</h3></a>
<p>Generating the Fence and Semaphore values is quite boring. You just call
<code>create_fence</code> and <code>create_semaphore</code> on your Device value, over and over until
you have enough. Technically this might cause an OutOfMemory problem on the GPU,
but that's not very likely, so there's little chance that we'll have a problem
in this stage of things.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let (image_available_semaphores, render_finished_semaphores, in_flight_fences) = {
  let mut image_available_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt; = vec![];
  let mut render_finished_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt; = vec![];
  let mut in_flight_fences: Vec&lt;&lt;back::Backend as Backend&gt;::Fence&gt; = vec![];
  for _ in 0..frames_in_flight {
    in_flight_fences.push(device.create_fence(true).map_err(|_| &quot;Could not create a fence!&quot;)?);
    image_available_semaphores.push(device.create_semaphore().map_err(|_| &quot;Could not create a semaphore!&quot;)?);
    render_finished_semaphores.push(device.create_semaphore().map_err(|_| &quot;Could not create a semaphore!&quot;)?);
  }
  (image_available_semaphores, render_finished_semaphores, in_flight_fences)
};
#}</code></pre></pre>
<a class="header" href="#renderpass" id="renderpass"><h2>RenderPass</h2></a>
<p>A RenderPass describes each part of the whole graphical processing for an image.
Well, actually it describes one &quot;pass&quot; which has various &quot;sub-passes&quot;, but you
can also do multi-pass rendering, and then each pass can have its own
sub-passes. It's a lot of organization you might need to keep track of, but it
lets you be very precise about what happens when.</p>
<p>The RenderPass type has a backend specific definition so there's no general
struct here, not even a trait for them, unfortunately. Instead, you make one
with
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_render_pass">Device::create_render_pass</a>.
This works a lot like that Submission stuff we had to deal with before, where
we'll have lists of stuff that all kinda get piled together. We need one
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/struct.Attachment.html">Attachment</a>
value (for the color), one
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/struct.SubpassDesc.html">SubpassDesc</a>
value (remember how we did a single &quot;inline&quot; render pass?), and then naturally
we have no
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/struct.SubpassDependency.html">SubpassDependency</a>
values since we only have a single subpass.</p>
<ul>
<li>Our Attachment needs
<ul>
<li><code>format</code>: the format that we picked out for our Swapchain to be using.</li>
<li><code>samples</code>: is only used when you get to multisampling, which is a later lesson.</li>
<li><code>ops</code>: determines what to do with the data in this Attachment at the start
of the subpass and at the end of the subpass. Remember how we recorded a
command that set a clear color and nothing else? That didn't even do the
clearing. <em>This</em> is the part that does the clearing. When the subpass begins
the old color value is all cleared. When the subpass ends the color values
are stored.</li>
<li><code>stencil_ops</code>: Is something we'll use later, but for now <code>DONT_CARE</code> is
sufficient. I guess this is one of the few places where we kinda have a
default to work with.</li>
<li><code>layouts</code>: This lets us define the starting and ending pixel layout of the
image we're processing. Each image has a pixel format which doesn't change
from pass to pass, but it also has a layout that does change from pass to
pass. It depends on what the image is being used for. In our case it starts
as Undefined (since nothing happened before this) and it ends with Present
(since we're done and want to present the image). Once again, we're using a
Range when the type <em>should be</em> RangeInclusive, or even maybe just a tuple.</li>
</ul>
</li>
<li>Our SubpassDesc needs the color attachment, and no others. This is where you
<em>can</em> get really fancy with &quot;post-processing effects&quot; type of stuff. We just
need one
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/type.AttachmentRef.html">AttachmentRef</a>
for our colors. An ID value (0 is fine) and a layout. <em>During</em> this pass we'll
be affecting the color, so we'll pick <code>ColorAttachmentOptimal</code>. Well, we don't
affect the colors after the clear during this tutorial, but once we start
drawing stuff it'll matter, so we might as well set it now.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let render_pass = {
  let color_attachment = Attachment {
    format: Some(format),
    samples: 1,
    ops: AttachmentOps {
      load: AttachmentLoadOp::Clear,
      store: AttachmentStoreOp::Store,
    },
    stencil_ops: AttachmentOps::DONT_CARE,
    layouts: Layout::Undefined..Layout::Present,
  };
  let subpass = SubpassDesc {
    colors: &amp;[(0, Layout::ColorAttachmentOptimal)],
    depth_stencil: None,
    inputs: &amp;[],
    resolves: &amp;[],
    preserves: &amp;[],
  };
  unsafe {
    device
      .create_render_pass(&amp;[color_attachment], &amp;[subpass], &amp;[])
      .map_err(|_| &quot;Couldn't create a render pass!&quot;)?
  }
};
#}</code></pre></pre>
<a class="header" href="#targets-for-rendering" id="targets-for-rendering"><h2>Targets For Rendering</h2></a>
<p>We've got all these images, but we can't use them as it is. The backend wants to
know more because it wants all the memory for each step to be as perfectly laid
out as possible.</p>
<a class="header" href="#imageview" id="imageview"><h3>ImageView</h3></a>
<p>First we have to take the Images (in the Backbuffer) and then make one ImageView
each. This adds the metadata to each image on how we're using it.</p>
<p>There's not too much to say about the process here. The Backbuffer technically
can hold two possible setups, one of which is for OpenGL and the other of which
is for everything else. It throws a bit of a wrench into our plans to support
the OpenGL setup so... well we just won't do it for now. After that's settled
it's just a simple map operation where we call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_image_view">Device::create_image_view</a>
a bunch and collect it all up.</p>
<p>We've seen some of this before.</p>
<ul>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/enum.ViewKind.html">ViewKind</a>
lets us pick that we want this ImageView to be a 2D image, which is already
enough of a heads up to know that an &quot;Image&quot; can get pretty weird the farther
we go into this and the more types of ViewKind we eventually use.</li>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/format/struct.Swizzle.html">Swizzle</a>
gives you the ability to transition between two different color channel
orderings, but we have no need for that now so we can use the <code>NO</code> constant.</li>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/struct.SubresourceRange.html">SubresourceRange</a>
lets us pick what sub-resources (eg: Color / Depth / Stencil) are used at what
mipmap levels (think &quot;zoom levels&quot;), and in what parts of the array (if our
image is an array, which it's not).</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let image_views: Vec&lt;_&gt; = match backbuffer {
  Backbuffer::Images(images) =&gt; images
    .into_iter()
    .map(|image| unsafe {
      device
        .create_image_view(
          &amp;image,
          ViewKind::D2,
          format,
          Swizzle::NO,
          SubresourceRange {
            aspects: Aspects::COLOR,
            levels: 0..1,
            layers: 0..1,
          },
        )
        .map_err(|_| &quot;Couldn't create the image_view for the image!&quot;)
    })
    .collect::&lt;Result&lt;Vec&lt;_&gt;, &amp;str&gt;&gt;()?,
  Backbuffer::Framebuffer(_) =&gt; unimplemented!(&quot;Can't handle framebuffer backbuffer!&quot;),
};
#}</code></pre></pre>
<a class="header" href="#framebuffer" id="framebuffer"><h3>Framebuffer</h3></a>
<p>Once we've got our ImageView values set, we can get one Framebuffer for each
with
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_framebuffer">Device::create_framebuffer</a>.
This is what we actually target with our CommandBuffer recordings. It's another
quick map operation, even less to say than with the ImageViews.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let framebuffers: Vec&lt;&lt;back::Backend as Backend&gt;::Framebuffer&gt; = {
  image_views
    .iter()
    .map(|image_view| unsafe {
      device
        .create_framebuffer(
          &amp;render_pass,
          vec![image_view],
          Extent {
            width: extent.width as u32,
            height: extent.height as u32,
            depth: 1,
          },
        )
        .map_err(|_| &quot;Failed to create a framebuffer!&quot;)
    })
    .collect::&lt;Result&lt;Vec&lt;_&gt;, &amp;str&gt;&gt;()?
};
#}</code></pre></pre>
<p>There's a use of <code>vec!</code> in there that we <em>could</em> avoid with the same ArrayVec
deal that we used before, but this is startup code so we don't quite need to
bother. We'll only have 2 or 3 framebuffers anyway, it's fine.</p>
<a class="header" href="#command-issuing" id="command-issuing"><h2>Command Issuing</h2></a>
<p>We're in the home stretch, we just need to initialize the ability to issue
commands so we can put all these other things into use.</p>
<p>It's so simple we won't even use sub-sections:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut command_pool = unsafe {
  device
    .create_command_pool_typed(&amp;queue_group, CommandPoolCreateFlags::RESET_INDIVIDUAL)
    .map_err(|_| &quot;Could not create the raw command pool!&quot;)?
};
#}</code></pre></pre>
<p>The <code>RESET_INDIVIDUAL</code> flag lets us reset individual command buffers that come
out of this pool (without the flag you have to reset the whole pool at once).</p>
<p>Once we have a CommandPool we make it give us one CommandBuffer for each
Framebuffer that we ended up with.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let command_buffers: Vec&lt;_&gt; = framebuffers.iter().map(|_| command_pool.acquire_command_buffer()).collect();
#}</code></pre></pre>
<a class="header" href="#current_frame" id="current_frame"><h3>current_frame</h3></a>
<p>I guess you could say that this is part of the command issuing maybe? I don't
know, but we've been initializing for a super long time and I'm getting sick of
it, so you probably are too. This value is just a <code>usize</code> tracking what set of
stuff to use, and it starts at 0.</p>
<a class="header" href="#cleaning-up-halstate" id="cleaning-up-halstate"><h1>Cleaning Up <code>HalState</code></h1></a>
<p>There's two situations where we'd need to clean up the <code>HalState</code> stuff:</p>
<ul>
<li>Drop triggering, for any reason: Easy to do, we'll show that in a moment, once
we've talked about this other situation we have to handle</li>
<li><code>new</code> returning before the <code>HalState</code> struct is actually declared (which means
that <code>HalState::drop</code> doesn't get called): Very un-ergonomic to handle
properly. Like, seriously it's bad. You could re-arrange all of the code so
that <em>every single</em> early return (the <code>?</code> parts) is actually resource safe,
but we're totally not even going to do that. It's just too terrible to try.
Every single potential early return would create a new indentation for the
main code and a custom cleanup block we'd have to write in the error case. I
don't even want to think about it.</li>
</ul>
<p>Why so? Well, almost none of the resource types are self-destructing, so even
though an early return causes them to die <a href="https://github.com/rust-lang/rfcs/blob/master/text/1857-stabilize-drop-order.md">in the proper
order</a>
(that is, we <em>always</em> want LIFO destruction), their moment of destruction
doesn't actually <em>do</em> anything because they don't have their own Drop code.
<em>This isn't anyone's fault</em>. I know in a few spots I've taken a few jabs at the
gfx team for using Range instead of RangeInclusive or something like that, but
this one they really can't fix.</p>
<p>Anything that comes from <code>Device::create_foo</code> needs to be destroyed by calling
<code>Device::destroy_foo</code> using that same device. So, either we need to have a
globally set Device value so that anyone's drop code can call <code>destroy_*</code> at any
time (rather bad to have such a global), or every single thing to later be
destroyed has to carry with it a copy of the Device so that they can use it to
destroy themselves (arguably worse in terms of overhead). It's just... it's just
not a good situation at all. We'll just have to be aware that our HalState
initialization code is just fundamentally broken for early returns, and it
probably always will be.</p>
<p>What are the <em>consequences</em> for any kind of improper resource destruction like
that? Well, it depends. Which is terrible to have to say, but it does. <em>Usually</em>
you get a resource leak but life goes on as long as everything that comes out of
your Instance goes away before your Instance does. If you try to destroy the
Instance before things that came out of it you'll (probably) segfault your
process on the Vulkan backend. DX12 doesn't seem to mind. I don't know about
Metal since I don't own a mac.</p>
<p>I feel about as bad for being so vague about it as you probably feel for having
to read it, but these are just the troubles with FFI.</p>
<a class="header" href="#waiting-until-idle" id="waiting-until-idle"><h3>Waiting Until Idle</h3></a>
<p>The first thing we do in the drop method is wait for the device to go idle. It's
not legal to destroy resources that are in use, so we just give it a moment to
cool down by calling
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.wait_idle">Device::wait_idle</a>.
This could technically error, but at this point we're tearing it all down so we
don't care about the error. The device had its chance and now we're in charge.</p>
<a class="header" href="#basic-destruction" id="basic-destruction"><h3>Basic Destruction</h3></a>
<p>As I said, anything that comes from <code>Device::create_foo</code> needs to go back to a
<code>Device::destroy_foo</code> call. If those things are stored in vectors, it's easy to
drain out the vector and destroy them one at a time.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl core::ops::Drop for HalState {
  /// We have to clean up &quot;leaf&quot; elements before &quot;root&quot; elements. Basically, we
  /// clean up in reverse of the order that we created things.
  fn drop(&amp;mut self) {
    let _ = self.device.wait_idle();
    unsafe {
      for fence in self.in_flight_fences.drain(..) {
        self.device.destroy_fence(fence)
      }
#}</code></pre></pre>
<p>And so on, for all of the things that are stored in vectors.</p>
<a class="header" href="#manuallydrop" id="manuallydrop"><h3>ManuallyDrop</h3></a>
<p>What do we do about things that aren't stored in vectors? We need to pass them
to <code>destroy_foo</code> but that's by-value and we can't move them out of a borrowed
context (since we're using <code>&amp;mut self</code> within the <code>drop</code> call).</p>
<p>The answer is that we cheat.</p>
<p>If we just use
<a href="https://doc.rust-lang.org/core/ptr/fn.read.html">core::ptr::read</a> we can make a
duplicate of any bits we want. The type doesn't even have to be Clone! It's as
unsafe as it sounds. How do we offset some of that? With a marker struct called
<a href="https://doc.rust-lang.org/core/mem/struct.ManuallyDrop.html">ManuallyDrop</a>,
which is magically known to the compiler, and the thing inside of the
ManuallyDrop will never run its own destructor automatically. When it's really
time to destroy the thing we can call <code>ManuallyDrop::into_inner</code> to unwrap the
value and pass it to some destroy function, or we can call <code>ManuallyDrop::drop</code>
to force the drop to happen on something that we don't have ownership of. We're
actually going to use <em>both</em> styles.</p>
<p>For things that go with a <code>destroy_foo</code> method we'll use the <code>::into_inner</code>
style:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// The CommandPool must also be unwrapped into a RawCommandPool,
// so there's an extra `into_raw` call here.
self
  .device
  .destroy_command_pool(ManuallyDrop::into_inner(read(&amp;mut self.command_pool)).into_raw());
self
  .device
  .destroy_render_pass(ManuallyDrop::into_inner(read(&amp;mut self.render_pass)));
self
  .device
  .destroy_swapchain(ManuallyDrop::into_inner(read(&amp;mut self.swapchain)));
#}</code></pre></pre>
<p>And for our three final items we just use the <code>ManuallyDrop::drop</code> style:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
ManuallyDrop::drop(&amp;mut self.queue_group);
ManuallyDrop::drop(&amp;mut self.device);
ManuallyDrop::drop(&amp;mut self._instance);
#}</code></pre></pre>
<a class="header" href="#final-halstate-definition" id="final-halstate-definition"><h1>Final <code>HalState</code> Definition</h1></a>
<p>Now that we know all of the fields that we have, including which ones are
wrapped in <code>ManuallyDrop</code>, we can look at our crazy, ugly, horrible <code>HalState</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct HalState {
  current_frame: usize,
  frames_in_flight: usize,
  in_flight_fences: Vec&lt;&lt;back::Backend as Backend&gt;::Fence&gt;,
  render_finished_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt;,
  image_available_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt;,
  command_buffers: Vec&lt;CommandBuffer&lt;back::Backend, Graphics, MultiShot, Primary&gt;&gt;,
  command_pool: ManuallyDrop&lt;CommandPool&lt;back::Backend, Graphics&gt;&gt;,
  framebuffers: Vec&lt;&lt;back::Backend as Backend&gt;::Framebuffer&gt;,
  image_views: Vec&lt;(&lt;back::Backend as Backend&gt;::ImageView)&gt;,
  render_pass: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::RenderPass&gt;,
  render_area: Rect,
  queue_group: ManuallyDrop&lt;QueueGroup&lt;back::Backend, Graphics&gt;&gt;,
  swapchain: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::Swapchain&gt;,
  device: ManuallyDrop&lt;back::Device&gt;,
  _adapter: Adapter&lt;back::Backend&gt;,
  _surface: &lt;back::Backend as Backend&gt;::Surface,
  _instance: ManuallyDrop&lt;back::Instance&gt;,
}
#}</code></pre></pre>
<a class="header" href="#everything-else" id="everything-else"><h1>Everything Else</h1></a>
<p>Now we just fill in those final bits that aren't the <code>HalState</code> materials.</p>
<a class="header" href="#userinput" id="userinput"><h2><code>UserInput</code></h2></a>
<p>For input, we'll just track a few of the possible things:</p>
<ul>
<li>If a close was requested.</li>
<li>The frame's new size (if any).</li>
<li>The mouse's new position (if any).</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Default)]
pub struct UserInput {
  pub end_requested: bool,
  pub new_frame_size: Option&lt;(f64, f64)&gt;,
  pub new_mouse_position: Option&lt;(f64, f64)&gt;,
}
impl UserInput {
  pub fn poll_events_loop(events_loop: &amp;mut EventsLoop) -&gt; Self {
    let mut output = UserInput::default();
    events_loop.poll_events(|event| match event {
      Event::WindowEvent {
        event: WindowEvent::CloseRequested,
        ..
      } =&gt; output.end_requested = true,
      Event::WindowEvent {
        event: WindowEvent::Resized(logical),
        ..
      } =&gt; {
        output.new_frame_size = Some((logical.width, logical.height));
      }
      Event::WindowEvent {
        event: WindowEvent::CursorMoved { position, .. },
        ..
      } =&gt; {
        output.new_mouse_position = Some((position.x, position.y));
      }
      _ =&gt; (),
    });
    output
  }
}
#}</code></pre></pre>
<a class="header" href="#localstate" id="localstate"><h2><code>LocalState</code></h2></a>
<p>Currently, the locals are just the user input, minus the bool for if the user is
trying to quit. We'll get plenty more locals later.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Copy, Default)]
pub struct LocalState {
  pub frame_width: f64,
  pub frame_height: f64,
  pub mouse_x: f64,
  pub mouse_y: f64,
}
impl LocalState {
  pub fn update_from_input(&amp;mut self, input: UserInput) {
    if let Some(frame_size) = input.new_frame_size {
      self.frame_width = frame_size.0;
      self.frame_height = frame_size.1;
    }
    if let Some(position) = input.new_mouse_position {
      self.mouse_x = position.0;
      self.mouse_y = position.1;
    }
  }
}
#}</code></pre></pre>
<a class="header" href="#do_the_render" id="do_the_render"><h2><code>do_the_render</code></h2></a>
<p>This part is easy right now. We just make up some arbitrary color and clear the
screen to that. We'll use the mouse's position as a fraction of the total frame
size, so that the color shifts as the mouse moves. It's some sort of feedback at
least.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn do_the_render(hal_state: &amp;mut HalState, local_state: &amp;LocalState) -&gt; Result&lt;(), &amp;'static str&gt; {
  let r = (local_state.mouse_x / local_state.frame_width) as f32;
  let g = (local_state.mouse_y / local_state.frame_height) as f32;
  let b = (r + g) * 0.3;
  let a = 1.0;
  hal_state.draw_clear_frame([r, g, b, a])
}
#}</code></pre></pre>
<a class="header" href="#main" id="main"><h2><code>main</code></h2></a>
<p>Now we put it all together, and we get a final form that's pleasantly similar to
what our initial goal looked like.</p>
<pre><pre class="playpen"><code class="language-rust">fn main() {
  simple_logger::init().unwrap();

  let mut winit_state = WinitState::default();

  let mut hal_state = match HalState::new(&amp;winit_state.window) {
    Ok(state) =&gt; state,
    Err(e) =&gt; panic!(e),
  };

  let (frame_width, frame_height) = winit_state
    .window
    .get_inner_size()
    .map(|logical| logical.into())
    .unwrap_or((0.0, 0.0));
  let mut local_state = LocalState {
    frame_width,
    frame_height,
    mouse_x: 0.0,
    mouse_y: 0.0,
  };

  loop {
    let inputs = UserInput::poll_events_loop(&amp;mut winit_state.events_loop);
    if inputs.end_requested {
      break;
    }
    local_state.update_from_input(inputs);
    if let Err(e) = do_the_render(&amp;mut hal_state, &amp;local_state) {
      error!(&quot;Rendering Error: {:?}&quot;, e);
      break;
    }
  }
}
</code></pre></pre>
<p><img src="images/clear-the-window-complete.png" alt="clear-the-window-complete" /></p>
<p>You can find the full code file in the <code>examples/</code> directory of the repo.</p>
<a class="header" href="#triangle-intro" id="triangle-intro"><h1>Triangle Intro</h1></a>
<p>Hey, you're back.</p>
<p>This lesson builds upon the last one. Before we could draw a clear frame, now
we'll add the ability to draw a frame with a single triangle in it.</p>
<a class="header" href="#usage-code" id="usage-code"><h2>Usage Code</h2></a>
<p>Once again, even baby steps in functionality will demand pages and pages of work
to get arranged properly.</p>
<p>What we're going to write in this lesson is a single public method so that we
can draw a single triangle as a displayed frame. For now we'll stick to just
<em>one</em> triangle (three points), and even then, only a 2D triangle of <code>(x,y)</code>
points.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Copy)]
pub struct Triangle {
  pub points: [[f32; 2]; 3],
}
impl Triangle {
  pub fn points_flat(self) -&gt; [f32; 6] {
    let [[a, b], [c, d], [e, f]] = self.points;
    [a, b, c, d, e, f]
  }
}
#}</code></pre></pre>
<p>Why only 2D? Unfortunately, without the help of camera perspective, lightning,
shading, and other effects like that, 3D things just don't show up very well on
a 2D screen. Instead of looking like a normal triangle at an angle, it just
looks like a slightly differently shaped triangle, but still totally flat. So
when we finally transmit the triangle to the GPU we'll simply give all three
points an identical <code>z</code> coordinate for now.</p>
<p>To have some sort of confirmation of input and output like before we'll have one
of the triangle points follow the user's mouse movements. Nothing fancy, just a
way to see that we're continually  drawing a new thing each time. Actually
passing in the triangle to draw is basically identical to the clear color
function:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl HalState {
  pub fn draw_triangle_frame(&amp;mut self, triangle: Triangle) -&gt; Result&lt;(), &amp;'static str&gt; {
    unimplemented!()
  }
}
#}</code></pre></pre>
<p>The ability to draw <em>exactly one</em> triangle isn't very useful on its own. What I
mean is that we could potentially use the <code>draw_clear_frame</code> method in the
future even in a &quot;complete program&quot;. We could use it during a brief loading
screen or something. However, <code>draw_triangle_frame</code> doesn't really have a good
shelf life. In a complete program we'd want to have a way to specify an entire
scene of models, each composed of many triangles. In fact, if properly
supporting <code>draw_triangle_frame</code> in future lessons gives us any trouble at all,
we'll just delete it instead. It's seriously that impractical.</p>
<p>Why add a thing only to then take it away? Because demanding of ourselves to
draw a single triangle, of any quality, forces us to put in to place many more
parts of our overall &quot;rendering pipeline&quot;. The rendering pipeline is what's
<em>really</em> here to stay. A <strong>complete</strong> rendering pipeline with all the bells and
whistles is <em>even more complex</em> than a complete Swapchain like we did last time.
It's a many lesson long process to fully understand. In fact, the Swapchain is
one portion of the overall rendering pipeline. So we saw a bit of the whole
picture in the last lesson, we'll add more this lesson, and we'll keep expanding
and refining our process in each future lesson.</p>
<p>The entire field of 3D programming is just an unending process of learning more
and more about how you can twist the rendering pipeline to do exactly what you
want, when you want, as fast as possible.</p>
<p>If that concept doesn't excite and interest you, best to get out now. No shame
in wanting to code other parts of a program instead, but that's really all we'll
be doing, so save yourself the time if that's not what you care about.</p>
<a class="header" href="#terminology-sidebar-immediate-vs-retained" id="terminology-sidebar-immediate-vs-retained"><h3>Terminology Sidebar: Immediate vs Retained</h3></a>
<p>As we go further I should probably define two terms you might see come up here
or in other graphics tutorials: Immediate API and Retained API.</p>
<ul>
<li>An immediate API is any API where you call a function with an argument and it
does all the work with that argument right then, without storing the argument
data for later.</li>
<li>A retained API is any API where your function calls cause data to be
<em>retained</em> by the system. Usually you make some calls to set up the situation,
and then you make a separate call to compute things using the requested setup.</li>
</ul>
<p>In general, an immediate API is often easier to use, but a retained API is often
more efficient if the input format and usage format differ (so you don't have to
convert more than once) or if the system needs special resources (heap
allocation, open file handles, things like that).</p>
<a class="header" href="#quick-bug-fixes" id="quick-bug-fixes"><h2>Quick Bug Fixes</h2></a>
<p>There's two things we have to change about last lesson's code before we proceed
to mostly work on new code.</p>
<a class="header" href="#that-swapchain-is-too-big" id="that-swapchain-is-too-big"><h3>That Swapchain Is Too Big!</h3></a>
<p>On the Metal backend (mac os) the extent that's reported in the swapchain
capabilities isn't clamped to the window size, so you get a reported maximum
size of 4096 x 4096. Obviously that's far too big! It doesn't matter for just
clearing the screen, but it matters now that we'll be drawing something.</p>
<p>We just have to edit how we define the extent as we create our Swapchain:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let extent = {
  let window_client_area = window
    .get_inner_size()
    .ok_or(&quot;Window doesn't exist!&quot;)?
    .to_physical(window.get_hidpi_factor());
  Extent2D {
    width: caps.extents.end.width.min(window_client_area.width as u32),
    height: caps.extents.end.height.min(window_client_area.height as u32),
  }
};
#}</code></pre></pre>
<a class="header" href="#the-swapchain-doesnt-resize" id="the-swapchain-doesnt-resize"><h3>The Swapchain Doesn't Resize!</h3></a>
<p>The window can resize, but the backing swapchain doesn't resize. Again, this
isn't apparent when you're drawing nothing, but once you draw something it'll be
drawing at the starting resolution and then scaling up or down to the window's
real size.</p>
<p>Now, you <em>could</em> try to carefully destroy anything that came from the Swapchain
and then the Swapchain itself and then re-create each element at the new size.
You could, it'd work.</p>
<p>Why bother being so fiddly though? We've gone to all the work of making our
<code>HalState</code> type very cleanly close itself down. Let's take advantage of that and
just throw out the <em>entire</em> old <code>HalState</code> and build a new one. We don't have to
think about what the ordering of anything is, we don't have to remember to
update the change_resolution code every time we touch some other part of the
code. It's really so much less error prone. &quot;Just restart the whole thing&quot; is
how you get that magical <a href="https://en.wikipedia.org/wiki/Erlang_(programming_language)">Nine Nines
Stability</a>, after
all ;3</p>
<p>Note that we need to restart hal if we detect a window size change, but <em>also</em>
if we're using <code>Mailbox</code> mode it's possible for the GPU to try and present a
frame in the moment between when the window resizes and when we detect the error
and respond. To cover this case, we'll also try to restart hal if we get any
rendering error.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
loop {
  let inputs = UserInput::poll_events_loop(&amp;mut winit_state.events_loop);
  if inputs.end_requested {
    break;
  }
  if inputs.new_frame_size.is_some() {
    debug!(&quot;Window changed size, restarting HalState...&quot;);
    drop(hal_state);
    hal_state = match HalState::new(&amp;winit_state.window) {
      Ok(state) =&gt; state,
      Err(e) =&gt; panic!(e),
    };
  }
  local_state.update_from_input(inputs);
  if let Err(e) = do_the_render(&amp;mut hal_state, &amp;local_state) {
    error!(&quot;Rendering Error: {:?}&quot;, e);
    debug!(&quot;Auto-restarting HalState...&quot;);
    drop(hal_state);
    hal_state = match HalState::new(&amp;winit_state.window) {
      Ok(state) =&gt; state,
      Err(e) =&gt; panic!(e),
    };
  }
}
#}</code></pre></pre>
<p>Now <strong>please</strong> be aware that this isn't actually the best design for every
possible <code>gfx-hal</code> program! It's just the best way to do it for our small
program here. The more data that you've uploaded to the GPU that you want to
preserve, the more you might want to consider rebuilding just a small number of
parts. It's something you have to investigate for yourself as your program
grows.</p>
<a class="header" href="#drawing-a-triangle" id="drawing-a-triangle"><h1>Drawing A Triangle</h1></a>
<p>To draw a triangle, we will use the same sort of setup before, with the frame
based drawing and the &quot;ring buffer&quot; vectors of all our tools. Literally just
copy and paste all of <code>draw_clear_frame</code> to a new spot and name it
<code>draw_triangle_frame</code>, the bulk of it is that similar. The argument is a single
triangle instead of a single color though.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn draw_triangle_frame(&amp;mut self, triangle: Triangle) -&gt; Result&lt;(), &amp;'static str&gt; {
#}</code></pre></pre>
<p>Now you'd think &quot;hey can't we abstract the commonalities here? Well, maybe but
you can't really do it with a function and a closure because lifetimes and
function borders don't play particularly nice in Rust. Our draw code
unfortunately really relies on having a lot of &quot;split borrows&quot; (where the borrow
is just on one field at a time) instead of struct-wide borrows (eg: <code>&amp;self</code> or
<code>&amp;mut self</code>). Or you could do it as a macro maybe? Either way it'd be probably
quite a bit of work for not too much gained. We don't want to over abstract
until we see how the code is growing.</p>
<a class="header" href="#upload-that-triangle-data" id="upload-that-triangle-data"><h2>Upload That Triangle Data</h2></a>
<p>To actually place data for the triangle into the vertex buffer we need a mapping
writer. Unfortunately, this is <em>basically</em> a reference, which means that it has
a lifetime linked to a particular blob of <code>Memory</code> from the GPU, which means
that we can't really store it in the same struct that holds the handle to the
Memory because Rust is just bad at self-referential struct things. Instead,
we'll get a mapping writer, use it, and then destroy it.</p>
<p>(Hint: if you already read <a href="https://doc.rust-lang.org/nomicon/">The
Rustonomicon</a> like I told you to in the
Introduction, then you already know how to cheese it and avoid this limitation
at the small cost of <em>massive</em> unsafety, should you want to. If you need <em>me</em> to
tell you how, then you're not ready to do it.)</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // WRITE THE TRIANGLE DATA
    unsafe {
      let mut data_target = self
        .device
        .acquire_mapping_writer(&amp;self.memory, 0..self.requirements.size)
        .map_err(|_| &quot;Failed to acquire a memory writer!&quot;)?;
      let points = triangle.points_flat();
      data_target[..points.len()].copy_from_slice(&amp;points);
      self
        .device
        .release_mapping_writer(data_target)
        .map_err(|_| &quot;Couldn't release the mapping writer!&quot;)?;
    }
#}</code></pre></pre>
<p>As you'll see in future lessons, it's actually very rare to update all the
vertex data of a model every frame. Usually you set it once and then use
&quot;transforms&quot; to move the model around within the scene, without actually
affecting the vertex data. For now, we'll just push fresh vertex data each
frame.</p>
<a class="header" href="#record-the-commands" id="record-the-commands"><h2>Record The Commands</h2></a>
<p>All that really changes here compared to <code>draw_clear_frame</code> is that instead of
starting a CommandBuffer and then recording <em>nothing</em>, we'll actually record
something this time.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // RECORD COMMANDS
    unsafe {
      let buffer = &amp;mut self.command_buffers[i_usize];
      const TRIANGLE_CLEAR: [ClearValue; 1] = [ClearValue::Color(ClearColor::Float([0.1, 0.2, 0.3, 1.0]))];
      buffer.begin(false);
      {
        let mut encoder = buffer.begin_render_pass_inline(
          &amp;self.render_pass,
          &amp;self.framebuffers[i_usize],
          self.render_area,
          TRIANGLE_CLEAR.iter(),
        );
        encoder.bind_graphics_pipeline(&amp;self.graphics_pipeline);
        // Here we must force the Deref impl of ManuallyDrop to play nice.
        let buffer_ref: &amp;&lt;back::Backend as Backend&gt;::Buffer = &amp;self.buffer;
        let buffers: ArrayVec&lt;[_; 1]&gt; = [(buffer_ref, 0)].into();
        encoder.bind_vertex_buffers(0, buffers);
        encoder.draw(0..3, 0..1);
      }
      buffer.finish();
    }
#}</code></pre></pre>
<p>This time out the mouse will control one of the triangle points instead of the
color, so we'll pick a fixed color for the clear color. Once we start the
&quot;render pass inline&quot; we're actually going to bind what we get back from that.
It's a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderPassInlineEncoder.html">RenderPassInlineEncoder</a>,
which is also
Deref&lt;Target=<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderSubpassCommon.html">RenderSubpassCommon</a>&gt;,
and it gives us access to the operations of a particular render pass.</p>
<ul>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderSubpassCommon.html#method.bind_graphics_pipeline">RenderSubpassCommon::bind_graphics_pipeline</a>
picks a particular graphics pipeline for the rendering of this subpass. You
<em>can</em> have more than one graphics pipeline, each with its own settings, if you
want, though while we're starting out we only need one per program.</li>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderSubpassCommon.html#method.bind_vertex_buffers">RenderSubpassCommon::bind_vertex_buffers</a>
picks the vertex buffers to use for this subpass. The magical looking <code>0</code> here
has to match up with the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.VertexBufferDesc.html">VertexBufferDesc</a>
that's specified as part of the graphics pipeline that you're using. We'll
talk about the full graphics pipeline definition in a moment, but the thing to
pay attention to right now is that you can have many buffers and you don't
need to specify them all in a single bind call. You could give 3 starting at
0, give 3 more starting at 3, etc. We only have one buffer, so we just need
one bind call and we place it at the 0th index.</li>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderSubpassCommon.html#method.draw">RenderSubpassCommon::draw</a>
uses Range properly, so those really are exclusive endings. This uses our
three vertices (indexed 0, 1, 2) and a single instance (indexed 0). The
instance thing has to do with a more advanced technique called &quot;instanced
drawing&quot; where you can draw a particular setup many times as a single draw
call, specifying parameters per instance. That'd be for something like drawing
ten copies of the same tree model, each in their own position and orientation
within the scene. There's a small price per draw call that you make, so if
you're drawing &quot;the same&quot; thing many times with small variation it pays off to
setup instanced drawing and make a single draw call with many instances
specified. We'll cover all that more in a future lesson. For now we've just
got a single triangle as part of a single instance.</li>
</ul>
<p>That's all we gotta do!</p>
<p>&quot;all&quot;</p>
<p>What comes next is setting up the graphical pipeline to make this happen.</p>
<a class="header" href="#define-a-graphics-pipeline" id="define-a-graphics-pipeline"><h1>Define A Graphics Pipeline</h1></a>
<p>I know that in the last lesson we did all of our setup without any of the code
being placed into helper functions, and I stand by that. None of it was super
complex (honest!) and most of the sub-parts weren't ever going to be called in
different contexts with different inputs. Most of the time you want to make
something a function when you're going to reuse it, not just because it's long.</p>
<p>This time I'm going to bend on that, because the graphics pipeline setup is
about 2/3rds as long as <em>all of</em> the initialization setup that we did before.
It's not even super complex, there's just a billion little settings and options
that we have to specify.</p>
<a class="header" href="#create_pipeline-signature" id="create_pipeline-signature"><h2><code>create_pipeline</code> Signature</h2></a>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  #[allow(clippy::type_complexity)]
  fn create_pipeline(
    device: &amp;mut back::Device, extent: Extent2D, render_pass: &amp;&lt;back::Backend as Backend&gt;::RenderPass,
  ) -&gt; Result&lt;
    (
      Vec&lt;&lt;back::Backend as Backend&gt;::DescriptorSetLayout&gt;,
      &lt;back::Backend as Backend&gt;::PipelineLayout,
      &lt;back::Backend as Backend&gt;::GraphicsPipeline,
    ),
    &amp;'static str,
  &gt; {
#}</code></pre></pre>
<p>Okay, ha, so, what have we got here. First, we're telling clippy to please stay
calm despite the very complex return type there. It wants us to make a
<code>Result&lt;Struct, &amp;str&gt;</code>, and I won't say it's wrong, it's just not what I wanna
do with my time right now. We'll just use a 3-tuple.</p>
<p>So what does our pipeline need for us to get our Result? First of all, let's be
<em>super</em> clear if it wasn't clear enough already from the tuple: The &quot;pipeline&quot;
is actually three different parts, <em>one of which</em> is a thing that's actually
called GraphicsPipeline, but also we need to know the PipelineLayout that goes
with it, as well as the DescriptorSetLayout. I'd love to link you to some docs
for these types, but the specifics of all three are Backend dependent. We just
take it on faith that they do something important, without yet knowing what they
do precisely.</p>
<p>If we review the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html">Device</a> trait
we'll see that each of these things comes from a <code>create_foo</code> method on the
Device, so we'll need to add them to the Drop code for <code>HalState</code>. I'll assume
that you can do that yourself by now, you just do the same thing as before. 1)
store it as a ManuallyDrop, 2) use <code>read</code> to pseudo-clone it and then pass that
pseudo-clone to the <code>destroy_foo</code> method.</p>
<p>So we need <code>&amp;mut Device</code> as an input. We also need the <code>Extent2D</code> for what size
of Swapchain this pipeline setup goes with. Finally, we need a <code>&amp;RenderPass</code>.
The sub-passes of the pipeline we make will need to be able to reference back to
it during the setup.</p>
<p>So we want to make a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.GraphicsPipelineDesc.html">GraphicsPipelineDesc</a>,
but as you can see there's 13 fields there, so we'll have to handle a few at a
time until everything is ready.</p>
<a class="header" href="#shader-modules" id="shader-modules"><h2>Shader Modules</h2></a>
<p>A <strong>Shader</strong> is one of several parts of the graphical pipeline on the GPU.
There's several stages of shader, as well as some non-shader stages. Right here
I'm going to go ahead and use a graphic from the <a href="https://vulkan-tutorial.com/Drawing_a_triangle/Graphics_pipeline_basics">Graphics Pipeline
Basics</a>
potion of the <a href="https://vulkan-tutorial.com">vulkan-tutorial.com</a> tutorial, because
they've got a pretty slick diagram of it.</p>
<p><img src="https://vulkan-tutorial.com/images/vulkan_simplified_pipeline.svg" alt="pipeline-diagram" /></p>
<p>Things in <em>green</em> are selections we can make, but from only a limited list of
options. Things in <em>yellow</em> are things that we can write a shader for.</p>
<p>A shader is a mini-program (sometimes not so mini) that has its own options for
source language, and it's own compiled format, and all of that. Instead of
writing in Rust and compiling to <code>ARM</code> or <code>x86_64</code> or something else, we write a
program in <a href="https://en.wikipedia.org/wiki/OpenGL_Shading_Language">GLSL</a> and
compile it to <a href="https://www.khronos.org/registry/spir-v/">SPIRV</a>. Actually you
can write a shader in anything that compiles to compatible SPIRV code, but the
tools that are easiest for us to use right now do GLSL -&gt; SPIRV.</p>
<p>A <strong>Shader Module</strong> is a handle that you get when you upload some shader code to
the GPU. We take a few shader modules and put them together into a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.GraphicsShaderSet.html">GraphicsShaderSet</a>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    let mut compiler = shaderc::Compiler::new().ok_or(&quot;shaderc not found!&quot;)?;
    let vertex_compile_artifact = compiler
      .compile_into_spirv(VERTEX_SOURCE, shaderc::ShaderKind::Vertex, &quot;vertex.vert&quot;, &quot;main&quot;, None)
      .map_err(|_| &quot;Couldn't compile vertex shader!&quot;)?;
    let fragment_compile_artifact = compiler
      .compile_into_spirv(FRAGMENT_SOURCE, shaderc::ShaderKind::Fragment, &quot;fragment.frag&quot;, &quot;main&quot;, None)
      .map_err(|e| {
        error!(&quot;{}&quot;, e);
        &quot;Couldn't compile fragment shader!&quot;
      })?;
    let vertex_shader_module = unsafe {
      device
        .create_shader_module(vertex_compile_artifact.as_binary_u8())
        .map_err(|_| &quot;Couldn't make the vertex module&quot;)?
    };
    let fragment_shader_module = unsafe {
      device
        .create_shader_module(fragment_compile_artifact.as_binary_u8())
        .map_err(|_| &quot;Couldn't make the fragment module&quot;)?
    };
#}</code></pre></pre>
<p>For this to work, you have to use the <code>shaderc-rs</code> crate, which takes <em>very</em>
long to build that first time because it's actually using <code>build.rs</code> to download
a relatively massive C++ lib and then link that in. Be sure to see the <code>shaderc-rs</code>
<a href="https://github.com/google/shaderc-rs#setup">setup instructions</a>.</p>
<ol>
<li>We open a compiler</li>
<li>We compile some Vertex Shader source. This is &quot;where do the points go on the
screen&quot;. We use a string literal in our file, the shader type we want, a
dummy file name (it's just used for error messages), the &quot;entry point&quot; of the
program, and finally we could give some extra options if we wanted.</li>
<li>Then we do the exact same thing for the Fragment Shader. This is &quot;what color
are the points&quot;.</li>
</ol>
<p>To form a GraphicsShaderSet you <em>always</em> need a vertex shader, and then all the
other types are optional. However, to form an image you always must include a
fragment shader or all the color output is undefined (hard to have an image
without any colors). There <em>are</em> things you can do with a GraphicsShaderSet
where you don't need a fragment shader because you don't use the color channel
output, but those are for some future lesson.</p>
<p>In fact, shaders are complex enough that we'll spend the next lesson on a proper
shader introduction, and I'm going to punt all the rest of the description about
them until that lesson.</p>
<p>The last thing to say here is that the shader modules need to be destroyed, but
we don't need to store them forever in the <code>HalState</code>. We can destroy them after
we've made our graphics pipeline parts but before <code>create_pipeline</code> returns.
Once they've been incorporated into the pipeline we don't need to hold on to the
individual handles any more.</p>
<a class="header" href="#make-a-graphicsshaderset" id="make-a-graphicsshaderset"><h2>Make A GraphicsShaderSet</h2></a>
<p>Next, we go into one of those inner scopes that we love to use. Don't you love
'em? I sure do. Scopes for days. In this case, the point here is that we're
separating off all the stuff that happens while we've got those shader modules
created.</p>
<p>To make a GraphicsShaderSet we need an
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.EntryPoint.html">EntryPoint</a>
for each shader. It needs the <code>entry</code> (which matches the entry defined in the
compiled SPIRV code), the shader module, and a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.Specialization.html">Specialization</a>,
which we won't use right now (we'll just give empty slices).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let (vs_entry, fs_entry) = (
        EntryPoint {
          entry: &quot;main&quot;,
          module: &amp;vertex_shader_module,
          specialization: Specialization {
            constants: &amp;[],
            data: &amp;[],
          },
        },
        EntryPoint {
          entry: &quot;main&quot;,
          module: &amp;fragment_shader_module,
          specialization: Specialization {
            constants: &amp;[],
            data: &amp;[],
          },
        },
      );
      let shaders = GraphicsShaderSet {
        vertex: vs_entry,
        hull: None,
        domain: None,
        geometry: None,
        fragment: Some(fs_entry),
      };
#}</code></pre></pre>
<a class="header" href="#input-assembler" id="input-assembler"><h2>Input Assembler</h2></a>
<p>Once we've got all of our shader stuff arranged, we need to define all the other
parts. The first thing up (going in order of the pipeline diagram) is the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.InputAssemblerDesc.html">InputAssemblerDesc</a>,
where we pick a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/enum.Primitive.html">Primitive</a> for how
our vertices will be treated. The vertices are really just a huge list of values
(usually <code>f32</code>, but even then not always), and you have to tell the system how
it's supposed to turn those values into geometry. You should check the <a href="https://vulkan.lunarg.com/doc/view/1.0.33.0/linux/vkspec.chunked/ch19s01.html">vulkan
docs</a>
on this one, because they really get into it with diagrams and everything, but
here's the short version:</p>
<ul>
<li>As you expect, there's triangles, but you can also specify lines and points.</li>
<li>Geometry can be given as a &quot;list&quot;, where each unit is totally unique, or as a
&quot;strip&quot; where successive units share some vertex data. This can be trickier to
arrange until you get used to it, but it saves on data uploaded and data
stored. Even as desktops move to having 8GB or 16GB of RAM, the GPU itself has
half (or less!) of that, so making your models &quot;compressed&quot; like this is very
nice.</li>
</ul>
<a class="header" href="#vertex-shader" id="vertex-shader"><h2>Vertex Shader</h2></a>
<p>I know that we already have a shader module for our vertex shader, but we also
need to specify what buffers are going to be serving up vertex data, as well as
the attributes for the data. I said that the vertex data is actually just a huge
list of values, but those values aren't <em>only</em> positions for each vertex. You
most commonly will specify color and/or texture info as well as position
information.</p>
<p>Well, you <em>would</em> if you were doing a bigger example than this. To start we're
doing a single monochrome triangle, so we'll just have each vertex specify an
<code>(x,y)</code> position.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let vertex_buffers: Vec&lt;VertexBufferDesc&gt; = vec![VertexBufferDesc {
        binding: 0,
        stride: (size_of::&lt;f32&gt;() * 2) as u32,
        rate: 0,
      }];
      let attributes: Vec&lt;AttributeDesc&gt; = vec![AttributeDesc {
        location: 0,
        binding: 0,
        element: Element {
          format: Format::Rg32Float,
          offset: 0,
        },
      }];
#}</code></pre></pre>
<p>For the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.VertexBufferDesc.html">VertexBufferDesc</a>
we give:</p>
<ul>
<li>A <code>binding</code> index: remember that &quot;magical 0&quot; I mentioned we used when we wrote
the CommandBuffer? That's this thing.</li>
<li>A <code>stride</code>: how much space, in bytes, between the start of one vertex data
blob and the next</li>
<li>A <code>rate</code>: which is for that instanced drawing thing that I said we'd do in a
future lessons).
We need one of these descriptions <em>per vertex buffer</em>.</li>
</ul>
<p>For the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.AttributeDesc.html">AttributeDesc</a>
we give</p>
<ul>
<li>A <code>location</code>: which will match up with locations specified for inputs in our
shader code. They're counted up from 0, like array indexes.</li>
<li>A <code>binding</code>: which matches up with the VertexBufferDesc that this
AttributeDesc is for. Each VertexBufferDesc can have its own attribute
arrangement if you like, it can get quite intricate.</li>
<li>An <code>element</code>: This is an
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.Element.html">Element</a>
entry, which gives the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/format/enum.Format.html">Format</a> of the
particular attribute, as well as the byte offset for how far into the vertex
entry this particular attribute starts. The formats are mostly all specified
in terms of what sort of color data format they'd give, so &quot;two f32 values&quot; is
<code>Rg32Float</code>, even though we won't be using them as red and green channel data.
This is one of those things where you just have to accept that bits are bits
and the meaning is more what you make of it.</li>
</ul>
<a class="header" href="#tessellation-shader" id="tessellation-shader"><h2>Tessellation Shader</h2></a>
<p>We don't do anything here! Freebie! This <em>would</em> break up geometry into smaller
geometry to add apparent details, but we're not gonna right now.</p>
<a class="header" href="#geometry-shader" id="geometry-shader"><h2>Geometry Shader</h2></a>
<p>We also don't do anything here! Another freebie! This <em>would</em> let us process
each geometry item (point/line/triangle) into either 0 outputs (canceling that
item), 1 output, or even more than one output (kinda like the tessellation
shader).</p>
<a class="header" href="#rasterization" id="rasterization"><h2>Rasterization</h2></a>
<p>Once we have all of our geometry arranged, we need to translate the points into
pixels on the screen. So we specify a <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.Rasterizer.html">Rasterizer</a>:</p>
<ul>
<li><code>polygon_mode</code>: Pick a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/enum.PolygonMode.html">PolygonMode</a>.
Usually you want <code>Fill</code>, though <code>Line</code> and <code>Point</code> are neat for &quot;debug
display&quot; sorts of things. Or if you want to go for the &quot;Tron&quot; look.</li>
<li><code>cull_face</code>: When you define a triangle, it's obviously got two sides (called
&quot;front&quot; and &quot;back&quot;). You can make it so that if a triangle is viewed from the
&quot;wrong&quot; side then it's not included in the output.</li>
<li><code>front_face</code>: The &quot;front&quot; of the triangle depends on the order that the vertex
data is specified, it can be &quot;clockwise&quot; or &quot;counterclockwise&quot; (that's
&quot;widdershins&quot; for all our UK friends). This decision is basically arbitrary,
your models can go either way as long as they match what you define here.</li>
<li><code>depth_clamping</code>: If a thing is off the screen in X or Y we're not going to
see it, but what about the Z direction? If this is false then things that are
&quot;out of bounds&quot; in the Z direction get culled. If this is true then they get
their Z position clamped, so they end up included in the output.</li>
<li><code>depth_bias</code>: An optional parameter that's for when you need to draw things
very closely to one other in the Z direction. Without this you can get a very
bad looking effect called &quot;z-fighting&quot; where two elements become incorrectly
mixed together visually
(<a href="http://farm8.staticflickr.com/7355/8872454389_b82ae11d77_o.png">pic</a>). This
lets you apply some <a href="https://www.khronos.org/registry/vulkan/specs/1.0/html/vkspec.html#primsrast-depthbias">complicated
math</a>
to compensate for such a situation. Another one of those &quot;we'll get to it
later&quot; things, so we specify <code>None</code> to start.</li>
<li><code>conservative</code>: This is a <a href="https://developer.nvidia.com/content/dont-be-conservative-conservative-rasterization">neat graphics
extension</a>
that basically lets more fragments be generated per geometry unit, which can
lead to a much better result, because the output appears more &quot;smoothly&quot; (see
the pics in that article to understand what I'm trying to say). There's
probably a reasonable number of GPUs that might be running gfx-hal that
<em>wouldn't</em> support this extension though, so we won't request it starting out,
because with just one triangle it doesn't make a difference in the scene.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let rasterizer = Rasterizer {
        depth_clamping: false,
        polygon_mode: PolygonMode::Fill,
        cull_face: Face::NONE,
        front_face: FrontFace::Clockwise,
        depth_bias: None,
        conservative: false,
      };
#}</code></pre></pre>
<a class="header" href="#fragment-shader" id="fragment-shader"><h2>Fragment Shader</h2></a>
<p>So the rasterizer turned all of our geometry elements into pixel locations for
us, now the final shader runs. It takes &quot;some data&quot; and picks a color for this
&quot;fragment&quot;. A fragment is like a <em>part</em> of a pixel. Depending on the full scene,
more than one fragment can end up in the same pixel, and then they'll get
blended together. You don't know what the pixel will finally be until all of the
fragments that touch that pixel are done.</p>
<p>The actual data that the fragment shader gets is mostly whatever the previous
stages of the pipeline have output. There's no specific format and there's no
&quot;FragmentShaderDesc&quot; type that you set up on the CPU side. It's all defined in
your shader files. Any per-fragment values have to come through the previous
stages of the pipeline, starting back at the Vertex Shader. There is the ability
to have global, read only data (as a Push Constant or Uniform), but any
per-fragment data has to come through the whole pipeline process.</p>
<p>A single geometry element can have many fragments. Imagine a triangle that goes
from the bottom left, to the top left, to the top right. There's only three
vertices, but <em>half the screen</em> is covered in fragments. The pipeline
interpolates the values for any fragment that's not directly from a vertex
(which is almost every fragment ever, honestly). That might sound kinda spooky,
but the weird part is that it works really well even once textures and stuff are
involved.</p>
<a class="header" href="#multisampling" id="multisampling"><h3>Multisampling</h3></a>
<p>Sometimes you'll get edges in your pictures that look &quot;jagged&quot;. The eyes can
pick up where a long line is jumping from one pixel to the next if it's almost
but not quite vertical or horizontal. Fixing that is called &quot;anti-aliasing&quot;, and
there's more than one way to do it.</p>
<p>The pipeline in <code>gfx-hal</code> has a parameter for &quot;multisampling&quot;, where instead of
computing fragments on a pixel basis, you compute them on a sub-pixel basis and
average the results. You're basically just throwing computational power at the
problem to try and get a more accurate result. Naturally, if you do enable
multisampling, you want to allow for a user to turn such a feature off if they
don't have as good of a graphics card. We won't enable it for now, because
adding it in touches just a little bit of the swapchain, the render pass, the
pipeline, anything that has to do with images. We can do that as lesson of its
own soon.</p>
<a class="header" href="#depth-testing" id="depth-testing"><h3>Depth Testing</h3></a>
<p>This is actually not <em>specifically</em> part of the fragment shader, it's a step
after the fragment shader but before the color blending. There's no space for
that on our handy diagram, so we'll talk about it right here. Basically, in
addition to having colors, an image also has depth values for each pixel (we've
touched on this a bit before). After a fragment shader runs and <em>would</em> perform
a change there's a depth test, and you can determine what actual change, if any,
goes into effect. Or you can enable <a href="http://vulkan-spec-chunked.ahcox.com/ch25s04.html">early fragment test
mode</a> if you want, it's one
of <a href="http://vulkan-spec-chunked.ahcox.com/ch25s01.html">many operations</a> that can
potentially discard a fragment.</p>
<p>As you're probably getting sick of hearing at this point, we're not using depth
testing right now.</p>
<p>Note that there's two different structs called <code>DepthStencilDesc</code> in the
<code>gfx-hal</code> crate. The one in the <code>image</code> module is deprecated old nonsense, we
want to be sure to import the one from the <code>pso</code> module.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let depth_stencil = DepthStencilDesc {
        depth: DepthTest::Off,
        depth_bounds: false,
        stencil: StencilTest::Off,
      };
#}</code></pre></pre>
<a class="header" href="#color-blending" id="color-blending"><h2>Color Blending</h2></a>
<p>The final stage is color blending. Since we're doing 3d graphics, sometimes one
thing will need to appear &quot;in front of&quot; another. If it's fully opaque you just
draw the closer thing, but sometimes you get fragments that aren't fully opaque,
and so you blend the closer and farther thing. We can describe how we want that
to happen.</p>
<p>Except we're not doing blending stuff so we're going to totally ignore the
&quot;current destination value&quot; and only take the &quot;source value&quot;.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let blender = {
        let blend_state = BlendState::On {
          color: BlendOp::Add {
            src: Factor::One,
            dst: Factor::Zero,
          },
          alpha: BlendOp::Add {
            src: Factor::One,
            dst: Factor::Zero,
          },
        };
        BlendDesc {
          logic_op: Some(LogicOp::Copy),
          targets: vec![ColorBlendDesc(ColorMask::ALL, blend_state)],
        }
      };
#}</code></pre></pre>
<a class="header" href="#more-things-to-define" id="more-things-to-define"><h2>More Things To Define</h2></a>
<p>You thought we were done! Ha, if only.</p>
<a class="header" href="#bakedstates" id="bakedstates"><h3>BakedStates</h3></a>
<p>We need to define</p>
<ul>
<li><code>viewport</code>: Defines part of the whole
<a href="https://renderdoc.org/vkspec_chunked/chap25.html#vertexpostproc-viewport">viewport</a>
process. Right now <code>gfx-hal</code> doesn't support more than one viewport, but it's
on the list of TODOs for 0.2.</li>
<li><code>scissor</code>: Defines the params for the <a href="https://renderdoc.org/vkspec_chunked/chap27.html#fragops-scissor">scissor
test</a>, which
takes in 2d framebuffer coordinates and cancels a fragment if it falls outside
the scissor area. This is also going to eventually allow for more than one
scissor areas, but it's not there yet.</li>
<li><code>blend_color</code>: This is a static color to blend over the whole image. You
probably don't want this most of the time, since it's baked into the whole
pipeline. For dynamic color blend effects (eg: flashing the screen red when an
attack hits) you'd put that in as part of your fragment shader.</li>
<li><code>depth_bounds</code>: This defines the limits of that depth test thing.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let baked_states = BakedStates {
        viewport: Some(Viewport {
          rect: extent.to_extent().rect(),
          depth: (0.0..1.0),
        }),
        scissor: Some(extent.to_extent().rect()),
        blend_color: None,
        depth_bounds: None,
      };
#}</code></pre></pre>
<a class="header" href="#non-buffer-data-sources" id="non-buffer-data-sources"><h3>Non-Buffer Data Sources</h3></a>
<p>Data for the graphics pipeline <em>can</em> come from things other than the vertex
buffer. We're not doing that here, but we still have to <em>say</em> that we're not
doing it here.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let bindings = Vec::&lt;DescriptorSetLayoutBinding&gt;::new();
      let immutable_samplers = Vec::&lt;&lt;back::Backend as Backend&gt;::Sampler&gt;::new();
      let descriptor_set_layouts: Vec&lt;&lt;back::Backend as Backend&gt;::DescriptorSetLayout&gt; = vec![unsafe {
        device
          .create_descriptor_set_layout(bindings, immutable_samplers)
          .map_err(|_| &quot;Couldn't make a DescriptorSetLayout&quot;)?
      }];
      let push_constants = Vec::&lt;(ShaderStageFlags, core::ops::Range&lt;u32&gt;)&gt;::new();
      let layout = unsafe {
        device
          .create_pipeline_layout(&amp;descriptor_set_layouts, push_constants)
          .map_err(|_| &quot;Couldn't create a pipeline layout&quot;)?
      };
#}</code></pre></pre>
<a class="header" href="#graphics-pipeline" id="graphics-pipeline"><h2>Graphics Pipeline</h2></a>
<p>We can finally, <em>finally</em> make that graphics pipeline. We use all the stuff
declared so far, and a few more filler arguments that are unimportant to us
right now, to make a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.GraphicsPipelineDesc.html">GraphicsPipelineDesc</a>.
That gets passed to
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#method.create_graphics_pipeline">Device::create_graphics_pipeline</a>.
We could optionally specify a pipeline cache too, but we don't have such a thing
yet.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let gfx_pipeline = {
        let desc = GraphicsPipelineDesc {
          shaders,
          rasterizer,
          vertex_buffers,
          attributes,
          input_assembler,
          blender,
          depth_stencil,
          multisampling: None,
          baked_states,
          layout: &amp;layout,
          subpass: Subpass {
            index: 0,
            main_pass: render_pass,
          },
          flags: PipelineCreationFlags::empty(),
          parent: BasePipeline::None,
        };

        unsafe {
          device
            .create_graphics_pipeline(&amp;desc, None)
            .map_err(|_| &quot;Couldn't create a graphics pipeline!&quot;)?
        }
      };
#}</code></pre></pre>
<a class="header" href="#backing-out-of-create_pipeline" id="backing-out-of-create_pipeline"><h2>Backing Out Of <code>create_pipeline</code></h2></a>
<p>Once that's done we go up a level, destroy our shader modules, and then return
what we've built to the caller.</p>
<a class="header" href="#define-a-buffer-for-vertex-data" id="define-a-buffer-for-vertex-data"><h1>Define A Buffer For Vertex Data</h1></a>
<p>So within <code>HalState::new</code> we've made some pipeline bits:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // Build our pipeline and vertex buffer
    let (descriptor_set_layouts, pipeline_layout, graphics_pipeline) = Self::create_pipeline(&amp;mut device, extent, &amp;render_pass)?;
#}</code></pre></pre>
<p>It said that it's going to use a buffer, but we need to make that buffer separately.</p>
<a class="header" href="#make-a-buffer-and-some-memory" id="make-a-buffer-and-some-memory"><h2>Make A Buffer And Some Memory</h2></a>
<p>First we ask the Device to please make us a Buffer, which is basically just
another &quot;handle&quot; thing.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      const F32_XY_TRIANGLE: u64 = (size_of::&lt;f32&gt;() * 2 * 3) as u64;
      let mut buffer = device
        .create_buffer(F32_XY_TRIANGLE, BufferUsage::VERTEX)
        .map_err(|_| &quot;Couldn't create a buffer for the vertices&quot;)?;
#}</code></pre></pre>
<p>Now that we have a buffer we can ask what the requirements for the buffer are.
It might seem strange to make a thing and <em>then</em> ask what the requirements for it
are, but that's how you do it.</p>
<p>Using the requirements we can get a &quot;memory type ID&quot;, which allows us to
allocate some memory to go with this buffer. It's certainly some <em>weird</em> looking
code, but just go with it.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let requirements = device.get_buffer_requirements(&amp;buffer);
      let memory_type_id = adapter
        .physical_device
        .memory_properties()
        .memory_types
        .iter()
        .enumerate()
        .find(|&amp;(id, memory_type)| {
          requirements.type_mask &amp; (1 &lt;&lt; id) != 0 &amp;&amp; memory_type.properties.contains(Properties::CPU_VISIBLE)
        })
        .map(|(id, _)| MemoryTypeId(id))
        .ok_or(&quot;Couldn't find a memory type to support the vertex buffer!&quot;)?;
      let memory = device
        .allocate_memory(memory_type_id, requirements.size)
        .map_err(|_| &quot;Couldn't allocate vertex buffer memory&quot;)?;
#}</code></pre></pre>
<p>And once that is allocated, we can bind the buffer to the memory that goes with
it.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      device
        .bind_buffer_memory(&amp;memory, 0, &amp;mut buffer)
        .map_err(|_| &quot;Couldn't bind the buffer memory!&quot;)?;
#}</code></pre></pre>
<a class="header" href="#update-the-halstate-struct" id="update-the-halstate-struct"><h2>Update The <code>HalState</code> Struct</h2></a>
<p>With these new things in hand, we need to add to the <code>struct</code> definition</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct HalState {
  buffer: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::Buffer&gt;,
  memory: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::Memory&gt;,
  descriptor_set_layouts: Vec&lt;&lt;back::Backend as Backend&gt;::DescriptorSetLayout&gt;,
  pipeline_layout: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::PipelineLayout&gt;,
  graphics_pipeline: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::GraphicsPipeline&gt;,
  requirements: Requirements,
  current_frame: usize,
  frames_in_flight: usize,
  in_flight_fences: Vec&lt;&lt;back::Backend as Backend&gt;::Fence&gt;,
  render_finished_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt;,
  image_available_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt;,
  command_buffers: Vec&lt;CommandBuffer&lt;back::Backend, Graphics, MultiShot, Primary&gt;&gt;,
  command_pool: ManuallyDrop&lt;CommandPool&lt;back::Backend, Graphics&gt;&gt;,
  framebuffers: Vec&lt;&lt;back::Backend as Backend&gt;::Framebuffer&gt;,
  image_views: Vec&lt;(&lt;back::Backend as Backend&gt;::ImageView)&gt;,
  render_pass: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::RenderPass&gt;,
  render_area: Rect,
  queue_group: QueueGroup&lt;back::Backend, Graphics&gt;,
  swapchain: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::Swapchain&gt;,
  device: ManuallyDrop&lt;back::Device&gt;,
  _adapter: Adapter&lt;back::Backend&gt;,
  _surface: &lt;back::Backend as Backend&gt;::Surface,
  _instance: ManuallyDrop&lt;back::Instance&gt;,
}
#}</code></pre></pre>
<p>And also make all the appropriate changes to the <code>Drop</code> impl, which you're smart
enough to do yourself at this point.</p>
<a class="header" href="#rendering-a-triangle" id="rendering-a-triangle"><h1>Rendering A Triangle</h1></a>
<p>Now that <code>HalState</code> supports it, actually rendering a triangle is pretty simple.
We just change our <code>do_the_render</code> function.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn do_the_render(hal_state: &amp;mut HalState, local_state: &amp;LocalState) -&gt; Result&lt;(), &amp;'static str&gt; {
  let x = ((local_state.mouse_x / local_state.frame_width) * 2.0) - 1.0;
  let y = ((local_state.mouse_y / local_state.frame_height) * 2.0) - 1.0;
  let triangle = Triangle {
    points: [[-0.5, 0.5], [-0.5, -0.5], [x as f32, y as f32]],
  };
  hal_state.draw_triangle_frame(triangle)
}
#}</code></pre></pre>
<p>Those coordinates are given in a 0.0 to 1.0 system, with +X going from left to
right, and +Y going from top to bottom. Two points of the triangle are fixed,
and the third one follows the mouse around as it moves. Looks like this:</p>
<p><img src="images/triangle-intro-complete.png" alt="triangle-intro-complete" /></p>
<p>You can find the full code file in the <code>examples/</code> directory of the repo.</p>
<a class="header" href="#shaders" id="shaders"><h1>Shaders</h1></a>
<p>I know you've been itching for a short lesson, so let's do a short lesson.</p>
<p>This time we're talking more about Shaders. <a href="https://www.youtube.com/watch?v=Kh0Y2hVe_bw">What are
shaders?</a> We just don't know.</p>
<a class="header" href="#glsl-and-spirv" id="glsl-and-spirv"><h1>GLSL and SPIRV</h1></a>
<p>Technically you can use any number of shader languages with <code>gfx-hal</code> as long as
they can compile to SPIRV. There's many options, and even an LLVM/SPIRV
converter (<a href="https://github.com/KhronosGroup/SPIRV-LLVM">really</a>), so you could
<em>potentially</em> use a very wide range of options.</p>
<p>For <strong>now</strong> now we're using a slightly special variant of GLSL, which stands for
&quot;open Graphics Library Shader Language&quot;, be cause it's technically the official
language for OpenGL, not Vulkan. Still, everyone already knew GLSL when Vulkan
came out, and it's actually quite good at what it does, so they kept the textual
format and just specified how to compile it to a new binary format.</p>
<p>The <code>shaderc-rs</code> crate that we're using compiles the textual GLSL into the
binary SPIRV for us. More precisely, the <code>shaderc-rs</code> crate's <code>build.rs</code> file
downloads the source of the <code>shaderc</code> C++ program and builds that, then puts
those binaries deep in your <code>target/</code> directory, then when you call the crate it
invokes that program to do the actual compilation. And it fails if the binaries
aren't there. The crate itself doesn't know how to do any compilation at all.</p>
<p>If you think that sounds crazy, you're right. People are working on better
solutions, <a href="https://www.youtube.com/watch?v=yoy4_h7Pb3M">top men</a>, I assure you,
but until then this is the best system we've got.</p>
<p>Now there's a whole lot that can be said about GLSL. You can seriously write
<a href="https://thebookofshaders.com/">books</a> and <a href="http://www.iquilezles.org/">blogs</a>
and <a href="https://www.shadertoy.com/">demo site</a> after <a href="https://www.vertexshaderart.com/">demo
site</a> after <a href="http://glslsandbox.com/">demo
site</a> after <a href="https://www.interactiveshaderformat.com/">demo
site</a> for just GLSL.</p>
<p>We'll cover some <em>introduction</em> level GLSL in this lesson, and it's fairly
straight forward so I don't think we'll need to specifically focus on it too
much later on. It's a &quot;based on C&quot; language with minimal extensibility, so you
can learn all the limits of the language itself fairly fast.</p>
<p>However, even once you quickly pick up all the rules of the language, you should
still read the books and blogs and sites and things like that because they teach
you how to actually apply those simple rules. Like the difference between
learning how to play chess and learning to be good at playing chess.</p>
<a class="header" href="#version" id="version"><h2>Version</h2></a>
<p>The first line of all your shaders will generally be</p>
<pre><code class="language-glsl">#version 450
</code></pre>
<p>There's technically a whole lot of GLSL versions, because each release of OpenGL
has a GLSL that goes with it, but since we're not <em>really</em> using OpenGL, we just
pretend we're using version 450 since that's what <code>shaderc</code> understands.</p>
<a class="header" href="#inputs-and-outputs" id="inputs-and-outputs"><h2>Inputs and Outputs</h2></a>
<p>Next you generally want to specify your inputs and outputs.</p>
<p>In normal GLSL you don't have to specify a layout value for each input and
output, but for the GLSL that we want to compile to SPIRV you are <em>required</em> to
give a layout location for each. The general format is</p>
<pre><code class="language-glsl">layout (location = INDEX) DIRECTION TYPE NAME;
</code></pre>
<ul>
<li>The <code>INDEX</code> values are just integer values. They're basically arbitrary, but
your Rust code and GLSL code must <strong>all</strong> agree on whatever you pick.
<ul>
<li>With a Vertex shader, the <code>AttributeDesc</code> determines the locations for
passing CPU side data into into GLSL data at the start of the process.</li>
<li>With a Fragment shader, the <code>SubpassDesc</code> determines the locations for
fragment outputs becoming framebuffer data at the end of the process.</li>
<li><em>Between</em> shaders the locations and variable outputs from one stage need to
match the locations and names of the next stage any time you want to pass
data between rendering stages.</li>
<li>There's a (rather small) limit on how many location slots you're allowed,
and if you use a struct type it can consume more than one slot. <a href="https://www.khronos.org/opengl/wiki/Layout_Qualifier_(GLSL)#Program_separation_linkage">The
Khronos
wiki</a>
has some more about the rules here if you want to know the exact details. I
don't expect any of our early lessons to hit these limits.</li>
</ul>
</li>
<li>The <code>DIRECTION</code> is a keyword: one of <code>in</code>, <code>out</code>, or <code>uniform</code>. Technically
there are other things you could put here but they're aliases for one of those
three so let's stick to the basics. An <code>in</code> value comes from a previous stage
(or the vertex buffer data, for the Vertex Shader), and an <code>out</code> value goes to
the next stage (or the framebuffer, for the Fragment Shader). A <code>uniform</code> is a
special kind of read-only value that we'll get to a little farther down the page.</li>
<li>The <code>TYPE</code> is a variable type, using C style names, so it's stuff like
<code>float</code>, <code>int</code>, and <code>uint</code>, not <code>f32</code>, <code>i32</code>, and <code>u32</code>. There's also <code>vecN</code>
where N is 2, 3, or 4 if you want a float vector, and you can have integer
vectors and such as well. You can even declare structs using the C style where
the block of fields is written <code>{ type1 field1; type2 field2; ... }</code>.</li>
<li>The <code>NAME</code> is just a name for the variable. Usually variable names are
camelCase with GLSL code that you find in the wild, but snake_case is fine too.</li>
</ul>
<p>In GLSL you'd normally have access to a few magical values that you can read and
write from, but not all of that translates cleanly with the <code>shaderc</code> compiler.
In our case, the thing that we need to be the most aware of is that instead of
writing to a magical and undeclared <code>gl_Position</code> value during the vertex shader
to determine a vertex's on-screen position, we need to declare and use a special
output like this:</p>
<pre><code class="language-glsl">layout (location = 0) out gl_PerVertex {
  vec4 gl_Position;
};
</code></pre>
<a class="header" href="#functions" id="functions"><h2>Functions</h2></a>
<p>Your GLSL can have any number of functions that you like, declared in the C
style where the output is on the left, then the function names and arguments.</p>
<p>At minimum each shader needs an &quot;entry point&quot;, as you may recall from the
pipeline declaration we did. By tradition it's just called <code>main</code>, and that's
probably good enough so we'll go with that in our shaders.</p>
<a class="header" href="#final-note" id="final-note"><h2>Final Note</h2></a>
<p>Just saying, in a normal project you'd probably want to have your shader code in
separate files, not directly as string constants. If you use a file extension
like .glsl, or maybe .vert and .frag, then your editor will probably have a mode
for syntax highlighting and other support for the GLSL format. That's a lot
better than a string literal. Somewhere in your Rust code you use the
<a href="https://doc.rust-lang.org/std/macro.include_str.html">include_str!</a> macro, like
this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
static VERT_SRC: &amp;'static str = include_str!(&quot;dwarf.vert&quot;);
static FRAG_SRC: &amp;'static str = include_str!(&quot;dwarf.frag&quot;);
#}</code></pre></pre>
<p>And then that's how you'll have your shader source available.</p>
<p>Please understand that I'm using embedded string literals just because it's
easiest <em>for example purposes</em> to have each example be a single file at a time.</p>
<a class="header" href="#adding-a-vertex-attribute-for-color" id="adding-a-vertex-attribute-for-color"><h1>Adding A Vertex Attribute For Color</h1></a>
<p>So let's add a second attribute to our vertex data. We'll add an attribute for
color. Make a fancy rainbow triangle.</p>
<a class="header" href="#update-shader-code" id="update-shader-code"><h2>Update Shader Code</h2></a>
<p>First we update our shaders to use the new color attribute. A full color output
is of course RGBA (vec4), but as input we'll just give RGB and then let the
fragment shader add that A=1.0 in its output.</p>
<p>So our <em>input</em> locations are 0 (position) and 1 (color), and our <em>output</em>
locations are also 0 (the magical gl_Position) and 1 (frag_color for the
fragment shader). The fact that the position information is location 0 for both
inputs and outputs isn't special, you could swap it around if you wanted. Like
with the previous lesson, our fragment shader just promotes the 2D input into a
flat 3D output (which is actually a <code>vec4</code>, and I'll get to why that is in
the lesson on coordinate spaces).</p>
<p>The other line of <code>main</code>, saying <code>frag_color = color;</code> might look a little
silly, but there's a lot of magic wrapped up in that shorthand. It's <em>not</em> a
direct copy of the data, it's what makes that interpolation happen when more
than one fragment is generated by a vertex. If we wanted to have a direct copy
without interpolation we could specify the <code>flat</code> keyword on the output here
(eg: <code>layout (location = 1) flat out vec3 frag_color;</code>). In that case, each
fragment will use the vertex shader outputs of a particular vertex element (the
spec calls it the &quot;<a href="https://www.khronos.org/opengl/wiki/Primitive#Provoking_vertex">provoking
index</a>&quot;). Since
integer values can't be interpolated, you actually <em>must</em> specify <code>flat</code> with
integers that pass between shader stages.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const VERTEX_SOURCE: &amp;str = &quot;#version 450
layout (location = 0) in vec2 position;
layout (location = 1) in vec3 color;

layout (location = 0) out gl_PerVertex {
  vec4 gl_Position;
};
layout (location = 1) out vec3 frag_color;

void main()
{
  gl_Position = vec4(position, 0.0, 1.0);
  frag_color = color;
}&quot;;
#}</code></pre></pre>
<p>For our fragment shader, we accept a single input, with the <em>exact same
location</em> as the output from the vertex shader. That's how the system knows to
make them match. (In some older GLSL versions you also could match up variables
by name, but SPIRV only goes by location.) This means that we actually don't
have a location 0 input for our fragment shader, and that's totally fine. Our
output is at location 0 (matching out <code>SubpassDesc</code>) vec4 (which is &quot;RGBA&quot;,
since it'll be treated as a color). We'll sensibly call it <code>color</code>. We just
promote the RGB color into an RGBA color by giving it an alpha of 1.0 (&quot;fully
opaque&quot;).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const FRAGMENT_SOURCE: &amp;str = &quot;#version 450
layout (location = 1) in vec3 frag_color;

layout (location = 0) out vec4 color;

void main()
{
  color = vec4(frag_color,1.0);
}&quot;;
#}</code></pre></pre>
<a class="header" href="#make-triangle-produce-the-new-data-format" id="make-triangle-produce-the-new-data-format"><h2>Make <code>Triangle</code> Produce The New Data Format</h2></a>
<p>Next we'll add a method to our <code>Triangle</code> type so that it can give us the
positions interleaved with some color data. We'll just have one corner be red,
one be green, and one blue.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn vertex_attributes(self) -&gt; [f32; 3 * (2 + 3)] {
    let [[a, b], [c, d], [e, f]] = self.points;
    [
      a, b, 1.0, 0.0, 0.0, // red
      c, d, 0.0, 1.0, 0.0, // green
      e, f, 0.0, 0.0, 1.0, // blue
    ]
  }
#}</code></pre></pre>
<a class="header" href="#create-a-pipeline-with-more-attributes" id="create-a-pipeline-with-more-attributes"><h2>Create A Pipeline With More Attributes</h2></a>
<p>Now we want to support the color attribute in our <code>create_pipeline</code> function.
That's pretty easy, we just change how the the <code>vertex_buffer</code> and <code>attributes</code>
values are defined.</p>
<ul>
<li><code>vertex_buffers</code> needs to have a bigger <code>stride</code> than before, because the
stride between elements is now &quot;five floats&quot; instead of the previous &quot;two
floats&quot;. We'll also cast the <code>usize</code> to the <code>ElemStride</code> type alias instead of
<code>u32</code>. It's the same type, but it lets future readers know that we probably
knew what we were doing (but only probably).</li>
<li><code>attributes</code> needs an entire second <code>AttributeDesc</code> entry to describe the
color data. The location is easy enough to understand, as is the binding. The
element format is now <code>Rgb32Float</code>, since this is three floats, and the offset
is the sum of the previous attributes up to this point.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let vertex_buffers: Vec&lt;VertexBufferDesc&gt; = vec![VertexBufferDesc {
        binding: 0,
        stride: (size_of::&lt;f32&gt;() * 5) as ElemStride,
        rate: 0,
      }];
      let position_attribute = AttributeDesc {
        location: 0,
        binding: 0,
        element: Element {
          format: Format::Rg32Float,
          offset: 0,
        },
      };
      let color_attribute = AttributeDesc {
        location: 1,
        binding: 0,
        element: Element {
          format: Format::Rgb32Float,
          offset: (size_of::&lt;f32&gt;() * 2) as ElemOffset,
        },
      };
      let attributes: Vec&lt;AttributeDesc&gt; = vec![position_attribute, color_attribute];
#}</code></pre></pre>
<p>This setup, with <code>[(position, color), (position, color), ..]</code> is called
&quot;interleaved&quot; data. You can also have non-interleaved data by laying out all the
positions and then all the colors, and so on. Then you adjust your <code>stride</code> and
<code>offset</code> value to match that. We'll use interleaved data just because I
personally think it's easier to think about, and even the <a href="https://www.khronos.org/opengl/wiki/Vertex_Specification_Best_Practices#Formatting_VBO_Data">Khronos
wiki</a>
doesn't take a clear stance either way.</p>
<a class="header" href="#colors" id="colors"><h2>Colors!</h2></a>
<p>That's pretty much it. Didn't I promise that <em>eventually</em> it'd get easier to
enhance the program? That was pretty easy.</p>
<p>So easy... that we'll keep going and add a little bit more to the lesson.</p>
<a class="header" href="#push-constants" id="push-constants"><h1>Push Constants</h1></a>
<p>Last lesson I said that most of the time you don't re-upload vertex data every
frame. That's because usually you'd have a single model (an &quot;iconic triangle&quot; if
you will) and then you'd tell the shader what animation frame, or position, or
global light level, or other detail to use during the drawing without touching
the model data directly. It doesn't seem like a big difference right now when
there's only 3 vertex entries in one triangle, but if there's <em>thousands</em> of
vertex entries, and there's <em>tens</em> of copies of that model that have to show up
in the scene, well you'd rather be doing all that math on your GPU (with dozens
of ALUs) than on your CPU (with only a handful of ALUs). That's like, the whole
<em>point</em> of the GPU after all.</p>
<p>So how do we know about these special global values during a draw call? They get
placed into things called <em>uniforms</em>, that's what the <code>uniform</code> keyword is for
in GLSL. When GLSL was used for OpenGL there were just &quot;uniforms&quot;, but with the
introduction of Vulkan now we've got both &quot;Uniform Buffers&quot; (like the old
uniforms) and also &quot;Push Constants&quot; (a fancy new thing). Uniforms get set before
a draw call and then they're a fixed, read-only value for that entire draw call.
No changes per-vertex or per-fragment or anything else. Any shader can access
that uniform, if it's been correctly configured in your pipeline setup.</p>
<p>As I said, push constants are newer, so older 3D books might not mention them if
you pick one up for some light technical reading, but they work the same way as
a uniform buffer. The biggest difference is that push constants can be assumed
to be significantly faster to update (because of where their physical memory is
on the GPU's card), and also they are somewhat easier to use (because there's no
faffing about with buffers), but you only get a <em>very</em> limited amount of push
constant space. With <code>gfx-hal</code> you can only use 128 <strong>bytes</strong> of push constant
space. The Vulkan spec assures that you have at least that much, and many
cards offer more these days, but currently <code>gfx-hal</code> has no way to ask the
graphics card exactly how much it supports. It's on the TODO list for 0.2.</p>
<p>As a demo of how to use push constants, we'll record a <code>std::time::Instant</code> at
the creation of our <code>HalState</code> and then use the time since that Instant to shift
our triangle towards black.</p>
<a class="header" href="#add-it-to-our-halstate" id="add-it-to-our-halstate"><h2>Add It To Our <code>HalState</code></h2></a>
<p>We first add an
<a href="https://doc.rust-lang.org/std/time/struct.Instant.html">Instant</a> field to our
<code>HalState</code> and then use <code>Instant::now</code> to get an Instant while we're
initializing our HalState value.</p>
<p>Before we record the command buffer, we'll decide the current time value as an
<code>f32</code>. Please note that <code>f32</code> is actually a <a href="https://randomascii.wordpress.com/2012/02/13/dont-store-that-in-a-float/">very
bad</a>
way to store time in the long term (that's why <code>Duration</code> has two integer values
instead of a single float value), but it's fine for our short term animation
purposes here.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // DETERMINE THE TIME DATA
    let duration = Instant::now().duration_since(self.creation_instant);
    let time_f32 = duration.as_secs() as f32 + duration.subsec_nanos() as f32 * 1e-9;
#}</code></pre></pre>
<p>And just after we bind the vertex buffer, we also push the graphics constant:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        encoder.bind_vertex_buffers(0, buffers);
        encoder.push_graphics_constants(
          &amp;self.pipeline_layout,
          ShaderStageFlags::FRAGMENT,
          0,
          &amp;[time_f32.to_bits()],
        );
#}</code></pre></pre>
<p>The important part is that we have to remember to adjust our pipeline definition
as well. Remember how the <code>push_constants</code> value was an empty Vec? We need one
entry now (one push constant).</p>
<p>The format of the Vec is pretty easy: You give <code>(ShaderStageFlags, Range)</code>
tuples, with the ShaderStageFlags signifying what stage the push const will
appear in, and the Range specifying what range of that <code>push_graphics_constants</code>
slice we made will be accessed during that stage. Our stage is
<code>ShaderStageFlags::FRAGMENT</code>, and our range is to just use index 0 (which is
<code>0..1</code> in Rust's Range notation, don't forget).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let push_constants = vec![(ShaderStageFlags::FRAGMENT, 0..1)];
      let layout = unsafe {
        device
          .create_pipeline_layout(&amp;descriptor_set_layouts, push_constants)
          .map_err(|_| &quot;Couldn't create a pipeline layout&quot;)?
      };
#}</code></pre></pre>
<a class="header" href="#add-it-to-the-shader-code" id="add-it-to-the-shader-code"><h2>Add It To The Shader Code</h2></a>
<p>Adding the push constants to a shader is pretty easy, but there are few rules.
All of your push constants appear in a single block with the special layout
value of <code>push_constant</code>. This block isn't <code>in</code> or <code>out</code>, instead it's
<code>uniform</code>. After that you give a name for the block type, the block itself, and then
the name that we're going to access it under. If you haven't programmed in C
before this, it may seem weird, but they think it's normal. We just have to go
with it.</p>
<p>Since we want a single <code>f32</code> to be the time, we define it as a block that holds
a single <code>float</code> value (the GLSL equivalent) which we call <code>time</code>. Then we
take <code>push.time</code> (think of it like they're all stored within a global <code>push</code>
struct), do some funny math on that so that it ends up as a 0.0 to 1.0 value
(since color channels are supposed to be in that range), and make a vec4. We can
multiply the vec4 from our time with the vec4 for our <code>frag_color</code>, and it does
a component-wise multiplication (a.x * b.x, a.y * b.y, etc). Then we shove the
result out the door. Bam, now our triangle shifts between black and rainbow.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const FRAGMENT_SOURCE: &amp;str = &quot;#version 450
layout (push_constant) uniform PushConsts {
  float time;
} push;

layout (location = 1) in vec3 frag_color;

layout (location = 0) out vec4 color;

void main()
{
  float time01 = -0.9 * abs(sin(push.time * 0.9)) + 0.9;
  color = vec4(frag_color,1.0) * vec4(time01,time01,time01,1.0);
}&quot;;
#}</code></pre></pre>
<a class="header" href="#uniform-buffers" id="uniform-buffers"><h1>Uniform Buffers</h1></a>
<p>Like I said, there's a harsh limit on your push constant space. If you want more
global data than you can fit into your push constants you need to setup a
Uniform Buffer.</p>
<p>However, I also promised to keep this lesson short, and we'll be using uniform
buffers soon enough I'm sure, so we <em>won't</em> go into them right now. Knowing
about push constants already teaches you about the general idea of uniform data,
so we've covered enough to stop here.</p>
<p><img src="images/shaders-complete.png" alt="shaders-complete" /></p>
<a class="header" href="#textures" id="textures"><h1>Textures</h1></a>
<p>You can draw a lot with just triangles and colors. Do a search for &quot;low poly
art&quot; and you'll find a bunch of stuff that's just lots and lots of color shaded
triangles. Like the digital version of stained glass art. It's really cool.</p>
<p>But you can't make Skyrim or Smash Bros with just colored triangles. At some
point you want to stick a picture of a thing on those triangles. A picture that
you place onto a model is called a &quot;texture&quot;, even though really it's just a
normal image. In fact, you can use <code>gfx-hal</code> to render into an image, then keep
that image around and use it to texture your models.</p>
<p>A picture has &quot;pixels&quot;, and sometimes you'll hear about a texture having
&quot;texels&quot;. Just a way that some people distinguish between images intended for
final use and images intended for placement onto a model. The thing that's the
most special about textures is that since X, Y, and Z are already being used for
3D spatial positioning of a vertex, the position within a texture that it maps
to is called U and V. This is called <a href="https://en.wikipedia.org/wiki/UV_mapping">UV
Mapping</a> and it can get very
complicated if you have a single texture being wrapped around a 3D model.</p>
<p>As always, each stage of this is hard enough already, so we'll keep it simple.
This time out we're going to place a texture onto a &quot;Quad&quot; (two triangles
oriented to make a quadrilateral). Like before, part of the quad will follow the
mouse so that we can see it stretch around and even flip backwards when the
mouse moves &quot;behind&quot; the start of the quad.</p>
<p>What picture? Well I've drawn a pic of a friendly water pal in MS Paint, just
for this occasion. Here's a quarter-size sample:</p>
<p><img src="images/creature-smol.png" alt="creature-smol" /></p>
<a class="header" href="#making-a-quad" id="making-a-quad"><h1>Making A Quad</h1></a>
<p>So instead of having a <code>Triangle</code> type, we're going to have a <code>Quad</code> type. What
makes up a quad? Of course it's four points instead of three.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Copy)]
pub struct Quad {
  pub x: f32,
  pub y: f32,
  pub w: f32,
  pub h: f32,
}
#}</code></pre></pre>
<p>So if we have four &quot;real&quot; points, and we want to make two triangles... well we
need 3 points per triangle... We could just list out some of the points more
than once (scrub mode) or we could get fancy in how we tell the GPU to do it and
kick it up to a technique called &quot;Indexed Drawing&quot; (cool mode). The details of
that will be covered in a moment, right now we need to have a method to turn a
quad into some vertex data.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl Quad {
  pub fn vertex_attributes(self) -&gt; [f32; 4 * (2 + 3 + 2)] {
    let x = self.x;
    let y = self.y;
    let w = self.w;
    let h = self.h;
    #[cfg_attr(rustfmt, rustfmt_skip)]
    [
    // X    Y    R    G    B                  U    V
      x  , y+h, 1.0, 0.0, 0.0, /* red     */ 0.0, 1.0, /* bottom left */
      x  , y  , 0.0, 1.0, 0.0, /* green   */ 0.0, 0.0, /* top left */
      x+w, y  , 0.0, 0.0, 1.0, /* blue    */ 1.0, 0.0, /* bottom right */
      x+w, y+h, 1.0, 0.0, 1.0, /* magenta */ 1.0, 1.0, /* top right */
    ]
  }
}
#}</code></pre></pre>
<p>As you can see, we're approaching the limit of being able to specify it all as a
flat array. In future lessons we'll talk about having a proper Vertex type and
giving it fields so that it's easier to tell what parts are what and such. For a
single quad it's probably okay to do it like this.</p>
<p>So each vertex will have an XY position like before, and an RGB color like
before, and now we're adding a UV texture coordinate as well. We'll also have to
change around our pipeline setup to allow for the new vertex attribute.</p>
<p>Texture positions are always stored as 0.0 to 1.0 within the texture, U goes
horizontal (like X) and V is vertical (like Y). Within <code>gfx-hal</code>, the (0.0, 0.0)
position for UV coordinates is the <strong>top left corner</strong> of the image. Even if the
backend would normally use some other system, <code>gfx-hal</code> does the translations
necessary so that (0.0, 0.0) is the top left.</p>
<p>Note that some other graphics systems (mostly OpenGL) put the texture origin at
the <em>bottom</em> left instead! If you're trying out some shader code samples from
some other place and your images come out unexpectedly upside down, that's why.
You can compensate by flipping the image data before you upload it (I'll mention
that in a moment), or you can flip the computed coordinate before looking up the
data in the texture by using <code>1.0-V</code> instead of using <code>V</code> directly.</p>
<a class="header" href="#indexed-drawing" id="indexed-drawing"><h1>Indexed Drawing</h1></a>
<p>Indexed drawing is a way to save on vertex space by specifying the minimum
number of vertices in just any order within an array, and then also specifying
indexes into that array to describe the triangles themselves.</p>
<p>That might sound silly, at first. We save a little space on the vertex data that
we didn't specify twice, but then we have to give all the indexes, so are we
really saving much? Let's check.</p>
<p>Say we have 28 bytes per vertex (7 floats * 4 bytes each, that's what we have
right now), and also that indexes are given as <code>u16</code> values:</p>
<ul>
<li>If there's a Quad:
<ul>
<li>We reduce the vertex count from 6 to 4 (56 bytes saved)</li>
<li>We need to spend 6 indexes to describe the triangles (12 bytes used)</li>
<li>Net savings of 44 bytes per quad (56-12)</li>
</ul>
</li>
<li>If there's a Cube:
<ul>
<li>We reduce the vertex count from 36 to 8 (784 bytes saved)</li>
<li>We need to spend 36 indexes to describe the triangles (72 bytes used)</li>
<li>Net savings of 712 bytes per cube (784-72)</li>
</ul>
</li>
<li>As the model shape gets more complex, causing more triangles to share the same
vertex, the overall savings <em>improve</em>.</li>
</ul>
<p>So, yeah, that's totally sweet.</p>
<a class="header" href="#making-a-bufferbundle-type" id="making-a-bufferbundle-type"><h2>Making A <code>BufferBundle</code> Type</h2></a>
<p>First of all, now that we're having more than one buffer, we want to take that
buffer creation (declare buffer, check requirements, get memory, bind memory)
and pack it into its own thing. We'll call it a <code>BufferBundle</code>, because that
seems like a good enough name for a really generic sort of thing that we don't
even fully know how we'll use in the future.</p>
<p>The struct for it is very simple. We can even make it generic over the <code>Backend</code>
trait for maximum angle brackets in our code. (Rust is always better with more
angle brackets in the types, right?)</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct BufferBundle&lt;B: Backend, D: Device&lt;B&gt;&gt; {
  pub buffer: ManuallyDrop&lt;B::Buffer&gt;,
  pub requirements: Requirements,
  pub memory: ManuallyDrop&lt;B::Memory&gt;,
  pub phantom: PhantomData&lt;D&gt;,
}
#}</code></pre></pre>
<p>We'll make all the fields be <code>pub</code>, because (hot take) that's honestly the
better default for fields, unless you're trying to maintain some invariants with
the type. The <code>BufferBundle</code> isn't smart enough to have any invariants.</p>
<p>So we've got it generic over <code>Backend</code>, and then our methods will be using a
particular <code>Device</code>, and it'd be slightly insane to try and use a buffer between
two different device implementations, so we'll throw in a ðŸ‘»
<a href="https://doc.rust-lang.org/core/marker/struct.PhantomData.html">PhantomData</a> ðŸ‘»
so that things know we had a particular device in mind when we made the buffer.
Is there anything that PhantomData can't solve? I sure hope not. ðŸ‘»</p>
<p>Do we want this type to have any methods? Yeah, obviously, we want to be able to
make new ones. We'll just cut that code for making the vertex buffer and then
make it a little more buffer agnostic and reusable.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;B: Backend, D: Device&lt;B&gt;&gt; BufferBundle&lt;B, D&gt; {
  pub fn new(adapter: &amp;Adapter&lt;B&gt;, device: &amp;D, size: usize, usage: BufferUsage) -&gt; Result&lt;Self, &amp;'static str&gt; {
    unsafe {
      let mut buffer = device
        .create_buffer(size as u64, usage)
        .map_err(|_| &quot;Couldn't create a buffer!&quot;)?;
      let requirements = device.get_buffer_requirements(&amp;buffer);
      let memory_type_id = adapter
        .physical_device
        .memory_properties()
        .memory_types
        .iter()
        .enumerate()
        .find(|&amp;(id, memory_type)| {
          requirements.type_mask &amp; (1 &lt;&lt; id) != 0 &amp;&amp; memory_type.properties.contains(Properties::CPU_VISIBLE)
        })
        .map(|(id, _)| MemoryTypeId(id))
        .ok_or(&quot;Couldn't find a memory type to support the buffer!&quot;)?;
      let memory = device
        .allocate_memory(memory_type_id, requirements.size)
        .map_err(|_| &quot;Couldn't allocate buffer memory!&quot;)?;
      device
        .bind_buffer_memory(&amp;memory, 0, &amp;mut buffer)
        .map_err(|_| &quot;Couldn't bind the buffer memory!&quot;)?;
      Ok(Self {
        buffer: ManuallyDrop::new(buffer),
        requirements,
        memory: ManuallyDrop::new(memory),
        phantom: PhantomData,
      })
    }
  }
#}</code></pre></pre>
<p><strong>Note:</strong> In a program with many buffers you wouldn't want each buffer to be its
own memory allocation, because devices have a limit on the number of allocations
as well as on the total amount of allocated memory. However, implementing a
proper memory allocator is obviously way out of scope for right now, so we'll
just do the beginner thing.</p>
<p>Also we want to be able to throw them away when we're done. Question: Do we want
it to be <code>Drop</code>? Mmmm, no. But <code>HalState</code> is <code>Drop</code>, why not this too? Well,
<code>HalState</code> gets to be <code>Drop</code> because it's holding the <code>Device</code> field that's
needed to destroy all the other stuff it has. A <code>BufferBundle</code> has a PhantomData
for a device thing, but it isn't holding an <em>actual</em> <code>Device</code>, so it can't
perform a <code>Drop</code> on its own. <em>Should</em> it hold an actual device reference? I
think not. That'd make it really hard to store in our <code>HalState</code> alongside the
device field. The lifetimes would go crazy. So we'll just make a method to
<code>manually_drop</code> the type, and then it'll do the thing.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub unsafe fn manually_drop(&amp;self, device: &amp;D) {
    use core::ptr::read;
    device.destroy_buffer(ManuallyDrop::into_inner(read(&amp;self.buffer)));
    device.free_memory(ManuallyDrop::into_inner(read(&amp;self.memory)));
  }
}
#}</code></pre></pre>
<a class="header" href="#adding-bufferbundle-to-halstate" id="adding-bufferbundle-to-halstate"><h2>Adding <code>BufferBundle</code> To <code>HalState</code></h2></a>
<p>So now <code>HalState</code> wants two fields like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  vertices: BufferBundle&lt;back::Backend, back::Device&gt;,
  indexes: BufferBundle&lt;back::Backend, back::Device&gt;,
#}</code></pre></pre>
<p>Lokathor, why did we make BufferBundle be all generic and not have HalState be
all generic?</p>
<p>Because I tried that at first and doing the whole <code>HalState</code> generic gave me
some trouble at the time, so I just gave up on it. Obviously.</p>
<p>Creating these buffers is pretty easy:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    const F32_XY_RGB_UV_QUAD: usize = size_of::&lt;f32&gt;() * (2 + 3 + 2) * 4;
    let vertices = BufferBundle::new(&amp;adapter, &amp;device, F32_XY_RGB_UV_QUAD, BufferUsage::VERTEX)?;

    const U16_QUAD_INDICES: usize = size_of::&lt;u16&gt;() * 2 * 3;
    let indexes = BufferBundle::new(&amp;adapter, &amp;device, U16_QUAD_INDICES, BufferUsage::INDEX)?;
#}</code></pre></pre>
<p>And once we have an index buffer we can fill it up just once as part of our
<code>HalState</code> startup. Even if our quad changes from frame to frame, the indexes
don't, so we won't have to re-upload them each frame (the savings don't stop!)</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // Write the index data just once.
    unsafe {
      let mut data_target = device
        .acquire_mapping_writer(&amp;indexes.memory, 0..indexes.requirements.size)
        .map_err(|_| &quot;Failed to acquire an index buffer mapping writer!&quot;)?;
      const INDEX_DATA: &amp;[u16] = &amp;[0, 1, 2, 2, 3, 0];
      data_target[..INDEX_DATA.len()].copy_from_slice(&amp;INDEX_DATA);
      device
        .release_mapping_writer(data_target)
        .map_err(|_| &quot;Couldn't release the index buffer mapping writer!&quot;)?;
    }
#}</code></pre></pre>
<p>This is the exact same idea as writing to the vertex buffer, so it should look
very familiar. Do we want to make a <code>write_stuff</code> method on the <code>BufferBundle</code>
type and capture this pattern? Hmmmmmm, maybe later. I don't think it'd be hard,
but it's not really our goal right now.</p>
<a class="header" href="#performing-indexed-drawing" id="performing-indexed-drawing"><h2>Performing Indexed Drawing</h2></a>
<p>When we're doing our command buffer encoding we do it just a little different.</p>
<p>Now we have to bind an index buffer (there's <em>just one</em> index buffer per draw
call, even if there's more than one vertex buffer being combined)</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        encoder.bind_index_buffer(IndexBufferView {
          buffer: &amp;self.indexes.buffer,
          offset: 0,
          index_type: IndexType::U16,
        });
#}</code></pre></pre>
<p>And then instead of calling <code>draw</code> with a vertex range, offset, and instance
range, we call <code>draw_indexed</code> with an index range, offset, and instance range.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        encoder.draw_indexed(0..6, 0, 0..1);
#}</code></pre></pre>
<p>Like I said, it's only <em>slightly</em> different.</p>
<a class="header" href="#adding-a-vertex-attribute-for-texture-positions" id="adding-a-vertex-attribute-for-texture-positions"><h1>Adding A Vertex Attribute For Texture Positions</h1></a>
<p>This is just a quick little bit. Since we've got a new vertex attribute, we need
to update our pipeline to account for it.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let vertex_buffers: Vec&lt;VertexBufferDesc&gt; = vec![VertexBufferDesc {
        binding: 0,
        stride: (size_of::&lt;f32&gt;() * (2 + 3 + 2)) as ElemStride,
        rate: 0,
      }];
      let position_attribute = AttributeDesc {
        location: 0,
        binding: 0,
        element: Element {
          format: Format::Rg32Float,
          offset: 0,
        },
      };
      let color_attribute = AttributeDesc {
        location: 1,
        binding: 0,
        element: Element {
          format: Format::Rgb32Float,
          offset: (size_of::&lt;f32&gt;() * 2) as ElemOffset,
        },
      };
      let uv_attribute = AttributeDesc {
        location: 2,
        binding: 0,
        element: Element {
          format: Format::Rg32Float,
          offset: (size_of::&lt;f32&gt;() * 5) as ElemOffset,
        },
      };
      let attributes: Vec&lt;AttributeDesc&gt; = vec![position_attribute, color_attribute, uv_attribute];
#}</code></pre></pre>
<p>Gosh, that's a very basic change. It's almost like <a href="https://docs.rs/glium/0.23.0/glium/macro.implement_vertex.html">a macro could do
it</a>. Naw, I'm
sure no one would ever <a href="https://docs.rs/vulkano/0.11.1/vulkano/macro.impl_vertex.html">use a macro for
that</a>. Never.</p>
<p>This is another reason why you want to switch to a proper &quot;vertex type&quot; as your
program grows bigger and bigger. It's not only easier to read, but you can start
throwing macros at your problems! We'll get there eventually.</p>
<a class="header" href="#loading-an-image" id="loading-an-image"><h1>Loading An Image</h1></a>
<p>I'm sorry ahead of time, but this process is a fiddly and long one compared to
how easy that index buffer thing is.</p>
<p>What we want is to take a collection of pixel data and get it form our CPU
memory into GPU memory. However, as much as you might think, &quot;oh that's super
common, that's gotta be like 1 call right?&quot; No, it's like 11 distinct steps,
some of which are several calls.</p>
<p>So, we'll make another type to hold this concept for us. This is very similar to
the BufferBundle, with some generics and PhantomData and such.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct LoadedImage&lt;B: Backend, D: Device&lt;B&gt;&gt; {
  pub image: ManuallyDrop&lt;B::Image&gt;,
  pub requirements: Requirements,
  pub memory: ManuallyDrop&lt;B::Memory&gt;,
  pub image_view: ManuallyDrop&lt;B::ImageView&gt;,
  pub sampler: ManuallyDrop&lt;B::Sampler&gt;,
  pub phantom: PhantomData&lt;D&gt;,
}
#}</code></pre></pre>
<p>And right now we can say that it's got a cleanup method too:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub unsafe fn manually_drop(&amp;self, device: &amp;D) {
    use core::ptr::read;
    device.destroy_sampler(ManuallyDrop::into_inner(read(&amp;self.sampler)));
    device.destroy_image_view(ManuallyDrop::into_inner(read(&amp;self.image_view)));
    device.destroy_image(ManuallyDrop::into_inner(read(&amp;self.image)));
    device.free_memory(ManuallyDrop::into_inner(read(&amp;self.memory)));
  }
#}</code></pre></pre>
<p>And it's got a load method which is complex enough that we'll talk about it in
steps.</p>
<a class="header" href="#method-signature" id="method-signature"><h2>Method Signature</h2></a>
<p>What will we need? Well, we need and Adapter and Device like we do for a lot of
these memory things, but we'll also be telling the GPU to do stuff, so we'll
need a CommandPool and a CommandQueue. They get bound by <code>Capability + Supports&lt;Transfer&gt;</code>, in other words, they have to be pools that support the
ability to transfer things around. That's actually <em>all</em> possible pools and
queues (since graphics and compute both also support transfer), but it doesn't
really hurt to be clear what we're looking for. Lastly we need the image to be
uploading. We'll use the <a href="https://docs.rs/image">image</a> crate because it's the
most commonly used one. They support most of the file formats and pixel types
you'd need. At the time of writing the latest version is <code>0.21</code>.</p>
<pre><code class="language-toml">[dependencies]
...
image = &quot;0.21&quot;
</code></pre>
<p>Now we can begin to define how to load an image:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;B: Backend, D: Device&lt;B&gt;&gt; LoadedImage&lt;B, D&gt; {
  pub fn new&lt;C: Capability + Supports&lt;Transfer&gt;&gt;(
    adapter: &amp;Adapter&lt;B&gt;, device: &amp;D, command_pool: &amp;mut CommandPool&lt;B, C&gt;,
    command_queue: &amp;mut CommandQueue&lt;B, C&gt;, img: image::RgbaImage,
  ) -&gt; Result&lt;Self, &amp;'static str&gt; {
    unsafe {
#}</code></pre></pre>
<a class="header" href="#figure-out-some-memory-stuff" id="figure-out-some-memory-stuff"><h2>Figure Out Some Memory Stuff.</h2></a>
<p>First, before we actually do any GPU interaction, we need to double check on
some values we'll be using. See, we're going to make a buffer for this whole
upload process, as you might guess. However, unlike with vertex data, the
backend is allowed to be more picky about the memory alignment of image data. We
have to have the individual values aligned properly (eg: <code>u32</code> aligned to 4
bytes), but we <em>also</em> have to have the rows of the image aligned to their own
alignment.</p>
<p>Some image memory needs a little extra padding between rows to be optimal. The
Adapter has a field for the physical device, and that has a method to get the
limits. Those limits include a <code>min_buffer_copy_pitch_alignment</code> field, which is
a fairly poor name perhaps, but it means how well aligned the entire row of of
pixels in an image have to be. For example, we might need to align each row into
a 4 unit wide buffer, so if we have some little picture that's 50x50 we'd need
to place it into a buffer that's actually 52 pixels wide to match the alignment.</p>
<p>We take the <code>min_buffer_copy_pitch_alignment</code> and do a little math to basically
&quot;round up&quot; our starting row size to the next aligned value. This will give us a
row &quot;pitch&quot; value for the buffer that will always be equal to or greater than
the image's size in our CPU memory.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 0. First we compute some memory related values.
      let pixel_size = size_of::&lt;image::Rgba&lt;u8&gt;&gt;();
      let row_size = pixel_size * (img.width() as usize);
      let limits = adapter.physical_device.limits();
      let row_alignment_mask = limits.min_buffer_copy_pitch_alignment as u32 - 1;
      let row_pitch = ((row_size as u32 + row_alignment_mask) &amp; !row_alignment_mask) as usize;
      debug_assert!(row_pitch as usize &gt;= row_size);
#}</code></pre></pre>
<p>Okay, now we're ready to focus on the actual upload process.</p>
<a class="header" href="#make-a-staging-buffer" id="make-a-staging-buffer"><h2>Make A Staging Buffer</h2></a>
<p>In the past we've been able to map memory which we can directly write into our
buffers (the Vertex Buffer and Index Buffer). This is because we've been using
<code>CPU_VISIBLE</code> memory, which for most Vulkan vendors means the memory being used
is in CPU RAM, not in VRAM which is on the graphics card. If we used this for an
image, sampling that image (aka &quot;reading it&quot;) would be very, <em>very</em> slow.
Instead, what we want to do is make an image that uses a different type of
memory called <code>DEVICE_LOCAL</code> (that is, &quot;local to the graphics device&quot;). It's RAM
that's actually on the graphics card itself, much faster for the GPU to use.
However, being close to the GPU means it's far from us (we're the CPU). It's so
far that you actually can't even get there from here. We have to make a &quot;staging
buffer&quot;, copy our image from CPU memory into that, then tell the GPU to copy
from the staging buffer into the actual image memory. Yes, really.</p>
<p>For the staging buffer we can use the <code>BufferBundle</code> type, and we want the usage
to be &quot;transfer source&quot;.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 1. make a staging buffer with enough memory for the image, and a
      //    transfer_src usage
      let required_bytes = row_pitch * img.height() as usize;
      let staging_bundle =
        BufferBundle::new(&amp;adapter, device, required_bytes, BufferUsage::TRANSFER_SRC)?;
#}</code></pre></pre>
<a class="header" href="#write-to-the-staging-buffer" id="write-to-the-staging-buffer"><h2>Write To The Staging Buffer</h2></a>
<p>Now that our staging buffer is created, we can &quot;stage&quot; the data into it.</p>
<p>Except, remember that alignment issue? <em>Sometimes</em> the buffer will have a pitch
that's exactly as big as our image's width, and sometimes it will have a bigger
pitch. So we can't do a straight copy like we've done in the past. We have to do
a row-wise copy.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 2. use mapping writer to put the image data into that buffer
      let mut writer = device
        .acquire_mapping_writer::&lt;u8&gt;(&amp;staging_bundle.memory, 0..staging_bundle.requirements.size)
        .map_err(|_| &quot;Couldn't acquire a mapping writer to the staging buffer!&quot;)?;
      for y in 0..img.height() as usize {
        let row = &amp;(*img)[y * row_size..(y + 1) * row_size];
        let dest_base = y * row_pitch;
        writer[dest_base..dest_base + row.len()].copy_from_slice(row);
      }
      device
        .release_mapping_writer(writer)
        .map_err(|_| &quot;Couldn't release the mapping writer to the staging buffer!&quot;)?;
#}</code></pre></pre>
<p>See that part where we iterate the picture rows and the writer rows in the
<em>same</em> direction? If we needed to flip our image data around we'd iterate one of
them in the <em>opposite</em> direction (doesn't matter which) and then our image would
get uploaded with a vertical flip applied.</p>
<a class="header" href="#make-an-image" id="make-an-image"><h2>Make An Image</h2></a>
<p>Now we make an Image on the Device with
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_image">create_image</a>.
This is just a description of what the image will be like. Like with Buffers, an
Image doesn't automatically have any memory bound to it.</p>
<ul>
<li><code>kind</code> looks like just the dimensionality of the image, but it's <a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkImageViewCreateInfo.html">actually
complex enough to need a huge
table</a>
of what's allowed to go with what.</li>
<li><code>mip_levels</code> is for when you do mip mapping to have more than one level of
detail for the image. We won't do that yet, so just leave it at 1.</li>
<li><code>format</code> is the pixel format of the image. This might not match the pixel
format of the swapchain that the image gets used with, and then the GPU will
convert around and stuff. Thankfully our formats will probably match here.</li>
<li><code>tiling</code> affects the memory layout of the image. In this case the image will
be purely used within the GPU, so we'll pick <code>Optimal</code> and let the GPU be
happy.</li>
<li><code>usage</code> is an image usage (which is <em>similar to but not the same as</em> the
buffer usage flags), and here we want <code>TRANSFER_DST</code> (since it will be the
destination for our staging buffer transfer) and also <code>SAMPLED</code> (since the
fragment shader will sample from it).</li>
<li><code>view_caps</code> is if we want our view into the image to support anything special,
but we don't need any of that.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 3. Make an image with transfer_dst and SAMPLED usage
      let mut the_image = device
        .create_image(
          gfx_hal::image::Kind::D2(img.width(), img.height(), 1, 1),
          1,
          Format::Rgba8Srgb,
          gfx_hal::image::Tiling::Optimal,
          gfx_hal::image::Usage::TRANSFER_DST | gfx_hal::image::Usage::SAMPLED,
          gfx_hal::image::ViewCapabilities::empty(),
        )
        .map_err(|_| &quot;Couldn't create the image!&quot;)?;
#}</code></pre></pre>
<a class="header" href="#allocate-some-image-memory" id="allocate-some-image-memory"><h2>Allocate Some Image Memory</h2></a>
<p>Next we want to allocate some memory for the image and bind it to the image.
This works <em>very close</em> to how it works with the <code>BufferBundle</code> type. However,
remember that instead of memory that's <code>CPU_VISIBLE</code>, we want memory that's
<code>DEVICE_LOCAL</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 4. allocate memory for the image and bind it
      let requirements = device.get_image_requirements(&amp;the_image);
      let memory_type_id = adapter
        .physical_device
        .memory_properties()
        .memory_types
        .iter()
        .enumerate()
        .find(|&amp;(id, memory_type)| {
          // BIG NOTE: THIS IS DEVICE LOCAL NOT CPU VISIBLE
          requirements.type_mask &amp; (1 &lt;&lt; id) != 0
            &amp;&amp; memory_type.properties.contains(Properties::DEVICE_LOCAL)
        })
        .map(|(id, _)| MemoryTypeId(id))
        .ok_or(&quot;Couldn't find a memory type to support the image!&quot;)?;
      let memory = device
        .allocate_memory(memory_type_id, requirements.size)
        .map_err(|_| &quot;Couldn't allocate image memory!&quot;)?;
      device
        .bind_image_memory(&amp;memory, 0, &amp;mut the_image)
        .map_err(|_| &quot;Couldn't bind the image memory!&quot;)?;
#}</code></pre></pre>
<p>The same note applies here as with the <code>BufferBundle</code>: in a program with many
textures you'd need to grab a big block of memory and use a sub-allocator to
pick out actual image memory yourself because there's a limit on total
allocations among GPU memory. This is fine for now though.</p>
<a class="header" href="#create-an-imageview-and-sampler" id="create-an-imageview-and-sampler"><h2>Create An <code>ImageView</code> And <code>Sampler</code></h2></a>
<p>We don't use it immediately, but later on we'll need to have both an <code>ImageView</code>
and <code>Sampler</code> for our Image, so we'll make them right now and store them in the
<code>LoadedImage</code> struct. Conceptually, the LoadedImage would just be somewhat
incomplete without them.</p>
<p>In <code>gfx-hal</code>, there are basically three &quot;levels&quot; of both image and buffer
resources. First there's the <code>Memory</code>, which is a handle to a specific piece of
device memory, which is where the raw data for that resource is stored. Then
there's the <code>Buffer</code> or <code>Image</code>, which is information about the size, planned
usage, and any special properties of the resource contained in the backing
memory. Finally there is the resource view. In this case, that's an <code>ImageView</code>,
but there are also <code>BufferView</code>s that we just haven't used yet. The view is like
a window into a resource, it describes how to think of it (the type of data,
pixel format, etc) and which part of the resource to view. You're even allowed
to have more than one view into the same resource, if you want.</p>
<p>On top of the <code>ImageView</code> layer we also want to use what is called a <code>Sampler</code>.
This is what lets us use the image data within a shader. In a graphics program
you usually don't want the direct value of a specific pixel in a texture,
instead you want to get the color of a texture at some <em>relative</em> point,
probably &quot;between&quot; two pixels. What <em>exactly</em> does that mean? The <code>Sampler</code>
decides what it means.</p>
<p>The sampler describes how we want the shader to interpolate between the colors
of a texture, including how to &quot;zoom&quot; the image to be bigger or smaller if it's
being stretched across a space that doesn't match the original image size.
Samplers are created and used in a similar way to other device resources. The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/struct.SamplerInfo.html#method.new">SamplerInfo::new</a>
method can do the work here, because using defaults for most of the stuff is
fine.</p>
<ul>
<li>We pick a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/enum.Filter.html">Filter</a>, which
determines how to pick the color that's at a &quot;sub-pixel&quot; location. <code>Nearest</code>
picks all color from just one pixel, whichever pixel the point would be at if
you rounded the floating point position into an integer position. This gives
results that are usually sharp and blocky. There's also <code>Linear</code> which does a
color blend between the pixels around the fractional location, weighted by how
far the location is towards each side. So if 2 is green and 3 is white, pixel
2.9 is 90% white and 10% green. The blend happens in however many dimensions
the image has, so a 1D image is a linear blend, a 2D image is a &quot;bilinear&quot;
blend, and so on. This gives results that are smoother looking.</li>
<li>We also pick a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/enum.WrapMode.html">WrapMode</a>.
Texture coordinates are in the 0.0 to 1.0 range, and if you access something
outside of that it's not actually an error like accessing outside a slice
bound is. Instead, the <code>WrapMode</code> determines how the out of bounds location is
translated to be back in bounds.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 5. create image view and sampler
      let image_view = device
        .create_image_view(
          &amp;the_image,
          gfx_hal::image::ViewKind::D2,
          Format::Rgba8Srgb,
          gfx_hal::format::Swizzle::NO,
          SubresourceRange {
            aspects: Aspects::COLOR,
            levels: 0..1,
            layers: 0..1,
          },
        )
        .map_err(|_| &quot;Couldn't create the image view!&quot;)?;
      let sampler = device
        .create_sampler(gfx_hal::image::SamplerInfo::new(
          gfx_hal::image::Filter::Nearest,
          gfx_hal::image::WrapMode::Tile,
        ))
        .map_err(|_| &quot;Couldn't create the sampler!&quot;)?;
#}</code></pre></pre>
<a class="header" href="#create-a-commandbuffer" id="create-a-commandbuffer"><h2>Create A <code>CommandBuffer</code></h2></a>
<p>We've done this step before, it's not weird. The biggest difference is that now
we're making a <code>OneShot</code> command buffer. Those other command buffers that we use
over and over are <code>MultiShot</code>. They both implement
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/trait.Shot.html">Shot</a>. It's
basically what it sounds like, one can be reused and one can't. At the end of
the loading process we'll be throwing this shot away
(<a href="https://www.youtube.com/watch?v=Ic7NqP_YGlg">Hamilton</a> would be so upset),
that means we'll make a <code>OneShot</code> buffer this time around.</p>
<p><code>OneShot</code> buffers are actually less restrictive than <code>MultiShot</code> buffers, but
the graphics driver can sometimes make some optimizations based on the manner in
which you plan to use the buffer. If you really need to care about it, the exact
details of what type of buffer to use when, with what video cards, with what
drivers, it's all one of those &quot;you have to profile it to know for sure&quot;
problems. We're not trying to push out that much performance yet though.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 6. create a command buffer
      let mut cmd_buffer = command_pool.acquire_command_buffer::&lt;gfx_hal::command::OneShot&gt;();
      cmd_buffer.begin();
#}</code></pre></pre>
<a class="header" href="#first-pipeline-barrier" id="first-pipeline-barrier"><h2>First Pipeline Barrier</h2></a>
<p>The image memory starts with undefined values (much like memory on the CPU) but
it <em>also</em> starts with an undefined <em>layout</em>. Which sounds a little weird, but
it's totally a thing.</p>
<p>Our first command into the buffer is to transition the image memory into a new
layout that's the best possible layout for being a transfer destination. What
<em>exactly</em> that means is up to the GPU, but it knows what to do.</p>
<p>In addition, we transfer the <code>Access</code> type from none at all to <code>TRANSFER_WRITE</code>,
which tells the GPU the type of access which we are going to be performing on
this resource for now. It's important that we transition resources which we want
to use in specific ways to the proper Layout and Access type, because performing
operations which are not supported by the Layout/Access that a resource
currently has isn't just a speed penalty, it's an explicit error and possibly
even <strong>Undefined Behavior</strong> (oh no!). <code>gfx-hal</code> goes to a lot of trouble to make
sure that all the backends behave like Vulkan even if they're not Vulkan, so you
can use the Vulkan spec to know which operations are supported by each
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkImageLayout.html">Layout</a>
and
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkAccessFlagBits.html">Access</a>
type.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 7. Use a pipeline barrier to transition the image from empty/undefined
      //    to TRANSFER_WRITE/TransferDstOptimal
      let image_barrier = gfx_hal::memory::Barrier::Image {
        states: (gfx_hal::image::Access::empty(), Layout::Undefined)
          ..(
            gfx_hal::image::Access::TRANSFER_WRITE,
            Layout::TransferDstOptimal,
          ),
        target: &amp;the_image,
        families: None,
        range: SubresourceRange {
          aspects: Aspects::COLOR,
          levels: 0..1,
          layers: 0..1,
        },
      };
      cmd_buffer.pipeline_barrier(
        PipelineStage::TOP_OF_PIPE..PipelineStage::TRANSFER,
        gfx_hal::memory::Dependencies::empty(),
        &amp;[image_barrier],
      );
#}</code></pre></pre>
<a class="header" href="#do-the-copy" id="do-the-copy"><h2>Do The Copy</h2></a>
<p>Our next command is to actually do that copy from the staging buffer (in
<code>CPU_VISIBLE</code> memory) into the image (the <code>DEVICE_LOCAL</code> memory).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 8. perform copy from staging buffer to image
      cmd_buffer.copy_buffer_to_image(
        &amp;staging_bundle.buffer,
        &amp;the_image,
        Layout::TransferDstOptimal,
        &amp;[gfx_hal::command::BufferImageCopy {
          buffer_offset: 0,
          buffer_width: (row_pitch / pixel_size) as u32,
          buffer_height: img.height(),
          image_layers: gfx_hal::image::SubresourceLayers {
            aspects: Aspects::COLOR,
            level: 0,
            layers: 0..1,
          },
          image_offset: gfx_hal::image::Offset { x: 0, y: 0, z: 0 },
          image_extent: gfx_hal::image::Extent {
            width: img.width(),
            height: img.height(),
            depth: 1,
          },
        }],
      );
#}</code></pre></pre>
<a class="header" href="#transition-the-image-into-shader-friendly-layout" id="transition-the-image-into-shader-friendly-layout"><h2>Transition The Image Into Shader-Friendly Layout</h2></a>
<p>Just like there's a layout for being an optimal destination, there's also a
layout for being an optimal place for a shader to read from, and an access type
for being read from a shader. We've gotta issue a pipeline barrier for this
transition too. There are other ways to transition resources which should be
used instead of pipeline barriers when possible (specifically, between render
Subpasses), but in this case pipeline barriers are required (as always, &quot;more on
that in future lessons&quot;).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 9. use pipeline barrier to transition the image to SHADER_READ access/
      //    ShaderReadOnlyOptimal layout
      let image_barrier = gfx_hal::memory::Barrier::Image {
        states: (
          gfx_hal::image::Access::TRANSFER_WRITE,
          Layout::TransferDstOptimal,
        )
          ..(
            gfx_hal::image::Access::SHADER_READ,
            Layout::ShaderReadOnlyOptimal,
          ),
        target: &amp;the_image,
        families: None,
        range: SubresourceRange {
          aspects: Aspects::COLOR,
          levels: 0..1,
          layers: 0..1,
        },
      };
      cmd_buffer.pipeline_barrier(
        PipelineStage::TRANSFER..PipelineStage::FRAGMENT_SHADER,
        gfx_hal::memory::Dependencies::empty(),
        &amp;[image_barrier],
      );
#}</code></pre></pre>
<a class="header" href="#submit-that-buffer" id="submit-that-buffer"><h2>Submit That Buffer!</h2></a>
<p>With all our commands written we submit the buffer. Except we don't have a fence
for the GPU to signal us when the whole thing is done. Well, it's not like we're
uploading whole images every frame, so we'll just make a temporary fence and
then destroy it after.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 10. Submit the cmd buffer to queue and wait for it
      cmd_buffer.finish();
      let upload_fence = device
        .create_fence(false)
        .map_err(|_| &quot;Couldn't create an upload fence!&quot;)?;
      command_queue.submit_nosemaphores(Some(&amp;cmd_buffer), Some(&amp;upload_fence));
      device
        .wait_for_fence(&amp;upload_fence, core::u64::MAX)
        .map_err(|_| &quot;Couldn't wait for the fence!&quot;)?;
      device.destroy_fence(upload_fence);
#}</code></pre></pre>
<a class="header" href="#destroy-the-other-temporary-resources" id="destroy-the-other-temporary-resources"><h2>Destroy The Other Temporary Resources</h2></a>
<p>We're all done, but we can't forget to clean up that staging buffer, and also
free that <code>OneShot</code> command buffer.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 11. Destroy the staging bundle and one shot buffer now that we're done
      staging_bundle.manually_drop(device);
      command_pool.free(Some(cmd_buffer));
#}</code></pre></pre>
<a class="header" href="#success" id="success"><h2>Success!</h2></a>
<p>We've finally uploaded an image!</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      Ok(Self {
        image: ManuallyDrop::new(the_image),
        requirements,
        memory: ManuallyDrop::new(memory),
        image_view: ManuallyDrop::new(image_view),
        sampler: ManuallyDrop::new(sampler),
        phantom: PhantomData,
      })
#}</code></pre></pre>
<a class="header" href="#shading-the-image-onto-the-quad" id="shading-the-image-onto-the-quad"><h1>Shading The Image Onto The Quad</h1></a>
<p>To actually use this image we've got more work ahead of us. Of course, that dumb
graphics pipeline of ours has to change yet again to accommodate this new thing.
So we'll have to make some changes to <code>create_pipeline</code>.</p>
<a class="header" href="#descriptorsetlayout" id="descriptorsetlayout"><h2>DescriptorSetLayout</h2></a>
<p>First we need a <code>DescriptorSetLayout</code>, which is a backend specific definition of
the <em>layout</em> of the resources in the graphics pipeline process. Later we'll bind
those as <code>Descriptors</code>, which we can access in the shader.</p>
<p>To be clear: we are not yet binding the actual resources which we want to use,
only describing the kind and place in which those resources will have to go. As
you'll see later, as long as we follow this layout, we can bind multiple
different resources into the same slots. We need a <code>SampledImage</code> and a
<code>Sampler</code>. Like with other shader stuff, the <code>binding</code> value here has to match
the number that the GLSL code will use.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 1. you make a DescriptorSetLayout which is the layout of one descriptor
      //    set
      let descriptor_set_layouts: Vec&lt;&lt;back::Backend as Backend&gt;::DescriptorSetLayout&gt; =
        vec![unsafe {
          device
            .create_descriptor_set_layout(
              &amp;[
                DescriptorSetLayoutBinding {
                  binding: 0,
                  ty: gfx_hal::pso::DescriptorType::SampledImage,
                  count: 1,
                  stage_flags: ShaderStageFlags::FRAGMENT,
                  immutable_samplers: false,
                },
                DescriptorSetLayoutBinding {
                  binding: 1,
                  ty: gfx_hal::pso::DescriptorType::Sampler,
                  count: 1,
                  stage_flags: ShaderStageFlags::FRAGMENT,
                  immutable_samplers: false,
                },
              ],
              &amp;[],
            )
            .map_err(|_| &quot;Couldn't make a DescriptorSetLayout&quot;)?
        }];
#}</code></pre></pre>
<a class="header" href="#descriptorpool" id="descriptorpool"><h2>DescriptorPool</h2></a>
<p>Next we need a <a href="DescriptorPool">DescriptorPool</a>. This comes from our <code>Device</code>,
and allows us to actually allocate some <code>Descriptor</code> and <code>DescriptorSet</code> values.
Unlike with the CommandPool, we have to decide how much of each kind of
descriptor, as well as how many sets, we'll <em>ever</em> allocate out of this thing
ahead of time.</p>
<p>The number of Descriptors is shared between all descriptor sets. We only want
one SampledImage and one Sampler, both in a single set.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 2. you create a descriptor pool, and when making that descriptor pool
      //    you specify how many sets you want to be able to allocate from the
      //    pool, as well as the maximum number of each kind of descriptor you
      //    want to be able to allocate from that pool, total, for all sets.
      let mut descriptor_pool = unsafe {
        device
          .create_descriptor_pool(
            1, // sets
            &amp;[
              gfx_hal::pso::DescriptorRangeDesc {
                ty: gfx_hal::pso::DescriptorType::SampledImage,
                count: 1,
              },
              gfx_hal::pso::DescriptorRangeDesc {
                ty: gfx_hal::pso::DescriptorType::Sampler,
                count: 1,
              },
            ],
          )
          .map_err(|_| &quot;Couldn't create a descriptor pool!&quot;)?
      };
#}</code></pre></pre>
<p>Technically you could do either steps 1 or 2 first, as long as they're both done
before step 3.</p>
<a class="header" href="#allocate-a-descriptorset" id="allocate-a-descriptorset"><h2>Allocate A DescriptorSet</h2></a>
<p>With a layout and a pool, we're ready to actually allocate a <code>DescriptorSet</code>. A
DescriptorSet is a set of descriptors in some specific layout. When it's first
created, there <em>still</em> aren't actual Descriptors written into the set yet, so
that's the next thing we'll have to do.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 3. you allocate said descriptor set from the pool you made earlier
      let descriptor_set = unsafe {
        descriptor_pool
          .allocate_set(&amp;descriptor_set_layouts[0])
          .map_err(|_| &quot;Couldn't make a Descriptor Set!&quot;)?
      };
#}</code></pre></pre>
<a class="header" href="#create-the-descriptors-you-want-to-write" id="create-the-descriptors-you-want-to-write"><h2>Create The Descriptors You Want To Write</h2></a>
<p>At this point you'd make the actual descriptors you'd want to write. For us
that's the ImageView and the Sampler that are part of our <code>LoadedImage</code>. So, in
the <code>HalState</code> startup we'll load up the image after we call <code>create_pipeline</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // 4. You create the actual descriptors which you want to write into the
    //    allocated descriptor set (in this case an image and a sampler)
    let texture = LoadedImage::new(
      &amp;adapter,
      &amp;device,
      &amp;mut command_pool,
      &amp;mut queue_group.queues[0],
      image::load_from_memory(CREATURE_BYTES)
        .expect(&quot;Binary corrupted!&quot;)
        .to_rgba(),
    )?;
#}</code></pre></pre>
<p>This could technically be either before or after the call to <code>create_pipeline</code>
(since neither depends on the other), but since it's &quot;step 4&quot; in this process,
and <code>create_pipeline</code> had steps 1 through 3, we'll put it after
<code>create_pipeline</code>.</p>
<a class="header" href="#write-the-descriptors-into-the-descriptorset" id="write-the-descriptors-into-the-descriptorset"><h2>Write The Descriptors Into The DescriptorSet</h2></a>
<p>Once all the resources which will be bound as <code>Descriptors</code> and the
<code>DescriptorSet</code> exist at the same time (after <code>create_pipeline</code> and after we
have our <code>LoadedImage</code>), we can write the one into the other. This binds the
specific ImageView (being used as a SampledImage descriptor) and Sampler (being
used as a Sampler descriptor) to that specific DescriptorSet.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // 5. You write the descriptors into the descriptor set using
    //    write_descriptor_sets which you pass a set of DescriptorSetWrites
    //    which each write in one or more descriptors to the set
    unsafe {
      device.write_descriptor_sets(vec![
        gfx_hal::pso::DescriptorSetWrite {
          set: &amp;descriptor_set,
          binding: 0,
          array_offset: 0,
          descriptors: Some(gfx_hal::pso::Descriptor::Image(
            texture.image_view.deref(),
            Layout::ShaderReadOnlyOptimal
          )),
        },
        gfx_hal::pso::DescriptorSetWrite {
          set: &amp;descriptor_set,
          binding: 1,
          array_offset: 0,
          descriptors: Some(gfx_hal::pso::Descriptor::Sampler(texture.sampler.deref())),
        },
      ]);
    }
#}</code></pre></pre>
<a class="header" href="#bind-the-descriptor-set-during-render-pass-encoding" id="bind-the-descriptor-set-during-render-pass-encoding"><h2>Bind The Descriptor Set During Render Pass Encoding</h2></a>
<p>Lastly, when we're doing all of our binding for the render pass, we have to bind
this stuff too. If you had multiple images which you wanted to bind into the
same shader program at different times, you'd create multiple DescriptorSets and
then write the different resources into those different DescriptorSets and then
finally bind the correct set before each draw call. You can also bind more than
one set into a single draw call, but the uses for that are a bit more
complicated (&quot;for another lesson&quot;).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        // 6. You actually bind the descriptor set in the command buffer before
        //    the draw call using bind_graphics_descriptor_sets
        encoder.bind_graphics_descriptor_sets(
          &amp;self.pipeline_layout,
          0,
          Some(self.descriptor_set.deref()),
          &amp;[],
        );
#}</code></pre></pre>
<p>Note 1: We've got it a in few places, but that <code>deref</code> call there is to make the
<code>Deref</code> trait on the <code>ManuallyDrop</code> wrapper trigger, because just using <code>&amp;</code>
doesn't do it. probably because <code>bind_graphics_descriptor_sets</code> is so generic
that <code>rustc</code> actually gets confused about what we're even trying to say.</p>
<p>Note 2: here we're using <code>Some(thing)</code> instead of making another <code>ArrayVec</code> of
length 1. I think we already did it above in this lesson too. It's ultimately
the same effect (since the generic here is for <code>IntoIterator</code>), and arguably
easier to use this way. However, I wanted to make sure that you knew how to do
the <code>ArrayVec</code> version, so it got shown off first. Using <code>Some(thing)</code> is quick
and easy, but it locks you at one element instead of allowing for as many
elements as you want with the <code>ArrayVec</code> (by just change the length value). Of
course, if you don't know how many things you'll be passing at compile time (for
whatever reason) you can also use a normal <code>Vec</code> (we're trying to avoid
allocations as much as we can though!).</p>
<a class="header" href="#update-the-vertex-shader" id="update-the-vertex-shader"><h2>Update The Vertex Shader</h2></a>
<p>We adjust the vertex shader slightly so that it passes the UV coordinates on through.</p>
<pre><code class="language-glsl">#version 450
layout (location = 0) in vec2 position;
layout (location = 1) in vec3 color;
layout (location = 2) in vec2 vert_uv;

layout (location = 0) out gl_PerVertex {
  vec4 gl_Position;
};
layout (location = 1) out vec3 frag_color;
layout (location = 2) out vec2 frag_uv;

void main()
{
  gl_Position = vec4(position, 0.0, 1.0);
  frag_color = color;
  frag_uv = vert_uv;
}
</code></pre>
<a class="header" href="#update-the-fragment-shader" id="update-the-fragment-shader"><h2>Update The Fragment Shader</h2></a>
<p>LAST STEP!</p>
<p>In the fragment shader we need to declare that we'll be getting this image data:</p>
<pre><code class="language-glsl">layout(set = 0, binding = 0) uniform texture2D tex;
layout(set = 0, binding = 1) uniform sampler samp;
</code></pre>
<p>Notice the <code>binding</code>s here match up with what we put all the way back in our
<code>DescriptorSetLayout</code>. The <code>set</code> value is matched up with the position of the
<code>DescriptorSet</code> within the <code>IntoIterator</code> that we passed to
<code>bind_graphics_descriptor_sets</code>.</p>
<p>Then in <code>main</code> we form a <code>sampler2D</code> from the <code>texture2D</code> and <code>sampler</code> put
together. This lets us call the
<a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/texture.xhtml">texture</a>
function, passing the <code>sampler2D</code> as well as the UV coordinates of that
fragment. That finally ets us a RGBA color out of the texture data.</p>
<p>We could output this directly, but just for fun (and to show off a little more
of what a fragment shader can do) we'll use the time value to shift between the
texture data and the rainbow color data. This is a snap to do with the
<a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/mix.xhtml">mix</a>
function. It takes two colors, and a portion (from 0.0 to 1.0) for how much the
<em>second</em> color should determine the output (it's just a linear interpolation, if
you remember that from the sampler stuff above). We'll cover this in more detail
later on. For now it's okay to just know that it works.</p>
<pre><code class="language-glsl">#version 450
layout (push_constant) uniform PushConsts {
  float time;
} push;

layout(set = 0, binding = 0) uniform texture2D tex;
layout(set = 0, binding = 1) uniform sampler samp;

layout (location = 1) in vec3 frag_color;
layout (location = 2) in vec2 frag_uv;

layout (location = 0) out vec4 color;

void main()
{
  float time01 = -0.9 * abs(sin(push.time * 0.7)) + 0.9;
  vec4 tex_color = texture(sampler2D(tex, samp), frag_uv);
  color = mix(tex_color, vec4(frag_color, 1.0), time01);
}
</code></pre>
<p>And we're finally through!</p>
<p><img src="images/textures-complete.png" alt="textures-complete" /></p>
<a class="header" href="#coordinates" id="coordinates"><h1>Coordinates</h1></a>
<p>So, when we did the Quad in the textures lesson, you may recall that it was
(x,y) for the base corner, and then width and height for the size, and then we
used the base corner plus the width and height to find the other three corners.
One of the non-base corners added the width to x, one added the height to y, and
one did both of the adds at the same time. How do we know that <code>x</code> and <code>width</code>
go together? Why doesn't <code>x</code> go with <code>height</code>? That's just kinda the convention
that you learn in school. <code>x</code> is horizontal with bigger values going to the
right, and <code>y</code> is vertical with bigger values going up. This is part of the
<a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system">Cartesian coordinate
system</a>. You might
not remember the name, but you probably remember the whole thing with <code>x</code> going
horizontally and <code>y</code> going vertically.</p>
<p>Here's the deal though. We're not aiming for just 2D drawing. We're aiming for
3D drawing and having 2D be just an occasional specialization of the whole 3D
process. So where does the <code>z</code> direction go? We probably drew that in our little
notebooks. It's hard to draw. On top of that we've got those <code>u</code> and <code>v</code> values
for texture lookups, and those don't have the origin in the middle of the space,
they have it in the top left corner of the texture. What's going on with any of
this nonsense?</p>
<a class="header" href="#coordinate-systems" id="coordinate-systems"><h2>Coordinate Systems</h2></a>
<p>Turns out there's not just one &quot;coordinate system&quot;, there's many coordinate
system<strong>s</strong>, that we have to deal with. Textures have a coordinate system, the
screen has a coordinate system, the scene has a coordinate system, and even each
individual model has a coordinate system. What?</p>
<p>Yeah, because floating point numbers have limited accuracy across big ranges,
the convention is to have all the points of a single model be in &quot;model space&quot;
with relatively small numbers and high accuracy. Then you have a transform
function that converts model space positions into world space positions based on
the overall position of the model in the world. Then the whole scene is being
viewed from some particular place and with a particular perspective, so there's
a transformation function to turn world space coordinates into screen space
coordinates. Any coordinate out of bounds of the screen space is off-screen, so
we don't even draw it.</p>
<a class="header" href="#transformations" id="transformations"><h2>Transformations</h2></a>
<p>So what's this &quot;function&quot; that shifts points between coordinate spaces? Well, I
kinda made it sound like a code function, but it's actually a math function
(<code>math</code>, <em>singular</em>, this is not a plural &quot;maths&quot; tutorial that's silly).</p>
<p>To translate a 3D point, we make the point into a <code>vec4</code> with the final position
as <code>1.0</code>, then we multiply it by a specially prepared 4x4 matrix (the
&quot;transformation matrix&quot;). That gives us a <code>vec4</code> output, and then to turn it
back into a <code>vec3</code> we just divide the <code>x</code>, <code>y</code>, and <code>z</code> axis by the <code>w</code> axis.</p>
<p>Vectors? Matrix? <code>w</code>-axis? What?</p>
<p>Ho boy are you in for some fun!</p>
<p>Yes, this (and more) is among the powers that math can grant you, but first you
must learn that math.</p>
<a class="header" href="#learning-the-math" id="learning-the-math"><h2>Learning The Math</h2></a>
<p>I'm not a math teacher, and math is universal enough that I can just tell you to
go learn from someone else's math course and you'll be able to use those skills
here, so that's exactly what I'll do.</p>
<ul>
<li>
<p>If you want <em>just</em> the fundamentals right now you can read the
<a href="https://learnopengl.com/Getting-started/Transformations">Transformations</a>
lesson on <code>LearnOpenGL.com</code>. Everything before the <code>In practice</code> section is
totally code free, just a math lesson, so you don't need to have any previous
OpenGL or C++ experience.</p>
</li>
<li>
<p>When you have the time you should really sit down and learn the subject a
little more properly there is a <a href="https://www.khanacademy.org/math/linear-algebra">Khan Academy Linear
Algebra</a> course, it's a totally
free video series style</p>
</li>
<li>
<p>If you like videos, the <a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear
Algebra</a>
by 3blue1brown is pretty amazing.</p>
</li>
</ul>
<a class="header" href="#applying-the-math" id="applying-the-math"><h2>Applying The Math</h2></a>
<p>So now that we know about how vectors and matrices work, how do we do this in
our code? Well, there's three main options here:</p>
<ul>
<li><a href="https://docs.rs/nalgebra-glm">nalgebra-glm</a> is a crate that provides a
GLM-like interface to the <a href="https://docs.rs/nalgebra">nalgebra</a> crate via type
aliases and such. <code>nalgebra</code> is a serious math crate for serious math people.
I generally wouldn't suggest that you use this crate <em>unless</em> you need to also
use the <code>ncollide</code> crate (which is a collision system based on nalgebra). The
extreme amount of generics makes error messages far worse when there's a type
error, and it also makes your compiles take longer.</li>
<li><a href="https://docs.rs/vek">vek</a> is the up and coming swiss army math lib that plans
to have an emphasis on SIMD support and is <code>#![no_std]</code>. I <em>always</em> approve of
a lib going for the <code>no_std</code> treatment. There's also a whole lot of features
you can enable to get extra benefits.</li>
<li><a href="https://docs.rs/cgmath">cgmath</a> is the &quot;tried and true beginner's crate&quot; for
graphics math. It's specifically their mandate to keep the focus on computer
graphics. Back in the day this set them apart from <code>nalgebra</code> all on its own,
but now that <code>vek</code> is coming up fast I'm not sure that <code>cgmath</code> has enough to
set itself apart.</li>
</ul>
<p>What should we use? Honestly, if it were just me I'd probably use <code>vek</code> to get
off the ground and then write my own vector math lib with no generics at all
when I wanted to take it easy during some programming day. Seriously, there's
only so much code involved in a vec math lib, you can totally write your own
from scratch.</p>
<p>However, this project isn't really about me, it's about you, the reader.
Accordingly, we're going to be using the <code>nalgebra-glm</code> crate. Out of all the
options, it's definitely got the worst error messages when things go wrong, so
any other crate that you decide to use instead will seem like a breeze in
comparison if you switch to another crate.</p>
<pre><code class="language-toml">[dependencies]
...
nalgebra-glm = &quot;0.2&quot;
</code></pre>
<a class="header" href="#the-primary-coordinate-systems" id="the-primary-coordinate-systems"><h1>The Primary Coordinate Systems</h1></a>
<p>There's actually an unlimited number of possible coordinate systems, but let's
focus on a few of them that you're most likely to encounter.</p>
<a class="header" href="#spatial-coordinates" id="spatial-coordinates"><h2>Spatial Coordinates</h2></a>
<p>A lot of the time we're concerned with 3D spatial positioning.</p>
<a class="header" href="#model-space" id="model-space"><h3>Model Space</h3></a>
<p>Each individual model exists in its own &quot;model space&quot;. A model can be anything
that's got all of its vertex positions specified in the same space. We'll be
using some basic shapes to start, and later on we'll learn how to load model
data out of a file.</p>
<p>The important thing about model space is that it's totally arbitrary and unique
to each model. You need to decide for yourself what your units are.</p>
<a class="header" href="#world-space" id="world-space"><h3>World Space</h3></a>
<p>By convention, each model within the scene has a transformation that converts
its model space points into world space points. This lets all of the models
exist in a single, unified coordinate space that's easier to think about.</p>
<p>As with model space, it's actually fairly arbitrary as to what your scale is.
The benefit of a world space is that you're usually doing not only the graphics,
but also any physics and such within the world space scale. It unifies the
whole simulation to get things into a space with a single origin.</p>
<a class="header" href="#view-space" id="view-space"><h3>View Space</h3></a>
<p>Graphics only happens from a particular point of observation. Transforming World
Space coordinates into how they should appear relative to the observer puts them
in &quot;View Space&quot;.</p>
<p>Once things are in View Space we can apply a Projection to the view. There's two
main projections to pick from:</p>
<ul>
<li>Orthographic Projection makes parallel lines stay parallel as they move far
away from you. Things are more angular, and even a little unreal looking
because of it. You probably want this projection for &quot;artificial&quot; sorts of
scenes, like if the user is designing something, or if the user is looking
over the scene in an &quot;all knowing&quot; sort of way and the scene is more like a
game board, like The Sims or Civilization.</li>
<li>Perspective Projection makes parallel lines appear to meet the farther away
they go from you. Like when looking far down a highway stretching out ahead.
This is basically how graphics work in the &quot;Real Life&quot; game, and that's a
fairly popular one that people have really become used to. You probably want
this projection if the scene is something that is being observed from some
sort of &quot;real&quot; perspective (either 1st person or 3rd person).</li>
</ul>
<p>The important thing here is that <em>the output is no longer arbitrary</em>. Once
you've run your projection matrix has transformed the vertex and the vertex
shader spits that value out, it has to be in what's called &quot;Normalized Device
Coordinates&quot;. For <code>gfx-hal</code> this means:</p>
<ul>
<li>X: -1.0 to +1.0 range, with +X going to the right</li>
<li>Y: -1.0 to +1.0 range, with +Y going to the down</li>
<li>Z: 0.0 to 1.0 range, with +Z going deeper into the screen</li>
</ul>
<a class="header" href="#texture-coordinates" id="texture-coordinates"><h2>Texture Coordinates</h2></a>
<p>In addition to &quot;physical&quot; locations, there's also texture lookups.</p>
<p>With textures the convention is to call the directions <code>u</code> and <code>v</code>, with <code>u</code>
being horizontal and <code>v</code> being vertical.</p>
<ul>
<li>U: 0.0 to 1.0, +U goes right</li>
<li>V: 0.0 to 1.0, +V goes down</li>
</ul>
<a class="header" href="#drawing-a-cube" id="drawing-a-cube"><h1>Drawing A Cube</h1></a>
<p>So, now that we've got a bit of an understanding of where our numbers need to
go, we just adjust the program a little bit. This time instead of doing a lot of
work in the fragment shader we're going to have the biggest change with the
fragment shader.</p>
<a class="header" href="#the-draw-call" id="the-draw-call"><h2>The Draw Call</h2></a>
<p>Okay so we're gonna draw one cube. In fact, now that we can put things in
different places and have it all show up properly, we'll draw <em>many</em> cubes. What
will define our cubes? Not vertex data any more. We're done with that. Now there
will be a <em>single</em> set of cube vertex data. Instead, a particular cube will be
defined by a model matrix to translate the local model points into world space
points. So drawing a series of cubes means we accept a slice of models and then
loop over each one.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn draw_cubes_frame(&amp;mut self, models: &amp;[glm::TMat4&lt;f32&gt;]) -&gt; Result&lt;(), &amp;'static str&gt; {
#}</code></pre></pre>
<p>The setup with picking our fences and such is the same as before, but then we
get to the new stuff. We need to get a Model-View-Projection Matrix to convert
the iconic cube data into a particular cube on the screen. We'll be drawing
several cubes, but they'll each have the same View and Projection Matrix, so
we'll determine View and Projection first.</p>
<a class="header" href="#view-matrix" id="view-matrix"><h3>View Matrix</h3></a>
<p>The View Matrix turns World Space into &quot;Camera Space&quot;. For our View matrix, we
want to use
<a href="https://docs.rs/nalgebra-glm/0.2.1/nalgebra_glm/fn.look_at_lh.html">look_at_lh</a>.
It's &quot;look at, left-handed&quot;. You can also have &quot;right-handed&quot; coordinate systems
(it has to do with which direction is positive as you move along each axis), but
<code>gfx-hal</code> is a left-handed coordinate system. Any time <code>nalgebra_glm</code> lets you
pick between the two you should pick the left-handed variant.</p>
<ul>
<li>The first argument is <em>where the camera is</em>.</li>
<li>The second argument is <em>where the camera is looking</em></li>
<li>The final argument is a <strong>normalized</strong> vector for which way is &quot;up&quot;. The third
argument can generally default to <code>[0.0, 1.0, 0.0]</code>.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // DETERMINE VIEW MATRIX (just once)
    let view = glm::look_at_lh(
      &amp;glm::make_vec3(&amp;[0.0, 0.0, -5.0]),
      &amp;glm::make_vec3(&amp;[0.0, 0.0, 0.0]),
      &amp;glm::make_vec3(&amp;[0.0, 1.0, 0.0]).normalize(),
    );
#}</code></pre></pre>
<p>Remember that +Z is &quot;into the screen&quot;, so we'll be starting a little &quot;back&quot; from
the world origin, looking at the world origin, and with the default up vector.</p>
<a class="header" href="#projection-matrix" id="projection-matrix"><h3>Projection Matrix</h3></a>
<p>The Projection Matrix turns Camera Space into &quot;Normalized Device Coordinates&quot;
(NDC). We start with a perspective matrix, but instead of just <code>perspective_lh</code>,
we need to add another detail. The whole GLM API was setup for OpenGL, which
uses -1.0 to +1.0 for Z, but <code>gfx-hal</code> uses only 0.0 to 1.0 for Z. As a result,
we need to select both the &quot;left-handed&quot;, and also <code>_zo</code> variant of the
perspective function, giving us
<a href="https://docs.rs/nalgebra-glm/0.2.1/nalgebra_glm/fn.perspective_lh_zo.html">perspective_lh_zo</a>.</p>
<ul>
<li>The first argument is the aspect ratio of the display area. We just put our width / height and we're set.</li>
<li>The second argument is the <a href="https://en.wikipedia.org/wiki/Field_of_view_in_video_games">field of
view</a> angle (in
radians). This is something that you should probably let your users customize
if you're making a &quot;real&quot; program. A comfortable field of view depends on the
user's physical screen size and how close they're sitting to it.</li>
<li>The third and fourth arguments are the distance to the near and far clipping
plane.</li>
</ul>
<p>Now once we have our Perspective calculation given to us, we need to flip the Y
value. This makes it so that increasing Y values in World Space will cause a
<em>decrease</em> in the Y result within NDC space. That way when things move up in the
world they actually go up on the screen too. Flipping all the Y values might
sound tricky, but we just need to negate a single element in the matrix,
position <code>(1,1)</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // DETERMINE PROJECTION MATRIX (just once)
    let projection = {
      let mut temp = glm::perspective_lh_zo(800.0 / 600.0, f32::to_radians(50.0), 0.1, 100.0);
      temp[(1, 1)] *= -1.0;
      temp
    };
#}</code></pre></pre>
<p>Now, yes, I know that maybe technically we shouldn't hard code the aspect ratio,
since we went to all that trouble to make our window resizable and everything,
but it's fine. Consider that small detail to be homework for the dedicated
reader.</p>
<a class="header" href="#a-combined-view-projection-matrix" id="a-combined-view-projection-matrix"><h3>A Combined View-Projection Matrix</h3></a>
<p>A matrix multiplication is actually fairly costly. For a 4x4 matrix you're doing
16 dot products. We want to keep that down, so we'll calculate a single
&quot;view-projection&quot; matrix right now (since it doesn't change per model), and then
use it for each model that we draw.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // COMBINE THE VIEW AND PROJECTION MATRIX AHEAD OF TIME (just once)
    let vp = projection * view;
#}</code></pre></pre>
<p>Remember, the right side of a stack of matrix transforms is the side that
happens &quot;first&quot; within the total transformation. Since we want to go from Model
Space to World Space to View Space to NDC Space, we'll have the model on the far
right, then the view in the middle, then the projection on the left side. Since
this doesn't have the model data yet, it's just projection on the left times the
view.</p>
<a class="header" href="#drawing-those-models" id="drawing-those-models"><h3>Drawing Those Models</h3></a>
<p>Now that we're all set we bind the various pipeline stuff like before. This
time, instead of writing the push constants once and then calling draw once, we
do a loop over all the models. For each model we compute the final MVP matrix by
going <code>vp * model</code>, push that, and then do a draw call.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        // ONE DRAW CALL PER MODEL MATRIX WE'RE GIVEN
        for model in models.iter() {
          // DETERMINE FINAL MVP MATRIX (once per model)
          let mvp = vp * model;
          encoder.push_graphics_constants(
            &amp;self.pipeline_layout,
            ShaderStageFlags::VERTEX,
            0,
            cast_slice::&lt;f32, u32&gt;(&amp;mvp.data)
              .expect(&quot;this cast never fails for same-aligned same-size data&quot;),
          );
          encoder.draw_indexed(0..36, 0, 0..1);
        }
#}</code></pre></pre>
<p>That's it! We've got cubes!</p>
<p>Well, no, not yet, we have to setup the rest of the pipeline to support our new
draw method, but we're well on the way to cubes.</p>
<a class="header" href="#new-buffer-data" id="new-buffer-data"><h1>New Buffer Data</h1></a>
<p>Let's put that cube data in our buffers!</p>
<a class="header" href="#defining-a-vertex-type" id="defining-a-vertex-type"><h2>Defining A <code>Vertex</code> Type</h2></a>
<p>As promised, we'll finally define a type for the Vertex format.</p>
<p>First, it must be <code>repr(C)</code>. Second, we'll give it a static function to spit out
the appropriate <code>Vec&lt;AttributeDesc&gt;</code> for the type. That way the two definitions
sit as close as possible in the code and we're more likely to change both at the
same time if one of them has a change.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Copy)]
#[repr(C)]
pub struct Vertex {
  xyz: [f32; 3],
  uv: [f32; 2],
}
impl Vertex {
  pub fn attributes() -&gt; Vec&lt;AttributeDesc&gt; {
    let position_attribute = AttributeDesc {
      location: 0,
      binding: 0,
      element: Element {
        format: Format::Rgb32Float,
        offset: 0,
      },
    };
    let uv_attribute = AttributeDesc {
      location: 1,
      binding: 0,
      element: Element {
        format: Format::Rg32Float,
        offset: size_of::&lt;[f32; 3]&gt;() as ElemOffset,
      },
    };
    vec![position_attribute, uv_attribute]
  }
}
#}</code></pre></pre>
<a class="header" href="#define-the-cube-vertexes" id="define-the-cube-vertexes"><h2>Define The Cube Vertexes</h2></a>
<p>Now at the minimum a cube needs 8 points. However, to make the textures show up
properly we'll need to have 6 quads so that the triangles can wind properly.
This means that we'll need 24 vertexes. Unfortunate.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[cfg_attr(rustfmt, rustfmt_skip)]
const CUBE_VERTEXES: [Vertex; 24] = [
  // Face 1 (front)
  Vertex { xyz: [0.0, 0.0, 0.0], uv: [0.0, 1.0] }, /* bottom left */
  Vertex { xyz: [0.0, 1.0, 0.0], uv: [0.0, 0.0] }, /* top left */
  Vertex { xyz: [1.0, 0.0, 0.0], uv: [1.0, 1.0] }, /* bottom right */
  Vertex { xyz: [1.0, 1.0, 0.0], uv: [1.0, 0.0] }, /* top right */
  // Face 2 (top)
  Vertex { xyz: [0.0, 1.0, 0.0], uv: [0.0, 1.0] }, /* bottom left */
  Vertex { xyz: [0.0, 1.0, 1.0], uv: [0.0, 0.0] }, /* top left */
  Vertex { xyz: [1.0, 1.0, 0.0], uv: [1.0, 1.0] }, /* bottom right */
  Vertex { xyz: [1.0, 1.0, 1.0], uv: [1.0, 0.0] }, /* top right */
  // Face 3 (back)
  Vertex { xyz: [0.0, 0.0, 1.0], uv: [0.0, 1.0] }, /* bottom left */
  Vertex { xyz: [0.0, 1.0, 1.0], uv: [0.0, 0.0] }, /* top left */
  Vertex { xyz: [1.0, 0.0, 1.0], uv: [1.0, 1.0] }, /* bottom right */
  Vertex { xyz: [1.0, 1.0, 1.0], uv: [1.0, 0.0] }, /* top right */
  // Face 4 (bottom)
  Vertex { xyz: [0.0, 0.0, 0.0], uv: [0.0, 1.0] }, /* bottom left */
  Vertex { xyz: [0.0, 0.0, 1.0], uv: [0.0, 0.0] }, /* top left */
  Vertex { xyz: [1.0, 0.0, 0.0], uv: [1.0, 1.0] }, /* bottom right */
  Vertex { xyz: [1.0, 0.0, 1.0], uv: [1.0, 0.0] }, /* top right */
  // Face 5 (left)
  Vertex { xyz: [0.0, 0.0, 1.0], uv: [0.0, 1.0] }, /* bottom left */
  Vertex { xyz: [0.0, 1.0, 1.0], uv: [0.0, 0.0] }, /* top left */
  Vertex { xyz: [0.0, 0.0, 0.0], uv: [1.0, 1.0] }, /* bottom right */
  Vertex { xyz: [0.0, 1.0, 0.0], uv: [1.0, 0.0] }, /* top right */
  // Face 6 (right)
  Vertex { xyz: [1.0, 0.0, 0.0], uv: [0.0, 1.0] }, /* bottom left */
  Vertex { xyz: [1.0, 1.0, 0.0], uv: [0.0, 0.0] }, /* top left */
  Vertex { xyz: [1.0, 0.0, 1.0], uv: [1.0, 1.0] }, /* bottom right */
  Vertex { xyz: [1.0, 1.0, 1.0], uv: [1.0, 0.0] }, /* top right */
];
#}</code></pre></pre>
<a class="header" href="#define-the-cube-indexes" id="define-the-cube-indexes"><h2>Define The Cube Indexes</h2></a>
<p>Of course, we need some indexes to go with the vertexes. We have to be very
careful here because if you get the winding on your triangles wrong things look
very bad very fast.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[cfg_attr(rustfmt, rustfmt_skip)]
const CUBE_INDEXES: [u16; 36] = [
   0,  1,  2,  2,  1,  3, // front
   4,  5,  6,  7,  6,  5, // top
  10,  9,  8,  9, 10, 11, // back
  12, 14, 13, 15, 13, 14, // bottom
  16, 17, 18, 19, 18, 17, // left
  20, 21, 22, 23, 22, 21, // right
];
#}</code></pre></pre>
<a class="header" href="#other-stuff" id="other-stuff"><h2>Other Stuff</h2></a>
<p>At this point you can figure out the rest yourself, and you can look at the
final code if there's a bit you're missing, but basically we want to fix up
<code>HalState</code> to have a field for the cube vertex buffer and the cube index buffer.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  cube_vertices: BufferBundle&lt;back::Backend, back::Device&gt;,
  cube_indexes: BufferBundle&lt;back::Backend, back::Device&gt;,
#}</code></pre></pre>
<p>And then you want to fill those up just once during initialization.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    let cube_vertices = BufferBundle::new(
      &amp;adapter,
      &amp;device,
      size_of_val(&amp;CUBE_VERTEXES),
      BufferUsage::VERTEX,
    )?;

    // Write the vertex data just once.
    unsafe {
      let mut data_target = device
        .acquire_mapping_writer(&amp;cube_vertices.memory, 0..cube_vertices.requirements.size)
        .map_err(|_| &quot;Failed to acquire an index buffer mapping writer!&quot;)?;
      data_target[..CUBE_VERTEXES.len()].copy_from_slice(&amp;CUBE_VERTEXES);
      device
        .release_mapping_writer(data_target)
        .map_err(|_| &quot;Couldn't release the index buffer mapping writer!&quot;)?;
    }

    let cube_indexes = BufferBundle::new(
      &amp;adapter,
      &amp;device,
      size_of_val(&amp;CUBE_INDEXES),
      BufferUsage::INDEX,
    )?;

    // Write the index data just once.
    unsafe {
      let mut data_target = device
        .acquire_mapping_writer(&amp;cube_indexes.memory, 0..cube_indexes.requirements.size)
        .map_err(|_| &quot;Failed to acquire an index buffer mapping writer!&quot;)?;
      data_target[..CUBE_INDEXES.len()].copy_from_slice(&amp;CUBE_INDEXES);
      device
        .release_mapping_writer(data_target)
        .map_err(|_| &quot;Couldn't release the index buffer mapping writer!&quot;)?;
    }
#}</code></pre></pre>
<p>In the graphics pipeline we need to change the rasterizer so that the back faces
of each triangle are culled. Without the culling, you'll get a bizarre looking
thing where the insides and the outsides of the cubes are drawn at the same
time. Like something Escher might draw.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let rasterizer = Rasterizer {
        depth_clamping: false,
        polygon_mode: PolygonMode::Fill,
        cull_face: Face::BACK,
        front_face: FrontFace::Clockwise,
        depth_bias: None,
        conservative: false,
      };
#}</code></pre></pre>
<p>Finally we need to change up the push_constants to be 16 floats in the Vertex
shader instead of 1 float in the fragment shader:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let push_constants = vec![(ShaderStageFlags::VERTEX, 0..16)];
#}</code></pre></pre>
<a class="header" href="#new-shaders" id="new-shaders"><h1>New Shaders</h1></a>
<p>Of course we'll need our GLSL to use the new data properly too.</p>
<a class="header" href="#vertex-shader-1" id="vertex-shader-1"><h2>Vertex Shader</h2></a>
<p>This is the &quot;interesting&quot; part, by which I mean that it's where the coordinate
spaces all meet up and shift around. However, it's not very interesting code to
just look at, since it boils down to basically one expression.</p>
<p>I said above that the &quot;right most&quot; part of a matrix transform stack happens
&quot;first&quot;, but what's it happening to? The data vector at the very far right of
the whole final equation of course. As I glibly said at the start of the
article, we take our 3D coordinate, add a <code>w</code> component of 1.0, and then
multiply it through our big matrix stack. Whatever comes out the left side is
the NDC of the position.</p>
<pre><code class="language-glsl">#version 450
layout (push_constant) uniform PushConsts {
  mat4 mvp;
} push;

layout (location = 0) in vec3 position;
layout (location = 1) in vec2 vert_uv;

layout (location = 0) out gl_PerVertex {
  vec4 gl_Position;
};
layout (location = 1) out vec2 frag_uv;

void main()
{
  gl_Position = push.mvp * vec4(position, 1.0);
  frag_uv = vert_uv;
}
</code></pre>
<a class="header" href="#fragment-shader-1" id="fragment-shader-1"><h2>Fragment Shader</h2></a>
<p>The fragment shader this time is simplified from last time. We don't need any
color shifting or anything at this point, just having some boxes should be
interesting enough to look at.</p>
<pre><code class="language-glsl">#version 450
layout(set = 0, binding = 0) uniform texture2D tex;
layout(set = 0, binding = 1) uniform sampler samp;

layout (location = 1) in vec2 frag_uv;

layout (location = 0) out vec4 color;

void main()
{
  color = texture(sampler2D(tex, samp), frag_uv);
}
</code></pre>
<a class="header" href="#update-the-main-functionality" id="update-the-main-functionality"><h1>Update The <code>main</code> Functionality</h1></a>
<p>So our <code>do_the_render</code> function simplifies down to just one line:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn do_the_render(hal_state: &amp;mut HalState, local_state: &amp;LocalState) -&gt; Result&lt;(), &amp;'static str&gt; {
  hal_state.draw_cubes_frame(&amp;local_state.cubes)
}
#}</code></pre></pre>
<a class="header" href="#time-per-frame" id="time-per-frame"><h2>Time Per Frame</h2></a>
<p>Last lesson we just tracked the time since the program started. That's fine if
your animation follows a perfect and immutable pattern (like sine wave shifting
between two modes), but most things aren't like that. Most of the time we want
to know the amount of time per frame so that we can apply that much time towards
an animation that might or might not be happening.</p>
<p>So we'll start tracking a time per frame. This will be a very basic &quot;Semi-fixed
Time Step&quot; scheme (there's an <a href="https://gafferongames.com/post/fix_your_timestep/">article all about
it</a>). Basically, each time
through the loop we'll accumulate some time. If there's enough time accumulated
we'll advance the &quot;state&quot; of our program (in our case we rotate the cubes some).</p>
<a class="header" href="#userinput-1" id="userinput-1"><h3>UserInput</h3></a>
<p>First we have to adjust the <code>UserInput</code> type so that the time taken is part of
the input for the frame. It could go just about anywhere as long as we check the
time once per frame, but if we consider the timing to be part of the input then
at some future point we could just start recording inputs and then playing them
back and they'll play back with the right associated timings. Bam, we've got
looped replay for practically nothing.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Default)]
pub struct UserInput {
  pub end_requested: bool,
  pub new_frame_size: Option&lt;(f64, f64)&gt;,
  pub new_mouse_position: Option&lt;(f64, f64)&gt;,
  pub seconds: f32,
}
#}</code></pre></pre>
<p>Now when we make a <code>UserInput</code> value we'll also take the timestamp from the last frame:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn poll_events_loop(events_loop: &amp;mut EventsLoop, last_timestamp: &amp;mut Instant) -&gt; Self {
#}</code></pre></pre>
<p>And after the call to <code>poll_events</code> we also set the <code>seconds</code> field.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    output.seconds = {
      let now = Instant::now();
      let duration = now.duration_since(*last_timestamp);
      *last_timestamp = now;
      duration.as_secs() as f32 + duration.subsec_nanos() as f32 * 1e-9
    };
#}</code></pre></pre>
<a class="header" href="#localstate-1" id="localstate-1"><h3>LocalState</h3></a>
<p>Now we update <code>LocalState</code> to track the spare time we had from last time:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Default)]
pub struct LocalState {
  pub frame_width: f64,
  pub frame_height: f64,
  pub mouse_x: f64,
  pub mouse_y: f64,
  pub cubes: Vec&lt;glm::TMat4&lt;f32&gt;&gt;,
  pub spare_time: f32,
}
#}</code></pre></pre>
<p>And every frame when we update, we'll use 1/60th of a second of time if it's
available. This makes the physics work as smoothly as possible. Of course, in a
full program you'd need some more checks before you blindly perform however many
physics frames all at once. If the system clock goes backwards maybe skip doing
physics that frame. If the system clock jumps forward too many frames at once
maybe cap out at some handful and discard the rest. And ideally you'd need to
make sure that your computation time per frame is <em>on average</em> less than the
actual time otherwise your leftover time would grow forever and the system would
chug slower and slower. Time has a lot of fiddly bits to get right if you want
to be robust about it.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl LocalState {
  pub fn update_from_input(&amp;mut self, input: UserInput) {
    if let Some(frame_size) = input.new_frame_size {
      self.frame_width = frame_size.0;
      self.frame_height = frame_size.1;
    }
    if let Some(position) = input.new_mouse_position {
      self.mouse_x = position.0;
      self.mouse_y = position.1;
    }
    assert!(self.frame_width != 0.0 &amp;&amp; self.frame_height != 0.0);
    let x_axis = (self.mouse_x / self.frame_width) as f32;
    let y_axis = (self.mouse_y / self.frame_height) as f32;
    self.spare_time += input.seconds;
    const ONE_SIXTIETH: f32 = 1.0 / 60.0;
    while self.spare_time &gt; 0.0 {
      for (i, cube_mut) in self.cubes.iter_mut().enumerate() {
        let r = ONE_SIXTIETH * 30.0 * (i as f32 + 1.0);
        *cube_mut = glm::rotate(
          &amp;cube_mut,
          f32::to_radians(r),
          // if you change z to 0.0 you need to assert that x_axis and y_axis
          // don't also end up as 0.0, otherwise you'll get NaN when you
          // normalize and then you'll get NaN in your matrix and then nothing
          // will display.
          &amp;glm::make_vec3(&amp;[x_axis, y_axis, 0.3]).normalize(),
        );
      }
      self.spare_time -= ONE_SIXTIETH;
    }
  }
}
#}</code></pre></pre>
<p>As to the actual &quot;physics&quot; we're doing, we'll just rotate the cubes some. Since
I still want a little interaction, so we'll have the mouse position control the
angle of rotation.</p>
<p>And now we got spinny boxes!</p>
<p><img src="images/coordinates-complete.png" alt="coordinates-complete" /></p>
<p>As always, full code is available in the <a href="https://github.com/Lokathor/learn-gfx-hal/tree/master/examples">examples directory</a>.</p>
<a class="header" href="#camera" id="camera"><h1>Camera</h1></a>
<p>Now that we've got everything in the right coordinate system, let's play around
a little bit with that.</p>
<p>Quick Review:</p>
<p>A <strong>Transformation</strong> converts a point within one coordinate system into a new
point in either the same coordinate system or a new coordinate system. When you
apply the same transformation to a group of points, you can <strong>Translate</strong>
(position change), <strong>Rotate</strong> (orientation change), or <strong>Scale</strong> (size change)
that whole group.</p>
<ul>
<li>The Model Matrix transforms model space points into world space points. It
&quot;places&quot; the model within the world. A &quot;model&quot; can be any collection of
points, from a single point or a single line segment all the way up to <em>Geralt
of Rivea</em> (clocking in at around 30,000 triangles in his Witcher 2 model,
according to a quick google).</li>
<li>The View Matrix transforms world space into view space. Instead of placing the
camera in the world, it's actually the opposite sort of effect. It re-places
everything within the whole world into the camera's vision of things, with the
camera at the view space origin.</li>
<li>The Projection Matrix transforms view space into Normalized Device
Coordinates. This acts like the &quot;lens&quot; of the camera, and it's where things
like field of view angle come into play.</li>
</ul>
<p>So in this lesson we'll first show an Orthographic Projection matrix, and then
we'll focus on two different camera types.</p>
<p>Side Note: Within math in general there <em>are</em> also other types of transformation
besides translate, rotate, and scale. However, we don't use them in our graphics
programming.</p>
<a class="header" href="#quick-patch" id="quick-patch"><h2>Quick Patch</h2></a>
<p>I've forgotten until now, but there's an important little bit you'll want to
know about on Windows. There's a special attribute that you can set on your
program to make it not have an attached console. This makes it so that if you
run the program from outside of a terminal it won't open up a dummy terminal in
the background.</p>
<p><code>windows_subsystem = &quot;windows&quot;</code></p>
<p>However, this also makes it so that the program can't do terminal output <em>even
if</em> it was run from a terminal. Since we want to see terminal debug output stuff
in debug builds, we want to only activate this attribute in builds <em>without</em>
<code>debug_assertions</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#![cfg_attr(not(debug_assertions), windows_subsystem = &quot;windows&quot;)]
#fn main() {
#}</code></pre></pre>
<p>(Note: if you have <code>windows_subsystem = &quot;windows&quot;</code> set on a program and run it
from the command line of a terminal <em>other than</em> <code>cmd.exe</code> and PowerShell (eg:
Git Bash) you might still get terminal output. But you have to ask yourself, who
would be so heretical?</p>
<a class="header" href="#orthographic-projection" id="orthographic-projection"><h1>Orthographic Projection</h1></a>
<p>I mentioned it in passing before, but there's a second major category of
projection that you might sometimes use. We're currently using
<a href="https://en.wikipedia.org/wiki/3D_projection#Perspective_projection">Perspective</a>,
which makes things look &quot;real&quot; because parallel lines will converge as they move
away from you. There's also
<a href="https://en.wikipedia.org/wiki/3D_projection#Orthographic_projection">Orthographic</a>,
which makes things look more &quot;tactical&quot; because parallel lines <em>don't</em> meet up
in the distance. Like SimCity or Civilization.</p>
<p>Since our scene is a bunch of cubes floating around in space, the orthographic
projection is going to look kinda weird, but we'll slot it in there as an
option. When the users presses the Tab key it'll flip a bool to swap between the
two projections.</p>
<a class="header" href="#update-draw_cubes_frame" id="update-draw_cubes_frame"><h2>Update <code>draw_cubes_frame</code></h2></a>
<p>First, we'll want to control the view and projection as part of our LocalState
now. That makes sense, in a game the camera position is more a part of the game
state than a part of the graphics driver.</p>
<p>We just adjust the function to accept a <code>view_projection</code> matrix that it's given
for the scene, and we'll just decide what the view and projection are before we
call here.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn draw_cubes_frame(
    &amp;mut self, view_projection: &amp;glm::TMat4&lt;f32&gt;, models: &amp;[glm::TMat4&lt;f32&gt;],
  ) -&gt; Result&lt;(), &amp;'static str&gt; {
#}</code></pre></pre>
<a class="header" href="#update-userinput" id="update-userinput"><h2>Update <code>UserInput</code></h2></a>
<p>Now we have to track if the user wants us to swap the projection. First we add
another field to the inputs.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Default)]
pub struct UserInput {
  pub end_requested: bool,
  pub new_frame_size: Option&lt;(f64, f64)&gt;,
  pub new_mouse_position: Option&lt;(f64, f64)&gt;,
  pub swap_projection: bool,
  pub seconds: f32,
}
#}</code></pre></pre>
<p>Then we add another match case to our event polling:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      Event::WindowEvent {
        event:
          WindowEvent::KeyboardInput {
            input:
              KeyboardInput {
                state: ElementState::Pressed,
                virtual_keycode: Some(VirtualKeyCode::Tab),
                ..
              },
            ..
          },
        ..
      } =&gt; {
        // Each time we see TAB we flip if a projection swap has been requested.
        // This will probably only happen once per frame anyway.
        output.swap_projection = !output.swap_projection;
      }
#}</code></pre></pre>
<p>Ya get all that? It's pretty wordy, but that's just the <code>winit</code> way to say &quot;Tab
was pressed&quot;: KeyboardInput + EventState::Pressed + VirtualKeyCode::Tab.</p>
<a class="header" href="#update-localstate" id="update-localstate"><h2>Update <code>LocalState</code></h2></a>
<p>Now the <code>LocalState</code> will hold two different projection matrices: one for
perspective and one for orthographic. We'll flip which one we use with a bool.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone)]
pub struct LocalState {
  pub frame_width: f64,
  pub frame_height: f64,
  pub mouse_x: f64,
  pub mouse_y: f64,
  pub cubes: Vec&lt;glm::TMat4&lt;f32&gt;&gt;,
  pub view: glm::TMat4&lt;f32&gt;,
  pub perspective_projection: glm::TMat4&lt;f32&gt;,
  pub orthographic_projection: glm::TMat4&lt;f32&gt;,
  pub is_orthographic: bool,
  pub spare_time: f32,
}
#}</code></pre></pre>
<p>Which means we add a bit to our &quot;update from user input&quot; method:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    if input.swap_projection {
      self.is_orthographic = !self.is_orthographic;
    }
#}</code></pre></pre>
<p>and now we need to initialize all the new data when we first make the LocalState
value. Once again, <code>nalgebra-glm</code> has many different <code>orthographic</code> projections
to pick from, and we want <code>_lh_zo</code>. This time instead of picking an aspect ratio
and view angle (plus near plane and far plane) we pick the left, right, bottom,
and top bounds of the view (plus near plane and far plane). The bounds are in
world coordinates, and I picked +/- 5.0 since our cubes are in that general
area. For your own code you'd need to decide on a comfortable value based on
your world scale and such.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    LocalState {
      frame_width,
      frame_height,
      mouse_x: 0.0,
      mouse_y: 0.0,
      cubes: vec![
        glm::identity(),
        glm::translate(&amp;glm::identity(), &amp;glm::make_vec3(&amp;[1.5, 0.1, 0.0])),
        glm::translate(&amp;glm::identity(), &amp;glm::make_vec3(&amp;[-3.0, 2.0, 3.0])),
        glm::translate(&amp;glm::identity(), &amp;glm::make_vec3(&amp;[0.5, -4.0, 4.0])),
        glm::translate(&amp;glm::identity(), &amp;glm::make_vec3(&amp;[-3.4, -2.3, 1.0])),
        glm::translate(&amp;glm::identity(), &amp;glm::make_vec3(&amp;[-2.8, -0.7, 5.0])),
      ],
      spare_time: 0.0,
      view: glm::look_at_lh(
        &amp;glm::make_vec3(&amp;[0.0, 0.0, -5.0]),
        &amp;glm::make_vec3(&amp;[0.0, 0.0, 0.0]),
        &amp;glm::make_vec3(&amp;[0.0, 1.0, 0.0]).normalize(),
      ),
      perspective_projection: {
        let mut temp = glm::perspective_lh_zo(800.0 / 600.0, f32::to_radians(50.0), 0.1, 100.0);
        temp[(1, 1)] *= -1.0;
        temp
      },
      orthographic_projection: {
        let mut temp = glm::ortho_lh_zo(-5.0, 5.0, -5.0, 5.0, 0.1, 100.0);
        temp[(1, 1)] *= -1.0;
        temp
      },
      is_orthographic: false,
    }
#}</code></pre></pre>
<p>And then in do_the_render we pick the right projection, combine it with our
view, and call <code>draw_cubes_frame</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn do_the_render(hal_state: &amp;mut HalState, local_state: &amp;LocalState) -&gt; Result&lt;(), &amp;'static str&gt; {
  let projection = if local_state.is_orthographic {
    local_state.orthographic_projection
  } else {
    local_state.perspective_projection
  };
  let view_projection = projection * local_state.view;
  hal_state.draw_cubes_frame(&amp;view_projection, &amp;local_state.cubes)
}
#}</code></pre></pre>
<p>Now we can see how ugly an orthographic projection is!</p>
<p>Well, it's not always ugly, but we'd really need to have a different sort of
scene of stuff to look at if we wanted it to look good. Unfortunately that's a
little out of scope at the moment, so I'll leave trying that out up to you now
that you know what to do. Right now I just wanted you to know that it's
<em>possible</em>, and let you have a sense of why the <code>view</code> and <code>projection</code> matrix
data isn't always just a single matrix based on the camera position.</p>
<a class="header" href="#euler-angle-fps-camera" id="euler-angle-fps-camera"><h1>Euler Angle FPS Camera</h1></a>
<p>Ultimately a camera is just about picking a <strong>location</strong> and <strong>orientation</strong> of
where you're looking at things from. However, there's actually a few major types
of camera similar to how there's a few major types of projection.</p>
<p>First we'll go over a camera that uses &quot;<a href="https://en.wikipedia.org/wiki/Euler_angles">Euler
Angles</a>&quot; to act like a First Person
Shooter (FPS) camera. It's probably the easiest style of camera to think about.
Euler angles means <code>pitch</code>, <code>roll</code>, and <code>yaw</code>. Like a plane.</p>
<ul>
<li><code>pitch</code>: angle up and down</li>
<li><code>roll</code>: angle rocking side to side</li>
<li><code>yaw</code>: angle left and right</li>
</ul>
<p>Actually, I lied just now, we <strong>won't</strong> be handling <code>roll</code>. If you allow the
user to adjust their <code>roll</code> value as much as they want they can trigger a
<a href="https://en.wikipedia.org/wiki/Gimbal_lock">Gimbal Lock</a>. For most first person
experiences you don't need roll at all, so we'll block the user from
accidentally giving themselves problems.</p>
<p>Also, we'll limit the maximum <code>pitch</code> value to +/- 89 degrees. You remember that
<code>up</code> vector thing from the <code>look_at</code> projection? If the <code>pitch</code> is allowed to
hit 90 degrees then the <code>up</code> vector and the <code>front</code> vector line up and that's a
problem too. Technically you <em>could</em> get around this pitch limitation, but
letting the user get flipped over backwards is probably good enough reason to
keep it in. Most users are actually very comfortable with the idea that they
can't just look up more and more until their perspective has flipped over
entirely, so it's still &quot;professional quality&quot; to have this limit in place.</p>
<p>If you <em>do</em> want to enable total freedom of movement that'll be available in
the next camera we go over.</p>
<a class="header" href="#eulercamera-struct" id="eulercamera-struct"><h2>EulerCamera Struct</h2></a>
<p>So we need a <em>location</em> and <em>orientation</em>. Our struct can hold exactly that:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Copy)]
pub struct EulerFPSCamera {
  pub position: glm::TVec3&lt;f32&gt;,
  pitch_deg: f32,
  yaw_deg: f32,
}
#}</code></pre></pre>
<p>We've got a little extra note there in the names that the pitch and yaw will be
in degrees, because degrees are usually easier for a human to think about, but
the <code>sin</code> and <code>cos</code> functions are for <code>radians</code>, so when we eventually call
those we'll need a conversion first.</p>
<p>Now we declare the &quot;up&quot; vector, which is always the same for this particular
camera. We need it for moving the camera and also for creating the <code>look_at</code>
view matrix. Unfortunately, I'm not seeing a <code>const</code> function for making a TVec3
value, so we'll declare the array as a const and then just convert it into a
TVec3 when we need to.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl EulerCamera {
  const UP: [f32; 3] = [0.0, 1.0, 0.0];
#}</code></pre></pre>
<p>Next we want a &quot;front&quot; or &quot;forward&quot; vector. This is a vector that points forward
out of the camera into the world. We're actually tracking our pitch and yaw as
angles, but we'll need the front vector for doing movement and computing the
<code>look_at</code> matrix. This involves some <code>sin</code> and <code>cos</code> calls, so we have to
convert our degree values into radian values. If we wanted we could cache this
vector along side our angle values, but that's not really necessary (you
probably only touch your camera once per frame) so we'll keep it simple and just
build the vector from scratch each time.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  fn make_front(&amp;self) -&gt; glm::TVec3&lt;f32&gt; {
    let pitch_rad = f32::to_radians(self.pitch_deg);
    let yaw_rad = f32::to_radians(self.yaw_deg);
    glm::make_vec3(&amp;[
      yaw_rad.sin() * pitch_rad.cos(),
      pitch_rad.sin(),
      yaw_rad.cos() * pitch_rad.cos(),
    ])
  }
#}</code></pre></pre>
<p>Orientation updates are pretty simple, but we have to be mindful of the limits
we talked about. We'll cap <code>pitch</code> at +/- 89 degrees, and we'll make sure that
the <code>yaw</code> value gets wrapped to being within +/- 360.0 degrees. Remember that
floats are more accurate the closer they are to zero, and we don't want any
weird accuracy problems creeping up on us.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn update_orientation(&amp;mut self, d_pitch_deg: f32, d_yaw_deg: f32) {
    self.pitch_deg = (self.pitch_deg + d_pitch_deg).max(-89.0).min(89.0);
    self.yaw_deg = (self.yaw_deg + d_yaw_deg) % 360.0;
  }
#}</code></pre></pre>
<p>Now we need a way to update the <em>position</em> of the camera. First of all, you can
just assign the camera any new position at any time and it'll work right. However, we also want to support going &quot;forward&quot; and &quot;sideways&quot; relative to the current perspective (like you do in a first person game), so we'll want a method for that.</p>
<p>We take in which keys are being held down and then how far the camera should
move in whatever direction the keys determine. The distance moved is
camera_speed * time_elapsed, but whoever calls <code>update_position</code> can just
compute that on their side before they call us.</p>
<p>The way that this works is that we first gather up all the deltas that the keys
are trying to get us to do. If that total is zero we didn't move so we're done.
If it's non-zero we first have to normalize the direction vector. If we didn't
normalize our direction vector then moving forward <em>or</em> sideways would be &quot;1&quot;
unit of distance but moving forward <em>and</em> sideways would end up being &quot;1.4&quot;
(technically <code>sqrt(2)</code>) units of distance (<a href="https://en.wikipedia.org/wiki/Pythagorean_theorem">Pythagorean
theorem</a>, yo). It's pretty
silly for diagonal movement to be faster than direct movement, and even
professional games such as
<a href="https://en.wikipedia.org/wiki/The_Elder_Scrolls_III:_Morrowind">Morrowind</a> and
<a href="https://en.wikipedia.org/wiki/Obduction_(video_game)">Obduction</a> make this easy
mistake.</p>
<p>Once we have our normalized direction vector, we scale the vector by our
distance value and add it to our position.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn update_position(&amp;mut self, keys: &amp;HashSet&lt;VirtualKeyCode&gt;, distance: f32) {
    let up = glm::make_vec3(&amp;Self::UP);
    let forward = self.make_front();
    let cross_normalized = glm::cross::&lt;f32, glm::U3&gt;(&amp;forward, &amp;up).normalize();
    let mut move_vector =
      keys
        .iter()
        .fold(glm::make_vec3(&amp;[0.0, 0.0, 0.0]), |vec, key| match *key {
          VirtualKeyCode::W =&gt; vec + forward,
          VirtualKeyCode::S =&gt; vec - forward,
          VirtualKeyCode::A =&gt; vec + cross_normalized,
          VirtualKeyCode::D =&gt; vec - cross_normalized,
          VirtualKeyCode::E =&gt; vec + up,
          VirtualKeyCode::Q =&gt; vec - up,
          _ =&gt; vec,
        });
    if move_vector != glm::zero() {
      move_vector = move_vector.normalize();
      self.position += move_vector * distance;
    }
  }
#}</code></pre></pre>
<p>I've implemented it as a &quot;flying&quot; style camera here. It uses the front vector
for movement, so if you look up while going forward then you also move up
(depending on pitch). I've also set <code>Q</code> and <code>E</code> to shift the camera directly up
and down. If that's not appropriate for your own program then you'd want to
compute a forward vector with just X and Z changes based on <code>yaw</code> alone. What
you'd probably actually want is to directly place the camera within the location
given to you by some physics object as it moves through the simulation, and just
let the physics system handle all the position updates. Just assigning to the
position field directly is fine, that's why it's <code>pub</code>.</p>
<p>(Note, the <code>A</code> and <code>D</code> math is sensitive to the fact that the projection matrix
is flipping <code>Y</code> values <em>after</em> they pass through the View matrix. In other
words, if you port this code to OpenGL where <code>Y</code> is up naturally then you'll
need to flip which one is <code>+</code> and which one is <code>-</code>, otherwise you'll move
left/right flipped).</p>
<p>Finally, now that we can adjust the details on our camera, we just need to ask
it to please give us the correct view matrix.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn make_view_matrix(&amp;self) -&gt; glm::TMat4&lt;f32&gt; {
    glm::look_at_lh(
      &amp;self.position,
      &amp;(self.position + self.make_front()),
      &amp;glm::make_vec3(&amp;Self::UP),
    )
  }
#}</code></pre></pre>
<p>Oh, and it needs at least one constructor because of those private fields. Let's
give it a const constructor for being at a particular position. Always nice to
have a const constructor if you can manage it.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub const fn at_position(position: glm::TVec3&lt;f32&gt;) -&gt; Self {
    Self {
      position,
      pitch_deg: 0.0,
      yaw_deg: 0.0,
    }
  }
#}</code></pre></pre>
<a class="header" href="#update-localstate-1" id="update-localstate-1"><h2>Update <code>LocalState</code></h2></a>
<p>Now that we've got this nice camera we can replace out view matrix field with a
camera field.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone)]
pub struct LocalState {
  pub frame_width: f64,
  pub frame_height: f64,
  pub mouse_x: f64,
  pub mouse_y: f64,
  pub cubes: Vec&lt;glm::TMat4&lt;f32&gt;&gt;,
  pub camera: EulerCamera,
  pub perspective_projection: glm::TMat4&lt;f32&gt;,
  pub orthographic_projection: glm::TMat4&lt;f32&gt;,
  pub is_orthographic: bool,
  pub spare_time: f32,
}
#}</code></pre></pre>
<p>And in the LocalState initializer we need to place the camera at the same
position as before.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
camera: EulerCamera::at_position(glm::make_vec3(&amp;[0.0, 0.0, -5.0])),
#}</code></pre></pre>
<p>which means that <code>do_the_render</code> needs a minor update to get a view matrix in
the new way.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn do_the_render(hal_state: &amp;mut HalState, local_state: &amp;LocalState) -&gt; Result&lt;(), &amp;'static str&gt; {
  let projection = if local_state.is_orthographic {
    local_state.orthographic_projection
  } else {
    local_state.perspective_projection
  };
  let view_projection = projection * local_state.camera.make_view_matrix();
  hal_state.draw_cubes_frame(&amp;view_projection, &amp;local_state.cubes)
}
#}</code></pre></pre>
<p>That finally brings us to <code>LocalState::update_from_input</code>.</p>
<p>This part is a little bit of a pickle. We're updating our &quot;physics&quot; by 1/60th of
a second every 1/60th of a second. However, we're accepting input faster than
that in some cases (if Mailbox mode is selected). Does the camera count as part
of our physics? Can we do some updates to it faster than 60fps and then others
at only 60fps? Should we buffer <em>all</em> updates until the next physics frame and
only do them exactly when the rest of the physics happens? Well, unfortunately
that's an answer you'll need to sort out for yourself.</p>
<p>Our camera isn't <em>really</em> connected to anything, but if your camera <strong>is</strong>
connected to an actual physics entity (like a player entity) then you'd probably
need to buffer up the inputs that come in faster than 60fps, do your physics at
the right time, and then update your camera only in response to the physics
simulation result. Or you could not even use Mailbox mode if you don't want to
worry about it possibly being there and possibly not being there.</p>
<p>For our example, I'll have the camera code be disjoint from the physics code
just to see how it would be done if you wanted to do it that way.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // do camera updates distinctly from physics, based on this frame's time
    const MOUSE_SENSITIVITY: f32 = 0.05;
    let d_pitch_deg = input.orientation_change.1 * MOUSE_SENSITIVITY;
    let d_yaw_deg = -input.orientation_change.0 * MOUSE_SENSITIVITY;
    self.camera.update_orientation(d_pitch_deg, d_yaw_deg);
    self
      .camera
      .update_position(&amp;input.keys_held, 5.0 * input.seconds);
#}</code></pre></pre>
<a class="header" href="#update-userinput-1" id="update-userinput-1"><h2>Update <code>UserInput</code></h2></a>
<p>So obviously our user input is storing a few more things than before, let's look at that.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Default)]
pub struct UserInput {
  pub end_requested: bool,
  pub new_frame_size: Option&lt;(f64, f64)&gt;,
  pub new_mouse_position: Option&lt;(f64, f64)&gt;,
  pub swap_projection: bool,
  pub keys_held: HashSet&lt;VirtualKeyCode&gt;,
  pub orientation_change: (f32, f32),
  pub seconds: f32,
}
#}</code></pre></pre>
<p>Okay, and we're actually going to be tracking quite a bit more now, so our
polling method has a few more arguments.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn poll_events_loop(
    winit_state: &amp;mut WinitState, last_timestamp: &amp;mut Instant,
    keys_held: &amp;mut HashSet&lt;VirtualKeyCode&gt;, focused: &amp;mut bool, grabbed: &amp;mut bool,
  ) -&gt; Self {
#}</code></pre></pre>
<p>Actually, all that stuff has to do with <code>winit</code> really, so it should be in the
<code>WinitState</code>, don't you think? We're already taking a <code>&amp;mut WinitState</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug)]
pub struct WinitState {
  pub events_loop: EventsLoop,
  pub window: Window,
  pub keys_held: HashSet&lt;VirtualKeyCode&gt;,
  pub grabbed: bool,
}
#}</code></pre></pre>
<p>Alright, and now our match statement is totally different, so we'll take it
again from the top. First though, we have to do an annoying manual split of the
borrow.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl UserInput {
  pub fn poll_events_loop(winit_state: &amp;mut WinitState, last_timestamp: &amp;mut Instant) -&gt; Self {
    let mut output = UserInput::default();
    // We have to manually split the borrow here. rustc, why you so dumb sometimes?
    let events_loop = &amp;mut winit_state.events_loop;
    let window = &amp;mut winit_state.window;
    let keys_held = &amp;mut winit_state.keys_held;
    let grabbed = &amp;mut winit_state.grabbed;
#}</code></pre></pre>
<p>Now we can start the events poll. First up is CloseRequested, which we just mark
down in our output.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // now we actually poll those events
    events_loop.poll_events(|event| match event {
      // Close when asked
      Event::WindowEvent {
        event: WindowEvent::CloseRequested,
        ..
      } =&gt; output.end_requested = true,
#}</code></pre></pre>
<p>Next we need to track what the state of all keys is. This is a little annoying
at the edge cases, because of <a href="https://en.wikipedia.org/wiki/Rollover_(key)">key
rollover</a>, and also because if the
uses presses and holds a key <em>before the window opens</em> we won't get the key
press event for that. Most of the time though we can fairly reliably get key
info. Now there's two ways to do this: one is through the
<a href="https://docs.rs/winit/0.18.1/winit/enum.WindowEvent.html">WindowEvent</a> type and
the other is through the
<a href="https://docs.rs/winit/0.18.1/winit/enum.DeviceEvent.html">DeviceEvent</a> type. We
want to use DeviceEvent. The difference is that you only get window events for
keys when your window is active, but you get device events at all times. If the
user presses or releases a key when the window is out of focus we want to track
that. If they press a key and then click in the window, we want to respond to
that <em>right away</em> without them having to release and press the key again.
Similarly, if they have a key held and then switch to another window, we want to
know if it got released while we didn't have focus.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // Track all keys, all the time. Note that because of key rollover details
      // it's possible to get key released events for keys we don't think are
      // pressed. This is a hardware limit, not something you can evade.
      Event::DeviceEvent {
        event:
          DeviceEvent::Key(KeyboardInput {
            virtual_keycode: Some(code),
            state,
            ..
          }),
        ..
      } =&gt; drop(match state {
        ElementState::Pressed =&gt; keys_held.insert(code),
        ElementState::Released =&gt; keys_held.remove(&amp;code),
      }),
#}</code></pre></pre>
<p>That would be the end of it, but macOS doesn't provide keys as
device events. So we need to handle keys as window events too. Also, even on
non-mac there's a few window event keys that we want to respond do. We're
keeping &quot;tab swaps the projection&quot;, and also we're adding &quot;escape undoes the
grab&quot;.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// We want to respond to some of the keys specially when they're also
      // window events too (meaning that the window was focused when the event
      // happened).
      Event::WindowEvent {
        event:
          WindowEvent::KeyboardInput {
            input:
              KeyboardInput {
                state,
                virtual_keycode: Some(code),
                ..
              },
            ..
          },
        ..
      } =&gt; {
        #[cfg(feature = &quot;metal&quot;)]
        {
          match state {
            ElementState::Pressed =&gt; keys_held.insert(code),
            ElementState::Released =&gt; keys_held.remove(&amp;code),
          }
        };
        if state == ElementState::Pressed {
          match code {
            VirtualKeyCode::Tab =&gt; output.swap_projection = !output.swap_projection,
            VirtualKeyCode::Escape =&gt; {
              if *grabbed {
                debug!(&quot;Escape pressed while grabbed, releasing the mouse!&quot;);
                window
                  .grab_cursor(false)
                  .expect(&quot;Failed to release the mouse grab!&quot;);
                window.hide_cursor(false);
                *grabbed = false;
              }
            }
            _ =&gt; (),
          }
        }
      }
#}</code></pre></pre>
<p>We also want to use <code>DeviceEvent</code> to track mouse motion. The difference between
this and the <code>CursorMoved</code> event from before is that <code>WindowEvent::CursorMoved</code>
gives the <em>position within the window</em>, while <code>DeviceEvent::MouseMotion</code> gives
the mouse's <em>position delta</em>. We're going to &quot;grab&quot; the mouse to lock it within
the window. When the mouse goes all the way to left and hits x=0 we'd stop
getting CursorMoved events, but we want to keep turning the view as long as the
user keeps turning the mouse. By using <code>MouseMotion</code> events we can track the
mouse's intended movement even while the cursor is grabbed.</p>
<p>Also, this is the part where you'd invert the X or Y movement effect if you
wanted to offer that option to users.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // Always track the mouse motion, but only update the orientation if
      // we're &quot;grabbed&quot;.
      Event::DeviceEvent {
        event: DeviceEvent::MouseMotion { delta: (dx, dy) },
        ..
      } =&gt; {
        if *grabbed {
          output.orientation_change.0 -= dx as f32;
          output.orientation_change.1 -= dy as f32;
        }
      }
#}</code></pre></pre>
<p>Next, if the user clicks in the window we'll grab the cursor. There's a literal
<code>grab_cursor</code> call which <em>on Windows</em> will automatically hide the cursor too,
but on macOS and some Linux distributions you have to issue <code>hide_cursor</code> as a separate
command.
We'll just do both, since it doesn't hurt to tell the already-hidden cursor to
hide again on Windows.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // Left clicking in the window causes the mouse to get grabbed
      Event::WindowEvent {
        event:
          WindowEvent::MouseInput {
            state: ElementState::Pressed,
            button: MouseButton::Left,
            ..
          },
        ..
      } =&gt; {
        if *grabbed {
          debug!(&quot;Click! We already have the mouse grabbed.&quot;);
        } else {
          debug!(&quot;Click! Grabbing the mouse.&quot;);
          window.grab_cursor(true).expect(&quot;Failed to grab the mouse!&quot;);
          window.hide_cursor(true);
          *grabbed = true;
        }
      }
#}</code></pre></pre>
<p>If the focus is lost, we want to automatically release any &quot;grab&quot;. This is just
the same two calls with reverse values.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // Automatically release the mouse when focus is lost
      Event::WindowEvent {
        event: WindowEvent::Focused(false),
        ..
      } =&gt; {
        if *grabbed {
          debug!(&quot;Lost Focus, releasing the mouse grab...&quot;);
          window
            .grab_cursor(false)
            .expect(&quot;Failed to release the mouse grab!&quot;);
          window.hide_cursor(false);
          *grabbed = false;
        } else {
          debug!(&quot;Lost Focus when mouse wasn't grabbed.&quot;);
        }
      }
#}</code></pre></pre>
<p>Finally, we'll update our window size still. I'm not sure we're using that any
more, but oh well. We can just track it anyway.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // Update our size info if the window changes size.
      Event::WindowEvent {
        event: WindowEvent::Resized(logical),
        ..
      } =&gt; {
        output.new_frame_size = Some((logical.width, logical.height));
      }
#}</code></pre></pre>
<p>And at the end, after the event polling, we want to be sure to hand over a clone
of the <code>keys_held</code> set <em>only if</em> we're grabbed. Otherwise the program would do
stuff even if it's out of focus. I'm sure there's some program that wants to do
that, but not us.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    output.keys_held = if *grabbed {
      keys_held.clone()
    } else {
      HashSet::new()
    };
#}</code></pre></pre>
<p>And everything works!</p>
<p>Except we can't roll yet.</p>
<a class="header" href="#quaternion-free-camera" id="quaternion-free-camera"><h1>Quaternion Free Camera</h1></a>
<p><em>&quot;what's going on? oh god quaternions, no effin' clue&quot; -Xavil</em></p>
<p>Now we're gonna use <a href="https://en.wikipedia.org/wiki/Quaternion">Quaternions</a>.
They're not super covered in the Khan Academy &quot;Vector and Matrix&quot; math course
that I linked last lesson, at least not from what I saw in their table of
contents listing. Instead, try <a href="https://www.3dgep.com/understanding-quaternions/">this link
here</a> to learn about them, or
perhaps
<a href="http://www.opengl-tutorial.org/intermediate-tutorials/tutorial-17-quaternions/">here</a>
if you want a short version that's mostly computer graphics oriented. You could
also try <a href="https://eater.net/quaternions/">these videos</a> if you're better at
learning through video. Quaternion are sure <em>weird</em>. They're 4D! Isn't that
already pretty weird all on its own?</p>
<p>With the power of quaternions at our finger tips we're going to make a &quot;free
camera&quot;, which means that we can pitch, yaw, <em>and also roll</em> as much as we want.
There's still a <em>mild</em> limit that if there's a large change in more than one
axis in a single <code>update_orientation</code> call then you could trigger a gimbal lock,
but for normal use that's not a danger, and if you really need to do big
orientation changes you can break it into a series of smaller changes.</p>
<p>The math here is actually so complicated that I honestly don't know how most of
it works exactly. However, <a href="https://github.com/termhn">termhn</a> managed to <s>help
me</s> <em>just tell me what to try over and over until it worked</em> and we got a
quaternion free camera going with only mild struggles. Cargo cult programming at
its finest.</p>
<p>So we start with our QuaternionFreeCamera struct, once again we have a public
position field and an internal way to track our orientation. Instead of storing
euler angles we store a quaternion.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Copy)]
pub struct QuaternionFreeCamera {
  pub position: glm::TVec3&lt;f32&gt;,
  quat: glm::Qua&lt;f32&gt;,
}
#}</code></pre></pre>
<p>Now we want to update the orientation. How do we even update a quaternion? Well,
you don't do it directly in an <code>x += 1</code> sort of way. Instead, if we take the
desired change in orientation as a quaternion, we can multiply it by our current
quaternion and the output quaternion is our old one with the change applied.
This is somewhat magical, but it's <em>similar</em> to how you can multiply one
transformation matrix with another and they &quot;combine&quot; into a new transformation.</p>
<p>And I promised that this time we can roll too, so our update function starts
like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl QuaternionFreeCamera {
  pub fn update_orientation(&amp;mut self, d_pitch: f32, d_yaw: f32, d_roll: f32) {
    unimplemented!();
  }
#}</code></pre></pre>
<p>Please note that we're <em>no longer dealing in degrees</em>. You'll see why in a
moment.</p>
<p>Alright so what <em>is</em> a quaternion? Well it's just a way to talk about a 3d
sphere on the surface of a 4d hypersphere. Obviously. Totally normal concept.
How do we represent a quaternion? Well, there's one real axis and three
imaginary axes. You know how a standard imaginary number is like <code>a + bi</code>?
That's one real axis and one imaginary axis. A quaternion is just more imaginary
axes, so we write them as <code>a + bi + cj+ dk</code>.</p>
<p>In code terms, a quaternion is basically four <code>f32</code> values (well, could be
<code>f64</code>, but you know). Normally to make a quaternion you'd use an angle and 3d
axis. The angle is of course in radians and then axis should of course be
normalized. Then you use this formula to get the four components:</p>
<pre><code>x = RotationAxis.x * sin(RotationAngle / 2)
y = RotationAxis.y * sin(RotationAngle / 2)
z = RotationAxis.z * sin(RotationAngle / 2)
w = cos(RotationAngle / 2)
</code></pre>
<p>You'll notice that we've switched from <code>a</code>, <code>b</code>, <code>c</code>, and <code>d</code> to using <code>x</code>, <code>y</code>,
<code>z</code>, and <code>w</code>. That's the convention. Presumably because folks wanted to have a
component output that's related to the input <code>x</code> axis also be named <code>x</code> and
such. So now our &quot;real&quot; component is the <code>w</code> value at the end of the list, not
the <code>a</code> value at the start of the list. Important to keep that straight.</p>
<p>So we could easily call
<a href="https://docs.rs/nalgebra-glm/0.2.1/nalgebra_glm/fn.quat_angle_axis.html">nalgebra_glm::quat_angle_axis</a>
to make a quaternion... but we don't <em>have</em> an axis and angle. We have euler
angles in unknown units.</p>
<p>This is where it gets strange. You see, I read <a href="http://in2gpu.com/2016/03/14/opengl-fps-camera-quaternion/">an
article</a> that
implied that you can just throw the delta values directly into a quaternion and
it works. That is, if you call
<a href="https://docs.rs/nalgebra-glm/0.2.1/nalgebra_glm/fn.quat.html">nalgebra_glm::quat</a>
you <em>can</em> specify <code>x</code>, <code>y</code>, <code>z</code>, and <code>w</code> without needing to know an axis and
angle. Normally you probably wouldn't do this unless you were reading in a
quaternion from a file or something, but that's what the article said to do. I
tried it, and it works. I was just as shocked as you to see this.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    let delta_quat = glm::quat(d_pitch, d_yaw, d_roll, 1.0);
#}</code></pre></pre>
<p>So I asked around and <a href="https://github.com/pinobatch">PinoBatch</a> pointed me to a
thing called <a href="https://en.wikipedia.org/wiki/Paraxial_approximation">Paraxial
Approximation</a>. If you
have a very small angle (&lt;10 degrees) you can skip computing a <code>sin</code> and just
use the value directly with minimal error compared to having done the <code>sin</code>. So
if we assign an input delta directly to <code>x</code>, <code>y</code>, or <code>z</code> we can <em>act like</em> we
did the right thing for some small rotation angle and just get a de-normalized
quaternion value. Okay? So that means that our inputs are effectively <em>double
radians</em>. Obviously(?). If we want to change 1 degree, that's 0.0175 radians,
and so we'd want only <code>0.00875</code> for our delta value.</p>
<p>Well, <em>almost</em>. Because we've got three deltas and we need four parts, so what's
our <code>w</code> value? <a href="https://github.com/grovesNL">groves</a> suggested that &quot;1 is
usually the identity&quot;, so we started with that. And it worked. Do other values
for <code>w</code> work? Yes they also work. As long as the value isn't 0 then it works.
And smaller <code>w</code> makes you spin faster, while large <code>w</code> makes you spin slower. So
if <code>w</code> can affect the rotation speed.... what?</p>
<p>Okay, <em>this</em> is where <a href="https://github.com/aaaaaa123456789">ax6</a> swooped in because
they know quaternions and they don't like cargo cult programming.</p>
<p>So imagine that we wanted to adjust <em>just one</em> axis. That's easy. Keeping in
mind that we're using <em>double</em> radians in place of radians, each axis has a
formula for it like this:</p>
<pre><code>// double radian formulas, divide the angle by 2 for normal radians
q(pitch) = cos(pitch) + (sin(pitch), 0, 0)
q(yaw) = cos(yaw) + (0, sin(yaw), 0)
q(roll) = cos(roll) + (0, 0, sin(roll))
</code></pre>
<p>So we just pick one of those and</p>
<pre><code>new = old * q(yaw)
</code></pre>
<p>But we want three adjustments. Okay, so just like with stacking up matrix
transforms we can stack up quaternion multiplications by adding more on the
right.</p>
<pre><code>new = old * q(yaw) * q(pitch) * q(roll)
</code></pre>
<p>But what does that <em>actually</em> mean if you expand it out?</p>
<pre><code>q(yaw) * q(pitch) = (cos yaw + (0, sin yaw, 0)) * (cos pitch + (sin pitch, 0, 0))
</code></pre>
<p>or alternately</p>
<pre><code>(cos yaw * cos pitch) + (cos yaw * sin pitch, sin yaw * cos pitch, - sin yaw * sin pitch)
</code></pre>
<p>And then we multiply in the q(roll) on the right to get...</p>
<pre><code>q = (cos yaw * cos pitch * cos roll - sin yaw * sin pitch * sin roll) +
  (cos yaw * sin pitch * cos roll + sin yaw * cos pitch * sin roll,
  sin yaw * cos pitch * cos roll - cos yaw * sin pitch * sin roll,
  cos yaw * cos pitch * sin roll - sin yaw * sin pitch * cos roll)
</code></pre>
<p>Which is <em>extremely ugly</em>, but this is where the Paraxial Approximation kicks
in:</p>
<ol>
<li>cos(foo) = 1, since the angles are small</li>
<li>sin(foo) = foo, since the angles are small</li>
<li>sin(foo) * sin(bar) = 0, because with angles being that small, multiplying
two of them gives a tiny number that almost vanishes</li>
</ol>
<p>So all cosines are cancelled out, any term with more than one sine is wholly
cancelled out, and all remaining sines are replaced by the actual angles and you
get an approximation of</p>
<pre><code>q = 1 + (pitch, yaw, roll)
</code></pre>
<p>Since we do a normalization step after multiplying our old quaternion by the
delta quaternion, the approximation is close enough to let it all work out. Our
effective rotation angle of the delta quaternion is <code>2 * arccos(Re(q) / |q|)</code>,
with <code>Re(q)</code> being &quot;the real part of <code>q</code>&quot;, meaning <code>w</code>.  Since <code>arccos</code> has a
negative derivative, increasing the <code>w</code> value reduces the angle of rotation.</p>
<p><strong>So, if you didn't get all that, it's okay.</strong> It's totally fine. We're <em>deep</em>
into the realm of magic here, so if you just want to use this code without
understanding why exactly it all adds up that's okay. Honestly I don't quite get
it myself. Now we finally know how to update our orientation at least:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  /// Updates the orientation of the camera.
  ///
  /// Inputs should be in double radians, and also limited to being less than 10
  /// degrees at a time to keep approximation error minimal.
  pub fn update_orientation(&amp;mut self, d_pitch_2rad: f32, d_yaw_2rad: f32, d_roll_2rad: f32) {
    // This gives a non-unit quaternion! That's okay because of the normalization step.
    let delta_quat = glm::quat(d_pitch_2rad, d_yaw_2rad, d_roll_2rad, 1.0);
    self.quat = glm::quat_normalize(&amp;(self.quat * delta_quat));
  }
#}</code></pre></pre>
<p>To update the position we do mostly the same things as the EulerFPSCamera did.</p>
<p>We sum up all the directions we're trying to go, check that it's non-zero, if so
we normalize it. Then there's a change: we can't yet adjust the magnitude and
then add. First we have to rotate our normalized vector vector with our
quaternion to give it the correct orientation relative to our own orientation.
Once it's rotated we multiply and add like before.</p>
<p>In the EulerFPSCamera the re-orientation was &quot;secretly&quot; a part of the
<code>make_font</code> computation (see how the front vec is based on the current pitch and
yaw values?). Now that we're storing a quaternion it's a little easier to just
do the re-orientation with a single rotation at the end.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn update_position(&amp;mut self, keys: &amp;HashSet&lt;VirtualKeyCode&gt;, distance: f32) {
    let up = glm::make_vec3(&amp;[0.0, 1.0, 0.0]);
    let forward = glm::make_vec3(&amp;[0.0, 0.0, 1.0]);
    let cross_normalized = glm::cross::&lt;f32, glm::U3&gt;(&amp;forward, &amp;up).normalize();
    let mut move_vector =
      keys
        .iter()
        .fold(glm::make_vec3(&amp;[0.0, 0.0, 0.0]), |vec, key| match *key {
          VirtualKeyCode::W =&gt; vec + forward,
          VirtualKeyCode::S =&gt; vec - forward,
          VirtualKeyCode::A =&gt; vec + cross_normalized,
          VirtualKeyCode::D =&gt; vec - cross_normalized,
          VirtualKeyCode::E =&gt; vec + up,
          VirtualKeyCode::Q =&gt; vec - up,
          _ =&gt; vec,
        });
    if move_vector != glm::zero() {
      move_vector = move_vector.normalize();
      let rotated_move_vector = glm::quat_rotate_vec3(&amp;self.quat, &amp;move_vector);
      self.position += rotated_move_vector * distance;
    }
  }
#}</code></pre></pre>
<p>To make a view matrix from this we have to expand our quaternion into a rotation
matrix, expand out position into a translation matrix, and then invert
<code>translation * rotation</code>. We invert the matrix because what the camera is
actually storing is <em>its own model matrix</em>. However, we're not trying to put the
camera in the world, we're trying to send the whole world backwards through the
camera. Uh, if that makes sense?</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn make_view_matrix(&amp;self) -&gt; glm::TMat4&lt;f32&gt; {
    let rotation = glm::quat_to_mat4(&amp;self.quat);
    let translation = glm::translation(&amp;self.position);
    glm::inverse(&amp;(translation * rotation))
  }
#}</code></pre></pre>
<p>And of course want a way to make a FreeCamera from just a position:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn at_position(position: glm::TVec3&lt;f32&gt;) -&gt; Self {
    Self {
      position,
      quat: glm::quat_identity(),
    }
  }
#}</code></pre></pre>
<p>Now we can finally move through box space in any way that we want!</p>
<p>Almost!</p>
<p>We have to update <code>LocalState</code> to have the new camera type, and we also have to
update how it computes the orientation deltas. Specifically, we have to turn the
pitch and yaw changes <em>way</em> down. Remember how we talked about the input values
needing to be small? Something like <code>0.0005</code> is a comfortable amount for one
frame of change.</p>
<p>Also, we will use <code>Z</code> and <code>C</code> to roll port and starboard.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    const MOUSE_SENSITIVITY: f32 = 0.0005;
    let d_pitch = -input.orientation_change.1 * MOUSE_SENSITIVITY;
    let d_yaw = -input.orientation_change.0 * MOUSE_SENSITIVITY;
    let mut d_roll = 0.0;
    if input.keys_held.contains(&amp;VirtualKeyCode::Z) {
      d_roll += 0.00875;
    }
    if input.keys_held.contains(&amp;VirtualKeyCode::C) {
      d_roll -= 0.00875;
    }
    self.camera.update_orientation(d_pitch, d_yaw, d_roll);
    self
      .camera
      .update_position(&amp;input.keys_held, 5.0 * input.seconds);
#}</code></pre></pre>
<p><img src="images/camera-complete.png" alt="camera-complete" /></p>
<p>Well, the boxes <em>still</em> draw over each other weird. Next lesson is finally putting
in that Depth Buffer stuff so that we can make them knock it off and act like
proper visuals.</p>
<p>As always, the code for this lesson is in the
<a href="https://github.com/Lokathor/learn-gfx-hal/tree/master/examples">examples/</a>
directory.</p>
<a class="header" href="#depth-buffer" id="depth-buffer"><h1>Depth Buffer</h1></a>
<p>Alright well we're getting close to having all the basics covered but our cubes
are all wrong when they're different distances. Later cubes overdraw earlier
cubes even if they're farther away. That's not how things should go!</p>
<p>We have to activate a part of the drawing pipeline called the &quot;Depth Buffer&quot;.
It's basically what it sounds like. In addition to recording one color value per
fragment, there's also now going to be a depth value per fragment. If any later
primitive (from the same draw call or a future draw call) <em>would</em> write to a
fragment's color, the depth buffer is checked. If it &quot;passes&quot; the check (we'll
see what that means in a moment) then the new depth value is recorded and the
new color value is recorded.</p>
<a class="header" href="#a-depthimage-type" id="a-depthimage-type"><h1>A <code>DepthImage</code> Type</h1></a>
<p>As you might imagine by now, if we're doing stuff with memory we gotta get that
memory from somewhere. The color image got allocated for us &quot;automatically&quot; as
part of us getting a backbuffer, but we don't get depth images for free.</p>
<p>By now we're a little more comfortable with things than we were at the start so
let jump straight to having all the parts of this bundled together. This is
<em>really close</em> to how <code>LoadedImage</code> works, but no Sampler.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
/// Parts for a depth buffer image
pub struct DepthImage&lt;B: Backend, D: Device&lt;B&gt;&gt; {
  pub image: ManuallyDrop&lt;B::Image&gt;,
  pub requirements: Requirements,
  pub memory: ManuallyDrop&lt;B::Memory&gt;,
  pub image_view: ManuallyDrop&lt;B::ImageView&gt;,
  pub phantom: PhantomData&lt;D&gt;,
}
#}</code></pre></pre>
<p>And we have a method to make one of these things as well as a method to clean it
up. There's not much that's surprising here. We pretty much use the same code as
before and any place we see &quot;color&quot; we replace it with &quot;depth&quot; instead. If we
had the time we could possibly make some sort of complicated thing where there's
just one AbstractImage that we use most of the time and then a LoadedImage holds
an AbstractImage plus a Sampler and all that... but I honestly just don't think
it's worth the effort to bother with all that layering complication.</p>
<p>Note: in the following code the <code>DepthImage</code> uses device local memory (since the
memory is used very actively in the graphics pipeline process), but in other
situations you might care to try and find some memory that's both device local
and <em>also</em> cpu visible (depending on exactly how you use the <code>DepthImage</code>). Most
graphics cards have at least some memory like that. As with other things in
<code>gfx-hal</code>, it always comes down to customizing every part of what's going on
based on exactly what you're trying to achieve.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;B: Backend, D: Device&lt;B&gt;&gt; DepthImage&lt;B, D&gt; {
  pub fn new(adapter: &amp;Adapter&lt;B&gt;, device: &amp;D, extent: Extent2D) -&gt; Result&lt;Self, &amp;'static str&gt; {
    unsafe {
      let mut the_image = device
        .create_image(
          gfx_hal::image::Kind::D2(extent.width, extent.height, 1, 1),
          1,
          Format::D32Float,
          gfx_hal::image::Tiling::Optimal,
          gfx_hal::image::Usage::DEPTH_STENCIL_ATTACHMENT,
          gfx_hal::image::ViewCapabilities::empty(),
        )
        .map_err(|_| &quot;Couldn't crate the image!&quot;)?;
      let requirements = device.get_image_requirements(&amp;the_image);
      let memory_type_id = adapter
        .physical_device
        .memory_properties()
        .memory_types
        .iter()
        .enumerate()
        .find(|&amp;(id, memory_type)| {
          // BIG NOTE: THIS IS DEVICE LOCAL NOT CPU VISIBLE
          requirements.type_mask &amp; (1 &lt;&lt; id) != 0
            &amp;&amp; memory_type.properties.contains(Properties::DEVICE_LOCAL)
        })
        .map(|(id, _)| MemoryTypeId(id))
        .ok_or(&quot;Couldn't find a memory type to support the image!&quot;)?;
      let memory = device
        .allocate_memory(memory_type_id, requirements.size)
        .map_err(|_| &quot;Couldn't allocate image memory!&quot;)?;
      device
        .bind_image_memory(&amp;memory, 0, &amp;mut the_image)
        .map_err(|_| &quot;Couldn't bind the image memory!&quot;)?;
      let image_view = device
        .create_image_view(
          &amp;the_image,
          gfx_hal::image::ViewKind::D2,
          Format::D32Float,
          gfx_hal::format::Swizzle::NO,
          SubresourceRange {
            aspects: Aspects::DEPTH,
            levels: 0..1,
            layers: 0..1,
          },
        )
        .map_err(|_| &quot;Couldn't create the image view!&quot;)?;
      Ok(Self {
        image: ManuallyDrop::new(the_image),
        requirements,
        memory: ManuallyDrop::new(memory),
        image_view: ManuallyDrop::new(image_view),
        phantom: PhantomData,
      })
    }
  }

  pub unsafe fn manually_drop(&amp;self, device: &amp;D) {
    use core::ptr::read;
    device.destroy_image_view(ManuallyDrop::into_inner(read(&amp;self.image_view)));
    device.destroy_image(ManuallyDrop::into_inner(read(&amp;self.image)));
    device.free_memory(ManuallyDrop::into_inner(read(&amp;self.memory)));
  }
}
#}</code></pre></pre>
<a class="header" href="#update-the-render-pass" id="update-the-render-pass"><h1>Update the render pass</h1></a>
<p>We're adding a bit to the render pass creation.</p>
<a class="header" href="#new-depth-attachment" id="new-depth-attachment"><h2>New Depth Attachment</h2></a>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let depth_attachment = Attachment {
        format: Some(Format::D32Float),
        samples: 1,
        ops: AttachmentOps {
          load: AttachmentLoadOp::Clear,
          store: AttachmentStoreOp::DontCare,
        },
        stencil_ops: AttachmentOps::DONT_CARE,
        layouts: Layout::Undefined..Layout::DepthStencilAttachmentOptimal,
      };
#}</code></pre></pre>
<p>This is <em>similar to</em> the color attachment.</p>
<ul>
<li>With the depth attachment we don't use the format that the GPU and surface
negotiated, that's just for the color data. Instead we use the format that we
specify during the <code>DepthImage</code> creation.</li>
<li><code>ops.store</code> can be changed to <code>DontCare</code> because we don't care what happens
after the full render pass completes. You <em>could</em> store it and check it later,
and there are good uses for that, but we really don't care right now.</li>
<li>Instead of our <code>layouts</code> going from <code>Undefined</code> to <code>Present</code> it goes to
<code>DepthStencilAttachmentOptimal</code>, which should sound familiar by now. That's
the depth version of the <code>ColorAttachmentOptimal</code> we're already using.</li>
</ul>
<a class="header" href="#update-subpassdesc" id="update-subpassdesc"><h2>Update SubpassDesc</h2></a>
<p>We add a new ID and layout to the <code>subpass</code></p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let subpass = SubpassDesc {
        colors: &amp;[(0, Layout::ColorAttachmentOptimal)],
        depth_stencil: Some(&amp;(1, Layout::DepthStencilAttachmentOptimal)),
        inputs: &amp;[],
        resolves: &amp;[],
        preserves: &amp;[],
      };
#}</code></pre></pre>
<a class="header" href="#add-subpass-dependencies" id="add-subpass-dependencies"><h2>Add Subpass Dependencies</h2></a>
<p>Now we're going to specify two
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/struct.SubpassDependency.html">SubpassDependency</a>
values. One for &quot;in&quot; and one for &quot;out&quot;. In our case they're basically a mirror
of each other, but if you had more passes then it'd get more intricate. Right
now our data just flows from the &quot;External&quot; world, into our lone subpass, and
then right back out into the External world.</p>
<p>We didn't have to talk about this stuff before because there <em>is</em> an <a href="https://www.reddit.com/r/vulkan/comments/8arvcj/a_question_about_subpass_dependencies/dx139hr/">implicit
subpass
dependency</a>
that happens if you don't specify one yourself. However, it's a little
conservative about when the pipeline can start and stop (as default definitions
often should be), and it doesn't enable a neat flag that we want.</p>
<p>There's a flag you can enable for <a href="http://vulkan-spec-chunked.ahcox.com/ch25s04.html">Early Fragment Test
Mode</a>. This does the depth
test (and some other tests) <em>before</em> the fragment shader runs instead of after.
This can potentially be quite a boost if you have a complicated fragment shader
that the depth buffer or other test will just cull anyway. However, there are
edge cases where you might not want it, so be sure to read that page for the
specifics. Our fragment shader isn't super fancy, so we'll just do the early
tests. Not that the speed boost really matters either since we're also well
under 16ms per frame either way, but it's the spirit of the thing.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let in_dependency = SubpassDependency {
        passes: SubpassRef::External..SubpassRef::Pass(0),
        stages: PipelineStage::COLOR_ATTACHMENT_OUTPUT
          ..PipelineStage::COLOR_ATTACHMENT_OUTPUT | PipelineStage::EARLY_FRAGMENT_TESTS,
        accesses: ImageAccess::empty()
          ..(ImageAccess::COLOR_ATTACHMENT_READ
            | ImageAccess::COLOR_ATTACHMENT_WRITE
            | ImageAccess::DEPTH_STENCIL_ATTACHMENT_READ
            | ImageAccess::DEPTH_STENCIL_ATTACHMENT_WRITE),
      };
      let out_dependency = SubpassDependency {
        passes: SubpassRef::Pass(0)..SubpassRef::External,
        stages: PipelineStage::COLOR_ATTACHMENT_OUTPUT | PipelineStage::EARLY_FRAGMENT_TESTS
          ..PipelineStage::COLOR_ATTACHMENT_OUTPUT,
        accesses: (ImageAccess::COLOR_ATTACHMENT_READ
          | ImageAccess::COLOR_ATTACHMENT_WRITE
          | ImageAccess::DEPTH_STENCIL_ATTACHMENT_READ
          | ImageAccess::DEPTH_STENCIL_ATTACHMENT_WRITE)..ImageAccess::empty(),
      };
#}</code></pre></pre>
<a class="header" href="#update-create_render_pass" id="update-create_render_pass"><h2>Update <code>create_render_pass</code></h2></a>
<p>We just change the call to incorporate the new values:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      unsafe {
        device
          .create_render_pass(
            &amp;[color_attachment, depth_attachment],
            &amp;[subpass],
            &amp;[in_dependency, out_dependency],
          )
          .map_err(|_| &quot;Couldn't create a render pass!&quot;)?
      }
#}</code></pre></pre>
<a class="header" href="#update-the-depth_stencil" id="update-the-depth_stencil"><h2>Update the <code>depth_stencil</code></h2></a>
<p>Where we have our descriptor sets and all that we need a new <code>depth_stencil</code>
definition in the <code>create_pipeline</code> function:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let depth_stencil = DepthStencilDesc {
        depth: DepthTest::On {
          fun: gfx_hal::pso::Comparison::LessEqual,
          write: true,
        },
        depth_bounds: false,
        stencil: StencilTest::Off,
      };
#}</code></pre></pre>
<p>Remember how I said that the depth buffer uses &quot;a test&quot;? Well we get limited
control over what test operation to use. In this case, we're saying that if the
new fragment's depth value is less than or equal to the old depth value (aka, if
the new fragment is closer or as close as the previous one) we write the new
fragment's data into the depth image and color image.</p>
<a class="header" href="#update-the-drawing" id="update-the-drawing"><h2>Update the drawing</h2></a>
<p>The <code>draw_clear_frame</code> method doesn't need a change. Since there's nothing that
really gets drawn we don't even have to specify a clear depth. However,
<code>draw_cubes_frame</code> has some stuff to draw so we need to give it a clear depth
value as well as a clear color value.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      const QUAD_CLEAR: [ClearValue; 2] = [
        ClearValue::Color(ClearColor::Float([0.1, 0.2, 0.3, 1.0])),
        ClearValue::DepthStencil(ClearDepthStencil(1.0, 0)),
      ];
#}</code></pre></pre>
<p>And, whoops, I guess that should be renamed to <code>CUBE_CLEAR</code> now.</p>
<a class="header" href="#update-halstate-itself" id="update-halstate-itself"><h2>Update <code>HalState</code> itself</h2></a>
<p>Finally, we need to add some depth images to our <code>HalState</code></p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  depth_images: Vec&lt;DepthImage&lt;back::Backend, back::Device&gt;&gt;,
#}</code></pre></pre>
<p>And then we adjust how we make our Framebuffer values. We already have the color
image views (which are views into the backbuffer images), but we also need to
incorporate the depth image views as well.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // Create The ImageViews
    let (image_views, depth_images, framebuffers) = match backbuffer {
      Backbuffer::Images(images) =&gt; {
        let image_views = images
          .into_iter()
          .map(|image| unsafe {
            device
              .create_image_view(
                &amp;image,
                ViewKind::D2,
                format,
                Swizzle::NO,
                SubresourceRange {
                  aspects: Aspects::COLOR,
                  levels: 0..1,
                  layers: 0..1,
                },
              )
              .map_err(|_| &quot;Couldn't create the image_view for the image!&quot;)
          })
          .collect::&lt;Result&lt;Vec&lt;_&gt;, &amp;str&gt;&gt;()?;
        let depth_images = image_views
          .iter()
          .map(|_| DepthImage::new(&amp;adapter, &amp;device, extent))
          .collect::&lt;Result&lt;Vec&lt;_&gt;, &amp;str&gt;&gt;()?;
        let image_extent = gfx_hal::image::Extent {
          width: extent.width as _,
          height: extent.height as _,
          depth: 1,
        };
        let framebuffers = image_views
          .iter()
          .zip(depth_images.iter())
          .map(|(view, depth_image)| unsafe {
            let attachments: ArrayVec&lt;[_; 2]&gt; = [view, &amp;depth_image.image_view].into();
            device
              .create_framebuffer(&amp;render_pass, attachments, image_extent)
              .map_err(|_| &quot;Couldn't crate the framebuffer!&quot;)
          })
          .collect::&lt;Result&lt;Vec&lt;_&gt;, &amp;str&gt;&gt;()?;
        (image_views, depth_images, framebuffers)
      }
      Backbuffer::Framebuffer(_) =&gt; unimplemented!(&quot;Can't handle framebuffer backbuffer!&quot;),
    };
#}</code></pre></pre>
<p>And finally, in <code>Drop</code> for <code>HalState</code> we have to clean up our <code>DepthImage</code>
values the same as we clean up the other stuff in each vec.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      for depth_image in self.depth_images.drain(..) {
        depth_image.manually_drop(&amp;self.device);
      }
#}</code></pre></pre>
<a class="header" href="#done" id="done"><h1>Done!</h1></a>
<p>We're already done! That was the whole thing! One of the shortest lessons yet,
but quite useful to be able to do.</p>
<p><img src="images/depth-buffer-complete.png" alt="depth-buffer-complete" /></p>
<p>As always, this example's code can be viewed in the
<a href="https://github.com/Lokathor/learn-gfx-hal/tree/master/examples">examples</a>
directory.</p>
<a class="header" href="#a-new-author" id="a-new-author"><h1>A new author!</h1></a>
<p>Introducing a new, star, guest author, @termhn! She's been
helping our main man Lokathor with the previous lessons, but this
time is hopping in to write the lesson for real. Woo!</p>
<a class="header" href="#instanced-drawing" id="instanced-drawing"><h1>Instanced Drawing</h1></a>
<p>So, now that we have a few cubes on the screen, what could be a more
logical step than drawing <strong>many, many more cubes on the screen</strong>?!
Well, the naive way to do this would be to just issue many more draw
calls, and indeed, since we are using push constants to change the
transformations, this would work. However, once you get to a few
thousand objects, this would start to slow down quite a bit, even for
something as simple as a textured cube, especially on less powerful
desktop and mobile GPUs. This is <em>less</em> of a problem when using one of
Vulkan/DX12/Metal than it was in the past with OpenGL, but it can still
bog down from many draw calls.</p>
<p>The solution to this problem is something called <em>instanced drawing</em>.
Whenever we've made a draw call, we've passed <em>two</em> ranges, one for
vertices and one for <em>instances</em>. Until this point, we've sort of
glossed over what this &quot;instances&quot; argument means, but that changes
now!</p>
<p>As you know, the Vertex Shader is run for every one of the vertexes in
the bound vertex buffer(s). The data from the vertex buffer gets sent in
to &quot;attributes&quot; in the shader and this data changes for each vertex
based on the stride that we told it when creating our pipeline. What
we also gave it was a &quot;rate,&quot; but we also sort of glossed over this in
the past. We have been inputting a &quot;rate&quot; of 0, which means that the
data in this vertex buffer should advance <em>for every vertex</em>. However,
if we input a rate of 1, then we are telling it that the data in this
buffer should advance only every <em>instance</em>.</p>
<p>For example, if we do a draw call over 50 vertices and 5 instances,
it will repeat all 50 vertices 5 times. Each &quot;rate 0&quot; vertex buffer
advances once per vertex and resets to the start for the next instance.
Each &quot;rate 1&quot; vertex buffer will stay the same across a whole instance
and then advance once in between instances.</p>
<p>Basically, we can get data which stays the same between each
<em>instance</em> of an object. This can often be super useful, as we'll
explore in this tutorial!</p>
<p>It's also possible to use a <code>rate</code> of more than 1. In this case,
the rate determines the <em>number of instanes</em> which will be skipped
before the data is advanced. For example, for a rate of 2, the
data will be advanced <em>every other</em> instance instead of every
instance. This feature is supported by default on DX12 and Metal,
but it is gated behind an extension in Vulkan and the <code>gfx-hal</code>
Vulkan backend does not currently support it. However, work
<a href="https://github.com/gfx-rs/gfx/pull/2611">is being done</a> to
rememdy this.</p>
<a class="header" href="#a-maximum-number-of-instances" id="a-maximum-number-of-instances"><h2>A maximum number of instances</h2></a>
<p>As we'll soon discover, using this method <em>does</em> come with some
limitations. One of them is that we'll need to know ahead of time
the maximum number of instances we want to be able to draw, and we'll
need to allocate a buffer big enough to fit all the data for those
maximum number of instances. Luckily, our per-instance data is
relatively small, so it's not too big a deal.</p>
<p>For now, we'll just choose an arbitrary but fairly large number like</p>
<ol start="5000">
<li>Just above where we have our vertex shader source, we'll put</li>
</ol>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const MAX_CUBES: usize = 5000;
#}</code></pre></pre>
<a class="header" href="#modifying-the-shader" id="modifying-the-shader"><h2>Modifying the shader</h2></a>
<p>Okay, so the next thing we'll do is modify our vertex shader a little
bit. The first thing we'll do is change our push constant block
slightly. Instead of passing in a fully precomputed
model-view-projection matrix all in one, we're now going to precompute
the view-projection matrix in our push constants and then pass in
<em>a new model matrix per instance</em> and combine the two in the vertex
shader.</p>
<pre><code class="language-glsl">layout (push_constant) uniform PushConsts {
  mat4 view_proj;
} push;
</code></pre>
<p>Next, we're going to add <em>four</em> new vertex attributes. We need four
because each attribute location can only store up to a maximum of a
<code>vec4</code> of data, and we want to pass in a <code>mat4</code> instead. Actually, in
theory, the Vulkan spec supports just defining one attribute at the
first of the four locations with type <code>mat4</code> and it will automatically
fetch the data from the next four attribute locations, but this isn't
yet translated properly to dx12, so we'll hold off on that for now.
So, just below our <code>position</code> and <code>vert_uv</code> input attributes, we'll add</p>
<pre><code class="language-glsl">layout (location = 2) in vec4 model_col1;
layout (location = 3) in vec4 model_col2;
layout (location = 4) in vec4 model_col3;
layout (location = 5) in vec4 model_col4;
</code></pre>
<p>And finally update the actual calculation to use this new setup like
so</p>
<pre><code class="language-glsl">void main()
{
  mat4 model = mat4(
    model_col1,
    model_col2,
    model_col3,
    model_col4);
  gl_Position = push.view_proj * model * vec4(position, 1.0);
  frag_uv = vert_uv;
}
</code></pre>
<p>Okay, that's all we need to do in the shaders!</p>
<a class="header" href="#adding-instance-buffers-to-halstate" id="adding-instance-buffers-to-halstate"><h2>Adding instance buffers to HalState</h2></a>
<p>The next thing we need to do is add a new piece of <code>HalState</code> which
we'll call <code>cube_instances</code></p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct HalState {
    //...
    cube_instances: Vec&lt;BufferBundle&lt;back::Backend, back::Device&gt;&gt;,
    //...
}
#}</code></pre></pre>
<p>The reason we want a <code>Vec</code> of <code>BufferBundle</code>s is because we are
actually going to use not just <em>one</em> instance buffer, but one instance
buffer <em>per frame</em> in flight. The reason we do this is so that we can
guarantee that we are not attempting to write new data into the buffer
to update the transformations of the cubes while another frame is
trying to read from that data on the GPU.</p>
<p>Next we'll actually create those buffers in <code>HalState</code>'s <code>new</code>, just
below where we create and upload to the index buffer:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    let mut cube_instances = Vec::new();
    for _ in 0..frames_in_flight {
      cube_instances.push(BufferBundle::new(
        &amp;adapter,
        &amp;device,
        size_of::&lt;f32&gt;() * 16 * MAX_CUBES,
        BufferUsage::VERTEX,
      )?);
    }
#}</code></pre></pre>
<p>Note that the size is 16 <code>f32</code>s (the size of a 4x4 matrix) times the
max number of cubes we defined earlier, and that the usage is
VERTEX. Also note that our <code>BufferBundle</code> already <em>by default</em> and
<em>only</em> (for now) supports creating a <code>CPU_VISIBLE</code> buffer. This is
usually what you want for an instance buffer, as you'll be wanting to
write data to it frequently. However, we'll also want to transition to
using to <code>DEVICE_LOCAL</code> memory for most of our normal vertex buffers,
which will likely <em>not</em> be changed and therefore are much better off
living in the high speed, on-device memory.</p>
<p>Oh, and don't forget to clean them up either! Right after we clean
up the other cube vertex and index buffers,</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
for buf in self.cube_instances.drain(..) {
    buf.manually_drop(self.device.deref());
}
#}</code></pre></pre>
<a class="header" href="#adding-new-vertex-buffer-and-attributes-to-pipeline" id="adding-new-vertex-buffer-and-attributes-to-pipeline"><h2>Adding new vertex buffer and attributes to pipeline</h2></a>
<p>The next thing we'll do is modify our pipeline to add another vertex
buffer and our four new vertex attributes.</p>
<p>In the <code>create_pipeline</code> function, we'll modify the creation of the
<code>vertex_buffers</code> to add a second one</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let vertex_buffers: Vec&lt;VertexBufferDesc&gt; = vec![
    VertexBufferDesc {
        binding: 0,
        stride: size_of::&lt;Vertex&gt;() as ElemStride,
        rate: 0,
    },
    // Add another vertex buffer with stride of a 4x4 matrix and rate 1
    // meaning it advances once per instance rather than per vertex
    VertexBufferDesc {
        binding: 1,
        stride: (size_of::&lt;f32&gt;() * 16) as ElemStride,
        rate: 1,
    }
];
#}</code></pre></pre>
<p>And add four new attributes to <code>attributes</code></p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut attributes: Vec&lt;AttributeDesc&gt; = Vertex::attributes();

// We need 4 new attributes, one for each column of the matrix we want to put in.
for i in 0..4 {
    attributes.push(AttributeDesc {
        location: 2 + i,
        binding: 1,
        element: Element {
            format: Format::Rgba32Float,
            offset: i * 16,
        },
    });
}
#}</code></pre></pre>
<p>Note the <code>binding</code> which matches the <code>VertexBufferDesc</code> above it,
as well as the <code>location</code>s which match with what we added to
our shaders. Also be careful to use the correct <code>format</code> and
<code>offset</code>s into each <code>stride</code> in the buffer.</p>
<a class="header" href="#uploading-data-and-drawing-it" id="uploading-data-and-drawing-it"><h2>Uploading data and drawing it</h2></a>
<p>Now we'll drop all the way down to <code>draw_cubes_frame</code>. The first thing
we'll do is get a mutable reference to the corresponding instance
buffer just after we wait on the acquire'd image's previous
submission fence.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let cube_instance_buf = &amp;mut self.cube_instances[i_usize];
#}</code></pre></pre>
<p>Next we'll write the instance data into the instance buffer for each
cube which we are passed in, up to the max number of cubes. This
process is pretty similar to other writing we've done to CPU visible
buffers in the past.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// Since we just waited for the previous submission's fence we know we can write data to the buffer
// We write each model matrix given (up to a max of MAX_CUBES because that's what we allocated space for)
unsafe {
    let mut data_target = self.device
        .acquire_mapping_writer(&amp;cube_instance_buf.memory, 0..cube_instance_buf.requirements.size)
        .map_err(|_| &quot;Failed to acquire an instance buffer mapping writer!&quot;)?;
    let stride = 16; // 16 floats = one 4x4 matrix
    for i in 0..models.len().min(MAX_CUBES) {
        data_target[i*stride..(i+1)*stride].copy_from_slice(&amp;models[i].data);
    }
    self.device
        .release_mapping_writer(data_target)
        .map_err(|_| &quot;Couldn't release an instance buffer mapping writer!&quot;)?;
}
#}</code></pre></pre>
<p>Next, we'll modify our command recording. First, we'll take out the
loop that previously existed so we only have one each of the
<code>push_graphics_constants</code> and <code>draw_indexed</code> commands. We'll also
change our <code>push_graphics_constants</code> to only pass in the
<code>view_projection</code> matrix, and delete the old math that calculated
the full MVP matrix.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
encoder.push_graphics_constants(
    &amp;self.pipeline_layout,
    ShaderStageFlags::VERTEX,
    0,
    cast_slice::&lt;f32, u32&gt;(&amp;view_projection.data)
        .expect(&quot;this cast never fails for same-aligned same-size data&quot;),
);
#}</code></pre></pre>
<p>And finally, change our draw call to draw the correct number of
vertices <em>and</em> instances.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
encoder.draw_indexed(0..36, 0, 0..models.len().min(MAX_CUBES) as u32);
#}</code></pre></pre>
<a class="header" href="#done--almost" id="done--almost"><h2>Done! ... Almost</h2></a>
<p>Okay! Now if you start it, you should see... the same thing as the
last lesson! Okay, well... nice, but we wanted <em>more cubes</em>! Alright,
well, to do that we'll bring in the <code>rand</code> crate and spice up our
cube generation just a little bit.</p>
<a class="header" href="#getting-random" id="getting-random"><h2>Getting Random</h2></a>
<p>First in our <code>Cargo.toml</code></p>
<pre><code class="language-toml">rand = &quot;0.6&quot;
</code></pre>
<p>Then, near the top of our rust file,</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
use rand::prelude::*;
#}</code></pre></pre>
<p>Next, we'll change the &quot;physics&quot; rotation code a bit, as it gets...
<em>really</em> fast when you increase the number of cubes being shown.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let r = ONE_SIXTIETH * 30.0 * (i as f32 + 1.0) / MAX_CUBES as f32;
#}</code></pre></pre>
<p>Next, we'll change our cube generation code a bit. Instead of
manually defining 6 cubes, we'll generate cubes up to our defined
<code>MAX_CUBES</code> and distribute them randomly into an area proportionate
to the number of them.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut cubes = Vec::with_capacity(MAX_CUBES);
let mut rng = rand::thread_rng();
for _ in 0..MAX_CUBES {
    let scaling = (MAX_CUBES as f32).cbrt() * 3.0;
    let rand_vec = glm::vec3(rng.gen::&lt;f32&gt;(), rng.gen::&lt;f32&gt;(), rng.gen::&lt;f32&gt;());
    cubes.push(glm::translation(&amp;(scaling * rand_vec)));
}
LocalState {
    //...
    cubes,
    //...
}
#}</code></pre></pre>
<p>You'll notice that the area we're distributing the cubes into is a
cube with each side as <code>cbrt(MAX_CUBES) * 3.0</code>. This means that, on
average, since each cube is one unit in size, there will be one cube
distributed every 3 units. Feel free to play around with the scalar
multiplication if you want a tighter or more spread distribution.</p>
<a class="header" href="#change-the-projection-matrix" id="change-the-projection-matrix"><h2>Change the projection matrix</h2></a>
<p>Finally, we'll need to change the perspective matrix a bit to make the
'far' plane further away, or else we'll lose some cubes off the far
clipping plane!</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut temp = glm::perspective_lh_zo(800.0 / 600.0, f32::to_radians(50.0), 0.1, 1000.0);
#}</code></pre></pre>
<p>Now you should get something like this</p>
<p><img src="images/5kcubes.jpg" alt="5000 cubes" /></p>
<p>Which, okay, that's cool, but how high can we go?! I've had success
with 200,000 cubes on my own machine, but you might be able to go
higher!</p>
<p><img src="images/200kcubes.jpg" alt="200k cubes" /></p>
<p>Yeah, that's a lot of cubes...</p>
<p>As always, this example's code can be viewed in the
<a href="https://github.com/Lokathor/learn-gfx-hal/tree/master/examples">examples</a>
directory.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
